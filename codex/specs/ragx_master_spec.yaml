# RAGX Master Spec
version: 0.3
metadata:
  project_name: ragx
  description: Clean-slate architecture for DSL-driven RAG system with MCP tools, declarative Toolpacks, REST/STDIO transports, policy/budget guards, linter, and optional C++ vector index core.
  owners: [pfahlr@gmail.com]
  last_updated: "2025-09-27T12:00:00Z"

# Canonical CLI flags (single source of truth)
arg_spec:
  common:
    - { flag: "--index-dir",         dest: index_dir,         type: path,   env: RAGX_INDEX_DIR,  default: ".cache/indexes", help: "Root directory for vector indexes." }
    - { flag: "--corpus-dir",        dest: corpus_dir,        type: path,   env: RAGX_CORPUS_DIR, help: "Directory containing corpus.jsonl and documents." }
    - { flag: "--embedding",         dest: embedding,         type: str,    env: RAGX_EMBEDDING,  default: "bge-small-en",    help: "Embedding model name." }
    - { flag: "--log-level",         dest: log_level,         type: enum,   choices: [DEBUG,INFO,WARN,ERROR], default: INFO }
    - { flag: "--config",            dest: config,            type: path,   help: "Optional YAML/JSON config file for defaults." }

  mcp_server:
    - { flag: "--http",              dest: http,              type: bool,   help: "Run HTTP transport." }
    - { flag: "--stdio",             dest: stdio,             type: bool,   help: "Run STDIO JSON-RPC transport." }
    - { flag: "--host",              dest: host,              type: str,    default: "127.0.0.1" }
    - { flag: "--port",              dest: port,              type: int,    default: 3333 }
    - { flag: "--max-connections",   dest: max_connections,   type: int,    default: 256 }
    - { flag: "--shutdown-grace",    dest: shutdown_grace,    type: int,    default: 10 }

  task_runner:
    - { flag: "--workflow",          dest: workflow,          type: path,   help: "Path to DSL workflow YAML." }
    - { flag: "--var",               dest: vars,              type: str,    repeatable: true, help: "Runtime vars KEY=VAL." }
    - { flag: "--vars-file",         dest: vars_file,         type: path }
    - { flag: "--trace",             dest: trace,             type: path,   default: "runs/trace.jsonl" }
    - { flag: "--artifacts-dir",     dest: artifacts_dir,     type: path,   default: "runs/{RUN_ID}" }
    - { flag: "--cache",             dest: cache,             type: enum,   choices: [off,read,readwrite], default: readwrite }
    - { flag: "--max-concurrency",   dest: max_concurrency,   type: int,    default: 4 }
    - { flag: "--fail-fast",         dest: fail_fast,         type: bool }
    - { flag: "--dry-run",           dest: dry_run,           type: bool }
    - { flag: "--policy-mode",       dest: policy_mode,       type: enum,   choices: [strict,permissive], default: strict }
    - { flag: "--usd-cap",           dest: usd_cap,           type: float,  help: "Override globals.run_budget.max_usd." }
    - { flag: "--otel-endpoint",     dest: otel_endpoint,     type: str }
    - { flag: "--mcp-url",           dest: mcp_url,           type: str,    default: "http://127.0.0.1:3333" }

  linter:
    - { flag: "--spec",              dest: spec,              type: path }
    - { flag: "--strict-missing-pricing", dest: strict_missing_pricing, type: bool }
    - { flag: "--format",            dest: format,            type: enum, choices: [text,json,sarif], default: text }

  vectordb_builder:
    - { flag: "--index-kind",        dest: index_kind,        type: enum,   choices: [flat,ivf_flat,ivf_pq,hnsw], default: ivf_flat }
    - { flag: "--metric",            dest: metric,            type: enum,   choices: [l2,ip], default: ip }
    - { flag: "--dim",               dest: dim,               type: int,    default: 384 }
    - { flag: "--nlist",             dest: nlist,             type: int,    default: 2048 }
    - { flag: "--nprobe",            dest: nprobe,            type: int,    default: 32 }
    - { flag: "--pq-m",              dest: pq_m,              type: int,    default: 16 }
    - { flag: "--pq-bits",           dest: pq_bits,           type: int,    default: 8 }
    - { flag: "--M",                 dest: hnsw_M,            type: int,    default: 32 }
    - { flag: "--ef-construction",   dest: hnsw_ef_construction, type: int, default: 200 }
    - { flag: "--ef-search",         dest: hnsw_ef_search,    type: int,    default: 64 }
    - { flag: "--train-vectors",     dest: train_vectors,     type: path }
    - { flag: "--add-vectors",       dest: add_vectors,       type: path }
    - { flag: "--out",               dest: out,               type: path }
    - { flag: "--merge",             dest: merge,             type: path,   repeatable: true }
    - { flag: "--faiss-threads",     dest: faiss_threads,     type: int,    default: 0 }
    - { flag: "--to-gpu",            dest: to_gpu,            type: int }
    - { flag: "--accept-format",     dest: accept_format,     type: enum,   choices: [pdf,md], repeatable: true, default: [pdf,md], help: "Accepted source formats when scanning --corpus-dir." }

  retrieval:
    - { flag: "--search",            dest: search,            type: enum,   choices: [bing,tavily,none], default: none, help: "Web search provider used by retriever." }
    - { flag: "--hybrid",            dest: hybrid,            type: bool,   help: "Enable BM25+vector hybrid scoring." }
    - { flag: "--hybrid-weight",     dest: hybrid_weight,     type: float,  default: 0.5, help: "Weight for vector score (1-w for BM25)." }
    - { flag: "--top-k",             dest: top_k,             type: int,    default: 10 }
    - { flag: "--rerank",            dest: rerank,            type: enum,   choices: [on,off], default: off }
    - { flag: "--rerank-model",      dest: rerank_model,      type: str,    default: "cross-encoder/ms-marco-MiniLM-L-12-v2" }
    - { flag: "--rerank-top-k",      dest: rerank_top_k,      type: int,    default: 20 }

  planner:
    - { flag: "--topic",             dest: topic,             type: str }
    - { flag: "--depth",             dest: depth,             type: int,    default: 2 }
    - { flag: "--max-perspectives",  dest: max_perspectives,  type: int,    default: 5 }
    - { flag: "--seed",              dest: seed,              type: int,    default: 1337 }
    - { flag: "--save-mindmap",      dest: save_mindmap,      type: path }

  hitl:
    - { flag: "--approve-outline",   dest: approve_outline,   type: enum,   choices: [editor,stdin,noninteractive], default: noninteractive }
    - { flag: "--inject-questions",  dest: inject_questions,  type: path }
    - { flag: "--sources-review",    dest: sources_review,    type: path }

  research:
    - { flag: "--parallel",          dest: parallel,          type: int,    default: 8 }
    - { flag: "--out-dir",           dest: out_dir,           type: path,   default: "runs/${EPOCH_TS}" }

# Components
components:
  - id: dsl
    phase: P0
    title: Multi-shot Prompting DSL & Executor
    description: Declarative graph-based DSL for units, transforms, decisions, and loops; policies, budgets, fallbacks; templating, caching, tracing; CI linter.
    responsibilities:
      - Define nodes, edges, control structures (unit, transform, decision, loop, end).
      - Render Jinja templates; resolve inputs/outputs; deterministic caching.
      - Enforce policies (allow/deny tools/tags) and budgets (usd, tokens, calls, time).
      - Emit JSONL traces, artifacts; provide static linter for CI.
    interfaces:
      cli:
        command: "task-runner"
        subcommands:
          - { name: "run",  flags_ref: task_runner }
          - { name: "lint", flags_ref: linter }
      classes:
        - { name: FlowRunner, methods: [plan, run], fields: [policy_stack, budget_meter, adapters] }
        - { name: TraceWriter, methods: [start_run, emit, end_run] }
      python:
        protocols:
          - { name: Adapter, methods: [estimate_min_cost, call], notes: "MUST dispatch via MCP tools; direct vector backends are disallowed." }
          - { name: Transform, methods: [execute] }
    schemas:
      base: "pkgs/dsl/schemas/flow.base.schema.json"
      policy_patch: "pkgs/dsl/schemas/flow.policy.patch.schema.json"
      budget_patch: "pkgs/dsl/schemas/flow.budget.patch.schema.json"
      hints_patch: "pkgs/dsl/schemas/flow.hints.patch.schema.json"
      example_flows:
        - "flows/example.react_self_refine.yaml"
    data_contracts:
      trace_event_jsonl_example:
        json: {"ts":"...", "event":"node_end", "run_id":"abc", "node_id":"final_answer", "cost":{"usd":0.012,"tok_in":420,"tok_out":210}}
    dependencies: [jinja2, jsonschema, pydantic, pyyaml]
    observability:
      traces:
        format: jsonl
        path_default: "runs/trace.jsonl"
      metrics: [budget_spend_usd_total, tool_calls_total, run_duration_seconds, cache_hit_ratio]
      logs: [node_start, node_end, retries, fallbacks, costs]
    risks:
      - shell_transforms_are_nondeterministic
      - pricing_metadata_can_drift
    outputs:
      - { type: artifact, id: dsl_trace, path_template: "runs/{run_id}/events.jsonl" }

  - id: policy_engine
    phase: P0
    title: Policy Engine (Tool Constraints)
    description: Hierarchical allow/deny for tools and tags at node/loop/decision scopes; branch-scoped policies.
    responsibilities:
      - Maintain policy stack; compute effective allowlist; enforce and trace policy decisions.
      - Validate reachability at compile time (linter rules).
    interfaces:
      classes:
        - { name: PolicyStack, methods: [push, pop, effective_allowlist], fields: [stack] }
    data_contracts:
      policy_snippet:
        yaml: |
          policy:
            allow_tools: [analysis_only]
            deny_tags: [external]
    dependencies: []
    observability:
      logs: [policy_push, policy_pop, policy_violation]
      metrics: [policy_blocked_nodes_total]
    risks:
      - nested_precedence_confusion

  - id: budget_guards
    phase: P0
    title: Budget & Cost Guards
    description: Hard/soft budgets at run/node/spec/loop; stop-on-budget for loops; cost/tokens/calls/time.
    responsibilities:
      - Track spend; enforce caps; expose meters to runner; estimate costs via tool pricing.
    interfaces:
      classes:
        - { name: BudgetMeter, methods: [can_spend, charge, remaining], fields: [usd, tokens, calls, time_ms] }
    data_contracts:
      loop_stop_budget:
        yaml: |
          stop:
            max_iterations: 3
            budget: { max_usd: 0.75, breach_action: stop }
    dependencies: []
    observability:
      metrics: [usd_spent_total, tokens_spent_total, calls_made_total, budget_breaches_total]
      logs: [budget_breach, budget_warn]
    risks:
      - price_drift_model_updates

  - id: linter
    phase: P0
    title: Static Flow Linter
    description: Detect unreachable tools, impossible budgets, loop blow-ups, missing pricing; CI-friendly.
    responsibilities:
      - Analyze DSL + tool pricing; output structured issues.
    interfaces:
      cli:
        command: "ragw"
        subcommands:
          - { name: "flow", flags_ref: linter }
      stdio_methods: []
      classes:
        - { name: Issue, methods: [], fields: [level, code, msg, path] }
    dependencies: [pyyaml, jsonschema]
    observability:
      logs: [issue_summary]
      metrics: [linter_errors_total, linter_warnings_total]
    risks:
      - conservative_estimates_trigger_false_positives

  - id: transforms_sandbox
    phase: P1
    title: Transform Sandbox
    description: Jinja/Python (and optional shell) transforms with resource limits and optional network-off.
    responsibilities:
      - Execute transforms safely; capture stdout/stderr; enforce time/memory.
    interfaces:
      classes:
        - { name: Sandbox, methods: [run_python, run_shell], fields: [cpu_ms, mem_mb, net_enabled] }
    dependencies: []
    observability:
      logs: [stdout_snippet, stderr_snippet, exit_code]
      metrics: [transform_latency_seconds, transform_failures_total]
    risks:
      - enabling_shell_opens_attack_surface

  - id: mcp_server
    phase: P0
    title: MCP Server (HTTP + STDIO)
    description: Deterministic server exposing tools and prompt registry via uniform Envelope.
    responsibilities:
      - Serve discovery, prompts, and tool invocations; load Toolpacks; schema-validate IO.
    interfaces:
      cli:
        command: "mcp-server"
        flags_ref: mcp_server
      endpoints_http:
        - { method: GET,  path: "/mcp/discover" }
        - { method: GET,  path: "/mcp/prompt/{domain}/{name}/{major}" }
        - { method: POST, path: "/mcp/tool/{tool_name}" }
      stdio_methods:
        - "mcp.discover"
        - "mcp.prompt.get"
        - "mcp.tool.invoke"
      classes:
        - { name: McpService, methods: [discover, get_prompt, invoke_tool] }
        - { name: Registry,   methods: [discover, get_prompt] }
        - { name: Toolpack,   fields: [id, version, deterministic, timeoutMs, limits, caps, inputSchema, outputSchema, execution, env, templating] }
        - { name: Envelope,   fields: [ok, data, meta, errors] }
      adapters:
        - { name: http_transport, tool: any, transport: http }
        - { name: stdio_transport, tool: any, transport: stdio }
    schemas:
      envelope: "apps/mcp_server/schemas/envelope.schema.json"
      tools:
        web_search_query_input:  "apps/mcp_server/schemas/tools/web_search_query.input.schema.json"
        web_search_query_output: "apps/mcp_server/schemas/tools/web_search_query.output.schema.json"
        vector_query_search_input:  "apps/mcp_server/schemas/tools/vector_query_search.input.schema.json"
        vector_query_search_output: "apps/mcp_server/schemas/tools/vector_query_search.output.schema.json"
        docs_load_fetch_input:  "apps/mcp_server/schemas/tools/docs_load_fetch.input.schema.json"
        docs_load_fetch_output: "apps/mcp_server/schemas/tools/docs_load_fetch.output.schema.json"
        citations_audit_check_input:  "apps/mcp_server/schemas/tools/citations_audit_check.input.schema.json"
        citations_audit_check_output: "apps/mcp_server/schemas/tools/citations_audit_check.output.schema.json"
        exports_render_markdown_input:  "apps/mcp_server/schemas/tools/exports_render_markdown.input.schema.json"
        exports_render_markdown_output: "apps/mcp_server/schemas/tools/exports_render_markdown.output.schema.json"
      toolpacks_dir: "apps/mcp_server/toolpacks/"
      prompts_dir: "apps/mcp_server/prompts/"
    dependencies: [fastapi, uvicorn, pydantic, jsonschema, jinja2, httpx, packaging]
    observability:
      logs: [trace_id, transport, tool, version, duration_ms, io_bytes, status, error_code]
      metrics: [mcp_requests_total, mcp_request_duration_seconds_bucket, mcp_errors_total, mcp_io_bytes_total]
      traces:
        format: jsonl
        path_default: "runs/mcp_trace.jsonl"
    risks:
      - backpressure_defaults
      - subprocess_resource_limits
    outputs:
      - { type: discovery_doc, path: "/mcp/discover" }

  - id: toolpacks_runtime
    phase: P0
    title: Declarative Toolpacks Runtime
    description: Load and execute YAML-defined tools (python/node/php/cli/http) with JSON stdin/stdout, schema validation, and limits.
    responsibilities:
      - Load *.tool.yaml; resolve $ref; execute via subprocess/in-proc; idempotency cache.
    interfaces:
      classes:
        - { name: ToolpackLoader, methods: [load_dir, list, get] }
        - { name: Executor, methods: [run_toolpack] }
      adapters:
        - { name: kind_python, tool: any, transport: inproc_or_subprocess }
        - { name: kind_node,   tool: any, transport: subprocess }
        - { name: kind_php,    tool: any, transport: subprocess }
        - { name: kind_cli,    tool: any, transport: subprocess }
        - { name: kind_http,   tool: any, transport: http }
    data_contracts:
      execution_stdin_example: { json: { input: { any: "object" } } }
      execution_stdout_example: { json: { any: "tool_data" } }
    dependencies: [jinja2, httpx, packaging]
    observability:
      logs: [exec_kind, argv_or_module, exit_code, duration_ms, out_bytes]
    metrics: [toolpack_exec_total, toolpack_timeout_total, toolpack_bytes_out_total]
    risks:
      - script_path_traversal
      - nondeterministic_external_services

  - id: core_tools
    phase: P0
    title: Core MCP Tools (canonical set)
    description: Web search, docs loader, vector query, citation audit, and markdown renderer with normalized schemas.
    responsibilities:
      - Provide stable input/output schemas; normalize provider outputs.
    interfaces:
      stdio_methods:
        - "mcp.tool:web.search.query"
        - "mcp.tool:docs.load.fetch"
        - "mcp.tool:vector.query.search"
        - "mcp.tool:citations.audit.check"
        - "mcp.tool:exports.render.markdown"
    schemas:
      ref: "*see mcp_server.schemas.tools*"
    dependencies: []
    observability:
      metrics: [tool_success_total, tool_error_total, tool_duration_seconds_bucket]
    risks:
      - provider_normalization_gaps
  - id: rest_facade
    phase: P1
    title: REST Parity Facade
    description: Thin HTTP endpoints mirroring key MCP tools for convenience.
    responsibilities:
      - Provide /v1/search, /v1/plan, /v1/research, /v1/hitl/*.
    interfaces:
      endpoints_http:
        - { method: POST, path: "/v1/search" }
        - { method: POST, path: "/v1/plan" }
        - { method: POST, path: "/v1/research" }
        - { method: POST, path: "/v1/hitl/outline-review" }
        - { method: POST, path: "/v1/hitl/questions-merge" }
    dependencies: [fastapi]
    observability:
      logs: [route, status_code, duration_ms, payload_bytes]
      metrics: [rest_requests_total, rest_request_duration_seconds_bucket]
    risks:
      - streaming_vs_sync_for_long_runs

  - id: retrieval_rerank
    phase: P1
    title: Enhanced Retrieval + Re-Ranking
    description: Retriever factory with Bing/Tavily connectors via MCP, hybrid BM25+vector scoring, optional cross-encoder reranker.
    responsibilities:
      - Normalize results via web.search; combine BM25 & vector scores; optional rerank; NDCG gates.
    interfaces:
      cli:
        command: "rw"
        subcommands:
          - { name: "search", flags_ref: retrieval }
      classes:
        - { name: RetrieverFactory, methods: [make_retriever] }
        - { name: CrossEncoderReranker, methods: [rerank] }
      adapters:
        - { name: web_bing,  tool: mcp.tool:web.search.query, transport: http_or_stdio }
        - { name: web_tavily, tool: mcp.tool:web.search.query, transport: http_or_stdio }
    data_contracts:
      search_input_example:
        json: { q: "urban heat islands", recencyDays: 30, limit: 10, provider: "tavily" }
      search_output_example:
        json: { results: [ { title: "...", url: "https://...", snippet: "...", publishedAt: "2024-01-01T00:00:00Z" } ], meta: { provider: "tavily" } }
    dependencies: [numpy, sentence-transformers, faiss]
    observability:
      metrics: [ndcg_at_3, ndcg_at_5, retrieval_latency_seconds, rerank_latency_seconds]
      logs: [provider, hybrid_enabled, rerank_enabled]
    risks:
      - model_download_in_ci
      - variability_across_providers

  - id: planner_multiperspective
    phase: P1
    title: Multi-Perspective Question Planning
    description: Deterministic perspective/question generation and concept graph (mind-map).
    responsibilities:
      - Derive perspectives; generate questions with stable ids; export/import graph JSON.
    interfaces:
      cli:
        command: "rw"
        subcommands:
          - { name: "plan", flags_ref: planner }
      stdio_methods:
        - "mcp.tool:planner.multi_perspective"
      classes:
        - { name: Perspective, methods: [derive_perspectives, generate_questions] }
        - { name: MindMap, methods: [add_node, add_edge, to_json, from_json] }
    data_contracts:
      plan_input_example:
        json: { topic: "Solar rooftops", depth: 2, maxPerspectives: 5, seed: 1337 }
      plan_output_example:
        json: { questions: [ { id: "q1", perspective: "historical", text: "..." } ], perspectives: ["historical"], graph: { nodes: {}, edges: [] } }
    dependencies: []
    observability:
      metrics: [planner_latency_seconds, perspective_count, question_count]
    risks:
      - outline_integration_fidelity

  - id: hitl_checkpoints
    phase: P1
    title: Human-in-the-Loop Checkpoints
    description: Outline approval (editor/stdin/noninteractive), question injection, source review; mind-map viewer.
    responsibilities:
      - Validate & merge user-provided edits/questions; pretty-print mind-map.
    interfaces:
      cli:
        command: "rw"
        subcommands:
          - { name: "mindmap", flags_ref: planner }
      endpoints_http:
        - { method: POST, path: "/v1/hitl/outline-review" }
        - { method: POST, path: "/v1/hitl/questions-merge" }
      stdio_methods:
        - "mcp.tool:hitl.outline_review"
        - "mcp.tool:hitl.questions_merge"
      classes:
        - { name: Checkpointer, methods: [approve_outline, inject_questions, review_sources] }
        - { name: MindMapView, methods: [pretty_print] }
    data_contracts:
      outline_schema_ref: "apps/mcp_server/schemas/hitl/outline.schema.json"
      questions_schema_ref: "apps/mcp_server/schemas/hitl/questions.schema.json"
      sources_schema_ref: "apps/mcp_server/schemas/hitl/sources.schema.json"
    dependencies: [pyyaml]
    observability:
      metrics: [edits_applied_total, questions_merged_total, validation_errors_total]
    risks:
      - editor_mode_in_automation

  - id: agents_pipeline
    phase: P1
    title: Multi-Agent Research Pipeline
    description: Planner → Executor (parallel retrieval/summarization) → Publisher assembling report/outline/bibliography.
    responsibilities:
      - Deterministic outputs; parallel speedups; clear separation of concerns.
    interfaces:
      cli:
        command: "rw"
        subcommands:
          - { name: "research", flags_ref: research }
      stdio_methods:
        - "mcp.tool:research.execute"
      classes:
        - { name: Planner,   methods: [plan] }
        - { name: Executor,  methods: [run] }
        - { name: Publisher, methods: [assemble] }
    data_contracts:
      research_input_example:
        json: { topic: "Urban heat islands", parallel: 8, seed: 1337, maxTasks: 12 }
      research_output_example:
        json:
          notes: [ { id: "n1", task_id: "t1", text: "...", sources: ["u1"], citation_keys: ["[1]"] } ]
          sources: [ { id: "u1", url: "https://...", title: "...", snippet: "...", reliability: 0.8 } ]
          artifacts: { report_md: "# Report\n...", outline_md: "# Outline\n...", bibliography_md: "# References\n..." }
          run_id: "uuid"
    dependencies: [anyio]
    observability:
      metrics: [executor_parallel_speedup, dedupe_ratio, citations_per_k_tokens]
      logs: [task_count, note_count, source_count]
    risks:
      - backpressure_and_streaming_policies

  - id: flowscript_frontend
    phase: P1
    title: FlowScript Frontend (human-readable DSL -> YAML DSL)
    description: A friendlier textual DSL that compiles to the existing YAML DSL. Ships grammar, AST schema, compiler, and lints.
    responsibilities:
      - Define PEG grammar and JSON Schema for FlowScript AST.
      - Compile FlowScript -> YAML DSL 1:1 preserving policies, budgets, hints, and IO.
      - Validate AST against schema before compilation; emit precise errors with line/col.
      - Provide editor niceties: syntax highlight spec, error codes, and quick-fixes.
    interfaces:
      cli:
        command: "rw"
        subcommands:
          - { name: "compile", flags: ["--in", "--out", "--validate-only", "--pretty"] }
      classes:
        - { name: FlowScriptCompiler, methods: [parse, validate_ast, compile_to_yaml] }
        - { name: FlowScriptLints, methods: [unused_vars, missing_outputs_default, invalid_tool_refs] }
    schemas:
      ast: "codex/flowscript/flowscript.ast.schema.json"
      mapping: "codex/flowscript/flowscript.mapping.yaml"
      grammar: "codex/flowscript/flowscript.grammar.pegjs"
    data_contracts:
      examples_dir: "codex/flowscript/examples/"
    dependencies: [jsonschema]
    observability:
      logs: [fs_parse_ms, fs_validate_ms, fs_compile_ms]
      metrics: [flowscript_files_compiled_total, flowscript_compile_errors_total]
    risks:
      - grammar_ambiguities_vs_yaml_semantics
      - drift_between_mapping_and_runner
    outputs:
      - { type: artifact, id: flowscript_yaml, path_template: "runs/{run_id}/compiled.yaml" }

  # ===== Vector DB area split for maintainability =====

  - id: vector_db_core
    phase: P0
    title: Vector DB Core (Interfaces + Orchestrator)
    description: Stable Python registry + protocols; C++ interface design; CLI wrapper; CPU-serialized index contract. Consumed by MCP tool implementations and Serving Node; NOT imported directly by the Task Runner.
    responsibilities:
      - Provide Backend/Handle protocols, registry, CLI; enforce CPU serialization contract; shard merge API.
      - Orchestrate ingestion from PDF and Markdown corpora discovered under --corpus-dir, extracting text and metadata (front-matter aware).
    interfaces:
      cli:
        command: "vectordb-builder"
        subcommands:
          - { name: "build", flags_ref: vectordb_builder }
          - { name: "merge", flags_ref: vectordb_builder }
      python:
        protocols:
          - { name: Backend, methods: [capabilities, build] }
          - { name: Handle,  methods: [requires_training, train, add, search, ntotal, serialize_cpu, to_gpu, merge_with, spec] }
        registry: { module: "ragcore.registry", functions: [register, get, list_backends] }
    data_contracts:
      index_layout:
        index_bin: "index.bin"
        index_spec_json: "index_spec.json"
        docmap_json: "docmap.json"
        shards_dir: "shards/"
      corpus_input:
        description: "Files discovered under --corpus-dir; PDFs and Markdown are supported."
        formats:
          pdf: "Extract text and document metadata when available."
          md: "Extract Markdown content; parse optional front-matter (YAML or key:value headers) above a '---' delimiter."
    dependencies: [numpy]
    observability:
      metrics: [shards_merged_total, index_serialize_seconds, index_deserialize_seconds]
      logs: [backend_selected, shard_merge_started, shard_merge_completed]
    risks:
      - cross-version_handle_incompatibility

  - id: vector_backend_faiss
    phase: P0
    title: FAISS Backend (C++ + pybind11)
    description: Flat, IVF-Flat, IVFPQ (CPU) with optional GPU serve; robust merge for flat; IVF merge requiring identical codebooks else reassign/re-encode.
    responsibilities:
      - Train/add/search; serialize CPU; to_gpu(); merge_with() across shards.
    interfaces:
      cxx:
        classes:
          - { name: ragcore::IIndex, methods: [requires_training, train, add, search, ntotal, spec, serialize_cpu, merge_with, to_gpu] }
      python:
        protocols:
          - { name: Handle, methods: [train, add, search, serialize_cpu, to_gpu, merge_with] }
    dependencies: [faiss, openmp, pybind11]
    observability:
      metrics: [faiss_build_seconds, faiss_add_vectors_total, faiss_search_request_duration_seconds_bucket, faiss_memory_bytes]
      logs: [faiss_threads, index_kind, metric, params]
    risks:
      - ivf_pq_merge_requires_matching_codebooks
      - cuda_vendor_lock_in

  - id: vector_backend_hnsw
    phase: P1
    title: HNSW Backend (HNSWlib)
    description: HNSW index via HNSWlib; merge via reinsertion; CPU serialization.
    responsibilities:
      - Add/search; serialize CPU; merge by reinserting shard vectors.
    interfaces:
      cxx:
        classes:
          - { name: ragcore::IIndex, methods: [add, search, ntotal, spec, serialize_cpu, merge_with] }
    dependencies: [hnswlib]
    observability:
      metrics: [hnsw_add_vectors_total, hnsw_search_request_duration_seconds_bucket, hnsw_memory_bytes]
      logs: [hnsw_params]
    risks:
      - true_graph_merge_nontrivial

  - id: vector_backend_cuvs
    phase: P1
    title: GPU Backend (RAFT/cuVS)
    description: IVF-Flat/IVF-PQ on GPU; CPU-serialize via FAISS interop or custom dump; merge via CPU path then re-upload.
    responsibilities:
      - Train/add/search on GPU; serialize to CPU; merge via CPU fallback.
    interfaces:
      cxx:
        classes:
          - { name: ragcore::IIndex, methods: [to_gpu, serialize_cpu, merge_with] }
    dependencies: [raft_cuvs, cuda_toolkit]
    observability:
      metrics: [cuvs_build_seconds, cuvs_search_request_duration_seconds_bucket, cuvs_gpu_memory_bytes]
      logs: [cuda_device, nlist, nprobe, pq_m, pq_bits]
    risks:
      - gpu_driver_compat
      - limited_cross_vendor_support

  - id: adapter_milvus
    phase: P1
    title: Milvus Adapter (External DB)
    description: Out-of-process adapter via gRPC/HTTP to Milvus; maps IndexSpec; handles add/search/serialize via export.
    responsibilities:
      - Translate build/add/search/merge to Milvus; manage collection/index params; export/import where possible.
    interfaces:
      adapters:
        - { name: milvus_grpc_client, tool: vector_index, transport: grpc }
      endpoints_http:
        - { method: POST, path: "/adapter/milvus/search" }
    dependencies: [pymilvus, grpcio]
    observability:
      metrics: [milvus_requests_total, milvus_request_duration_seconds_bucket]
      logs: [milvus_collection, milvus_index_params]
    risks:
      - provider_api_compat_changes
      - data_export_limitations

  - id: adapter_qdrant
    phase: P1
    title: Qdrant Adapter (External DB)
    description: Out-of-process adapter via HTTP to Qdrant; supports HNSW and filters; bridges to our Search schema.
    responsibilities:
      - Translate add/search; manage collections; map filters/metadata; approximate serialize via collection dump.
    interfaces:
      adapters:
        - { name: qdrant_http_client, tool: vector_index, transport: http }
      endpoints_http:
        - { method: POST, path: "/adapter/qdrant/search" }
    dependencies: [qdrant-client, httpx]
    observability:
      metrics: [qdrant_requests_total, qdrant_request_duration_seconds_bucket]
      logs: [qdrant_collection, qdrant_index_params]
    risks:
      - dump_format_nonportable
      - filter_semantics_mismatch

  - id: research_collector
    phase: P1
    title: Research Collector CLI
    description: Scrape → manifest.json → download scripts → match/enrich → corpus export (jsonl + pdfs). Standalone project; not part of Task Runner/MCP codebase.
    repository: "git+ssh://example.com/your-org/research-collector.git"
    artifacts_out: ["collector/manifest.json", "collector/corpus.jsonl", "collector/pdfs/"]
    responsibilities:
      - Build manifest, download PDFs/Markdown, enrich metadata, export corpus for indexing.
    interfaces:
      cli:
        command: "research-collector"
        subcommands:
          - { name: "scrape" }
          - { name: "emit-downloads" }
          - { name: "match-enrich" }
    data_contracts:
      manifest_json: "collector/manifest.schema.json"
      corpus_jsonl: "collector/corpus.schema.json"
      markdown_front_matter:
        description: "When Markdown has front-matter, prefer YAML; otherwise support key:value header blocks above a '---' delimiter."
        precedence: "Front-matter keys override embedded metadata fields."
    dependencies: [aria2c, jdownloader, pypdf_or_pymupdf]
    observability:
      logs: [download_success_rate, metadata_completion_rate]
    risks:
      - site_html_variability

  - id: observability_ci
    phase: P0
    title: Observability & CI
    description: Structured logs, JSONL traces, lint/type/test pipelines, conformance tests.
    responsibilities:
      - Enforce naming/style, schema validation, MCP conformance, DSL lints.
    interfaces:
      ci:
        github_actions: ["lint", "typecheck", "unit", "integration", "e2e", "mcp_conformance"]
    dependencies: [ruff, mypy, yamllint, pytest, coverage, clang-format, clang-tidy]
    observability:
      logs: [ci_step, status, duration_ms]
    metrics: [tests_green_total, conformance_pass_total, style_pass_total]
    risks:
      - flakiness_if_external_network

tool_registry:
  gpt:
    type: llm
    model: gpt-5
    tags: [llm, analysis]
    pricing: { input_per_1k_tokens_usd: 0.002, output_per_1k_tokens_usd: 0.006 }

  web_search:
    type: mcp
    name: "mcp.tool:web.search.query"
    tags: [search, external]
    pricing: { per_call_usd: 0.003 }

  vector_query:
    type: mcp
    name: "mcp.tool:vector.query.search"
    tags: [retrieve, internal]
    pricing: { per_call_usd: 0.0005 }

  docs_load:
    type: mcp
    name: "mcp.tool:docs.load.fetch"
    tags: [ingest]
    pricing: { per_call_usd: 0.0005 }

  citations_audit:
    type: mcp
    name: "mcp.tool:citations.audit.check"
    tags: [quality, citations]
    pricing: { per_call_usd: 0.001 }

  exports_render:
    type: mcp
    name: "mcp.tool:exports.render.markdown"
    tags: [render, export]
    pricing: { per_call_usd: 0.0002 }

  planner_multi_perspective:
    type: mcp
    name: "mcp.tool:planner.multi_perspective"
    tags: [planning]
    pricing: { per_call_usd: 0.0003 }

  hitl_outline_review:
    type: mcp
    name: "mcp.tool:hitl.outline_review"
    tags: [hitl, review]
    pricing: { per_call_usd: 0.0002 }

  hitl_questions_merge:
    type: mcp
    name: "mcp.tool:hitl.questions_merge"
    tags: [hitl, merge]
    pricing: { per_call_usd: 0.0002 }

  research_execute:
    type: mcp
    name: "mcp.tool:research.execute"
    tags: [research, pipeline]
    pricing: { per_call_usd: 0.002 }

# Policy tool sets (used by DSL policies)
tool_sets:
  search_only: [web_search]
  retrieval_only: [vector_query]
  analysis_only: [gpt]
  safe_internal: [vector_query, gpt]
  planning_set: [planner_multi_perspective]
  hitl_set: [hitl_outline_review, hitl_questions_merge]
  publishing_set: [exports_render, citations_audit]

# Naming & style (readability-first guardrails)
style_guide:
  python:
    classes: PascalCase
    functions: snake_case
    variables: snake_case
  cpp:
    types_enums: PascalCase
    methods_vars: snake_case
  yaml_json:
    keys: snake_case
  cli_flags:
    case: kebab-case
  boolean_prefixes: [is_, has_, can_, should_]

# Open decisions to resolve later (keep adding)
open_decisions:
  - id: shell_transform_policy
    question: Allow shell transforms in P0?
    options: [disallow, allow_opt_in_flag, allow_sandboxed]
    default: allow_opt_in_flag
  - id: loop_time_limits
    question: Enforce wall-clock per loop/node in P0?
    options: [no, yes_hard, yes_soft_warn]
    default: no
  - id: filter_dsl
    question: Filter expression grammar for metadata-aware search?
    options: [json_ops_minimal, cel_expression, mongo_style]
    default: json_ops_minimal
  - id: rest_streaming_policy
    question: Stream long /v1/research runs over SSE/WS?
    options: [sync_only, sse_optional, websocket_optional]
    default: sse_optional
  - id: subprocess_limits
    question: Enforce CPU/RAM caps on Toolpacks?
    options: [none, soft_limits, cgroups]
    default: soft_limits
  - id: nondeterministic_tools
    question: How to handle tools marked deterministic:false?
    options: [bypass_cache_warn, block_in_ci, allow_with_tag]
    default: bypass_cache_warn
  - id: markdown_front_matter_precedence
    question: If both embedded metadata and front-matter exist, which wins?
    options: [front_matter_overrides, prefer_embedded_metadata, merge_with_priority_front_matter]
    default: front_matter_overrides
  - id: flowscript_parser_engine
    question: Which runtime parses FlowScript in P1?
    options: [peggy_node_subprocess, lark_python_inproc, tree_sitter_subprocess]
    default: peggy_node_subprocess
  - id: flowscript_error_surface
    question: How to surface parse/compile errors?
    options: [stderr_plain, envelope_structured, yaml_problem_markers]
    default: envelope_structured
  - id: flowscript_expr_interp
    question: Expression semantics inside Expr strings?
    options: [pass_through, jinja_eval_at_runtime, limited_expr_eval_at_compile]
    default: pass_through

# Test matrix (high-level)
tests:
  unit:
    - dsl_policy_resolution
    - budget_meter_limits
    - adapter_cost_estimation
    - registry_capabilities
    - toolpack_loader_resolves_refs
    - envelope_schema_validation
    - connectors_offline_normalization
    - hybrid_scoring_tie_breaks
    - reranker_fallback_scoring
    - perspectives_determinism_and_diversity
    - mindmap_roundtrip
    - hitl_outline_validation_and_merge
    - publisher_bibliography_contains_all_citations
  e2e:
    - mcp_http_and_stdio_conformance
    - rest_parity_endpoints
    - retrieval_ndcg_fixture_improves
    - planner_outline_hitl_flow
    - agents_parallel_speedup_and_dedupe
    - vectordb_build_and_search_small_fixture
    - vectordb_build_md_fixture
  ci:
    coverage_minimum: 85
