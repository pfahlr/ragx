{
  "documents": [
    {
      "format": "md",
      "id": "PSY0005_Autopoiesis",
      "metadata": {
        "source_format": "md",
        "source_path": "/tmp/corpus_split_psychology/shard_001/PSY0005_Autopoiesis.md",
        "source_relpath": "PSY0005_Autopoiesis.md"
      },
      "path": "PSY0005_Autopoiesis.md",
      "text": "# Autopoiesis\n\nThe term autopoiesis (from Greek  \u03b1\u1f50\u03c4o- (auto) 'self' and  \u03c0\u03bf\u03af\u03b7\u03c3\u03b9\u03c2 (poiesis) 'creation, production'), one of several current theories of life, refers to a system capable of producing and maintaining itself by creating its own parts.\nThe term was introduced in the 1972 publication Autopoiesis and Cognition: The Realization of the Living  by Chilean biologists Humberto Maturana and Francisco Varela to define the self-maintaining chemistry of living cells.\nThe concept has since been applied to the fields of cognition, neurobiology, systems theory, architecture and sociology. Niklas Luhmann briefly introduced the concept of autopoiesis to organizational theory.\n\n\n## Overview\n\nIn their 1972 book Autopoiesis and Cognition, Chilean biologists Maturana and Varela described how they invented the word autopoiesis.\n\n\"It was in these circumstances ... in which he analyzed Don Quixote's dilemma of whether to follow the path of arms (praxis, action) or the path of letters (poiesis, creation, production), I understood for the first time the power of the word \"poiesis\" and invented the word that we needed: autopoiesis. This was a word without a history, a word that could directly mean what takes place in the dynamics of the autonomy proper to living systems.\"\nThey explained that,\n\n\"An autopoietic machine is a machine organized (defined as a unity) as a network of processes of production (transformation and destruction) of components which: (i) through their interactions and transformations continuously regenerate and realize the network of processes (relations) that produced them; and (ii) constitute it (the machine) as a concrete unity in space in which they (the components) exist by specifying the topological domain of its realization as such a network.\"\nThey described the \"space defined by an autopoietic system\" as \"self-contained\", a space that \"cannot be described by using dimensions that define another space. When we refer to our interactions with a concrete autopoietic system, however, we project this system on the space of our manipulations and make a description of this projection.\"\n\n\n## Meaning\n\nAutopoiesis was originally presented as a system description that was said to define and explain the nature of living systems. A canonical example of an autopoietic system is the biological cell. The eukaryotic cell, for example, is made of various biochemical components such as nucleic acids and proteins, and is organized into bounded structures such as the cell nucleus, various organelles, a cell membrane and cytoskeleton. These structures, based on an internal flow of molecules and energy, produce the components which, in turn, continue to maintain the organized bounded structure that gives rise to these components.\nAn autopoietic system is to be contrasted with an allopoietic system, such as a car factory, which uses raw materials (components) to generate a car (an organized structure) which is something other than itself (the factory). However, if the system is extended from the factory to include components in the factory's \"environment\", such as supply chains, plant / equipment, workers, dealerships, customers, contracts, competitors, cars, spare parts, and so on, then as a total viable system it could be considered to be autopoietic.\nOf course, cells also require raw materials (nutrients), and produce numerous products -waste products, the extracellular matrix, intracellular messaging molecules, etc.\nAutopoiesis in biological systems can be viewed as a network of constraints that work to maintain themselves. This concept has been called organizational closure or constraint closure and is closely related to the study of autocatalytic chemical networks where constraints are reactions required to sustain life.\nThough others have often used the term as a synonym for self-organization, Maturana himself stated he would \"[n]ever use the notion of self-organization ... Operationally it is impossible. That is, if the organization of a thing changes, the thing changes\". Moreover, an autopoietic system is autonomous and operationally closed, in the sense that there are sufficient processes within it to maintain the whole. Autopoietic systems are \"structurally coupled\" with their medium, embedded in a dynamic of changes that can be recalled as sensory-motor coupling. This continuous dynamic is considered as a rudimentary form of knowledge or cognition and can be observed throughout life-forms.\nAn application of the concept of autopoiesis to sociology can be found in Niklas Luhmann's Systems Theory, which was subsequently adapted by Bob Jessop in his studies of the capitalist state system. Marjatta Maula adapted the concept of autopoiesis in a business context. The theory of autopoiesis has also been applied in the context of legal systems by not only Niklas Luhmann, but also Gunther Teubner. Patrik Schumacher has applied the term to refer to the 'discursive self-referential making of architecture.'  Varela eventually further applied autopoesis to develop models of mind, brain, and behavior called non-representationalist, enactive, embodied cognitive neuroscience, culminating in neurophenomenology.\nIn the context of textual studies, Jerome McGann argues that texts are \"autopoietic mechanisms operating as self-generating feedback systems that cannot be separated from those who manipulate and use them\". Citing Maturana and Varela, he defines an autopoietic system as \"a closed topological space that 'continuously generates and specifies its own organization through its operation as a system of production of its own components, and does this in an endless turnover of components'\", concluding that \"Autopoietic systems are thus distinguished from allopoietic systems, which are Cartesian and which 'have as the product of their functioning something different from themselves'\". Coding and markup appear allopoietic\", McGann argues, but are generative parts of the system they serve to maintain, and thus language and print or electronic technology are autopoietic systems.\n\nThe philosopher Slavoj \u017di\u017eek, in his discussion of Hegel, argues: \"Hegel is \u2013 to use today's terms \u2013 the ultimate thinker of autopoiesis, of the process of the emergence of necessary features out of chaotic contingency, the thinker of contingency's gradual self-organisation, of the gradual rise of order out of chaos.\"\n\n\n## Relation to complexity\n\nAutopoiesis can be defined as the ratio between the complexity of a system and the complexity of its environment.\n\nThis generalized view of autopoiesis considers systems as self-producing not in terms of their physical components, but in terms of its organization, which can be measured in terms of information and complexity. In other words, we can describe autopoietic systems as those producing more of their own complexity than the one produced by their environment.\nAutopoiesis has been proposed as a potential mechanism of abiogenesis, by which molecules evolved into more complex cells that could support the development of life.\n\n\n### Comparison with other theories of life\nAutopoiesis is just one of several current theories of life, including the chemoton of Tibor G\u00e1nti, the hypercycle of Manfred Eigen and Peter Schuster,\n\n the  (M,R) systems of Robert Rosen, and the autocatalytic sets of Stuart Kauffman, similar to an earlier proposal by Freeman Dyson. \nAll of these (including autopoiesis) found their original inspiration in Erwin Schr\u00f6dinger's book What is Life? but at first they appear to have little in common with one another, largely because the authors did not communicate with one another, and none of them made any reference in their principal publications to any of the other theories.  Nonetheless, there are more similarities than may be obvious at first sight, for example between G\u00e1nti and Rosen. Until recently there have been almost no attempts to compare the different theories and discuss them together.\n\n\n## Relation to cognition\n\nAn extensive discussion of the connection of autopoiesis to cognition is provided by Evan Thompson in his 2007 publication, Mind in Life. The basic notion of autopoiesis as involving constructive interaction with the environment is extended to include cognition. Initially, Maturana defined cognition as behavior of an organism \"with relevance to the maintenance of itself\". However, computer models that are self-maintaining but non-cognitive have been devised, so some additional restrictions are needed, and the suggestion is that the maintenance process, to be cognitive, involves readjustment of the internal workings of the system in some metabolic process. On this basis it is claimed that autopoiesis is a necessary but not a sufficient condition for cognition. Thompson wrote that this distinction may or may not be fruitful, but what matters is that living systems involve autopoiesis and (if it is necessary to add this point) cognition as well. It can be noted that this definition of 'cognition' is restricted, and does not necessarily entail any awareness or consciousness by the living system. With the publication of The Embodied Mind in 1991, Varela, Thompson and Rosch applied autopoesis to make non-representationalist, and enactive models of mind, brain and behavior, which further developed embodied cognitive neuroscience, later culminating in neurophenomenology.\n\n\n## Relation to consciousness\n\nThe connection of autopoiesis to cognition, or if necessary, of living systems to cognition, is an objective assessment ascertainable by observation of a living system.\nOne question that arises is about the connection between cognition seen in this manner and consciousness. The separation of cognition and consciousness recognizes that the organism may be unaware of the substratum where decisions are made. What is the connection between these realms? Thompson refers to this issue as the \"explanatory gap\", and one aspect of it is the hard problem of consciousness, how and why we have qualia.\nA second question is whether autopoiesis can provide a bridge between these concepts. Thompson discusses this issue from the standpoint of enactivism. An autopoietic cell actively relates to its environment. Its sensory responses trigger motor behavior governed by autopoiesis, and this behavior (it is claimed) is a simplified version of a nervous system behavior. The further claim is that real-time interactions like this require attention, and an implication of attention is awareness.\n\n\n## Criticism\n\nThere are multiple criticisms of the use of the term in both its original context, as an attempt to define and explain the living, and its various expanded usages, such as applying it to self-organizing systems in general or social systems in particular. Critics have argued that the concept and its theory fail to define or explain living systems and that, because of the extreme language of self-referentiality it uses without any external reference, it is really an attempt to give substantiation to Maturana's radical constructivist or solipsistic epistemology, or what Danilo Zolo has called instead a \"desolate theology\". An example is the assertion by Maturana and Varela that \"We do not see what we do not see and what we do not see does not exist\".\nAccording to Razeto-Barry, the influence of Autopoiesis and Cognition: The Realization of the Living in mainstream biology has proven to be limited. Razeto-Barry believes that autopoiesis is not commonly used as the criterion for life.\nZoologist and philosopher Donna Haraway also criticizes the usage of the term, arguing that \"nothing makes itself; nothing is really autopoietic or self-organizing\", and suggests the use of sympoiesis, meaning \"making-with\", instead.\n\n\n## See also\n\n\n\n## References\n\n\n\n## Further reading\n\n\n\n## External links\n\n",
      "vector_count": 1,
      "vector_offset": 0
    },
    {
      "format": "md",
      "id": "PSY0006_Broca_s_area",
      "metadata": {
        "source_format": "md",
        "source_path": "/tmp/corpus_split_psychology/shard_001/PSY0006_Broca_s_area.md",
        "source_relpath": "PSY0006_Broca_s_area.md"
      },
      "path": "PSY0006_Broca_s_area.md",
      "text": "# Broca's_area\n\nBroca's area, or the Broca area (, also UK: , US: ), is a region in the frontal lobe of the dominant hemisphere, usually the left, of the brain with functions linked to speech production.\nLanguage processing has been linked to Broca's area since Pierre Paul Broca reported impairments in two patients. They had lost the ability to speak after injury to the posterior inferior frontal gyrus (pars triangularis) (BA45) of the brain. Since then, the approximate region he identified has become known as Broca's area, and the deficit in language production as Broca's aphasia, also called expressive aphasia. Broca's area is now typically defined in terms of the pars opercularis and pars triangularis of the inferior frontal gyrus, represented in Brodmann's cytoarchitectonic map as Brodmann area 44 and Brodmann area 45 of the dominant hemisphere.\nFunctional magnetic resonance imaging (fMRI) has shown language processing to also involve the third part of the inferior frontal gyrus the pars orbitalis, as well as the ventral part of BA6 and these are now often included in a larger area called Broca's region.\nStudies of chronic aphasia have implicated an essential role of Broca's area in various speech and language functions. Further, fMRI studies have also identified activation patterns in Broca's area associated with various language tasks. However, slow destruction of Broca's area by brain tumors can leave speech relatively intact, suggesting its functions can shift to nearby areas in the brain.\n\n\n## Structure\n\n\nBroca's area is often identified by visual inspection of the topography of the brain either by macrostructural landmarks such as sulci or by the specification of coordinates in a particular reference space. The currently used Talairach and Tournoux atlas projects Brodmann's cytoarchitectonic map onto a template brain. Because Brodmann's parcelation was based on subjective visual inspection of cytoarchitectonic borders and also Brodmann analyzed only one hemisphere of one brain, the result is imprecise. Further, because of considerable variability across brains in terms of shape, size, and position relative to sulcal and gyral structure, a resulting localization precision is limited.\nNevertheless, Broca's area in the left hemisphere and its homologue in the right hemisphere are designations usually used to refer to the triangular part of inferior frontal gyrus (PTr) and the opercular part of inferior frontal gyrus (POp). The PTr and POp are defined by structural landmarks that only probabilistically divide the inferior frontal gyrus into anterior and posterior cytoarchitectonic areas of 45 and 44, respectively, by Brodmann's classification scheme.\nArea 45 receives more afferent connections from the prefrontal cortex, the superior temporal gyrus, and the superior temporal sulcus, compared to area 44, which tends to receive more afferent connections from motor, somatosensory, and inferior parietal regions.\nThe differences between area 45 and 44 in cytoarchitecture and in connectivity suggest that these areas might perform different functions. Indeed, recent neuroimaging studies have shown that the PTr and Pop, corresponding to areas 45 and 44, respectively, play different functional roles in the human with respect to language comprehension and action recognition/understanding.\nThe Broca's area is about 20% larger in women than in men.\n\n\n## Functions\n\n\n\n### Language comprehension\nFor a long time, it was assumed that the role of Broca's area was more devoted to language production than language comprehension. However, there is evidence to demonstrate that Broca's area also plays a significant role in language comprehension. Patients with lesions in Broca's area who exhibit agrammatical speech production also show inability to use syntactic information to determine the meaning of sentences. Also, a number of neuroimaging studies have implicated an involvement of Broca's area, particularly of the pars opercularis of the left inferior frontal gyrus, during the processing of complex sentences. Further, functional magnetic resonance imaging (fMRI) experiments have shown that highly ambiguous sentences result in a more activated inferior frontal gyrus. Therefore, the activity level in the inferior frontal gyrus and the level of lexical ambiguity are directly proportional to each other, because of the increased retrieval demands associated with highly ambiguous content.\nThere is also specialisation for particular aspects of comprehension within Broca's area. Work by Devlin et al. (2003) showed in a repetitive transcranial magnetic stimulation (rTMS) study that there was an increase in reaction times when performing a semantic task under rTMS aimed at the pars triangularis (situated in the anterior part of Broca's area). The increase in reaction times is indicative that that particular area is responsible for processing that cognitive function. Disrupting these areas via TMS disrupts computations performed in the areas leading to an increase in time needed to perform the computations (reflected in reaction times). Later work by Nixon et al. (2004) showed that when the pars opercularis (situated in the posterior part of Broca's area) was stimulated under rTMS there was an increase in reaction times in a phonological task. Gough et al. (2005) performed an experiment combining elements of these previous works in which both phonological and semantic tasks were performed with rTMS stimulation directed at either the anterior or the posterior part of Broca's area. The results from this experiment conclusively distinguished anatomical specialisation within Broca's area for different components of language comprehension. Here the results showed that under rTMS stimulation: \n\nSemantic tasks only showed a decrease in reaction times when stimulation was aimed at the anterior part of Broca's area (where a decrease of 10% (50 ms) was seen compared to a no-TMS control group)\nPhonological tasks showed a decrease in reaction times when stimulation was aimed at the posterior part of Broca's area (where a decrease of 6% (30 ms) was seen compared to control)\nTo summarise, the work above shows anatomical specialisation in Broca's area for language comprehension, with the anterior part of Broca's area responsible for understanding the meaning of words (semantics) and the posterior part of Broca's area responsible for understanding how words sound (phonology).\n\n\n### Action recognition and production\nExperiments have indicated that Broca's area is involved in various cognitive and perceptual tasks. One important contribution of Brodmann's area 44 is also found in the motor-related processes. Observation of meaningful hand shadows resembling moving animals activates frontal language area, demonstrating that Broca's area indeed plays a role in interpreting action of others. An activation of BA 44 was also reported during execution of grasping and manipulation.\n\n\n### Speech-associated gestures\nIt has been speculated that because speech-associated gestures could possibly reduce lexical or sentential ambiguity, comprehension should improve in the presence of speech-associated gestures. As a result of improved comprehension, the involvement of Broca's area should be reduced.\nMany neuroimaging studies have also shown activation of Broca's area when representing meaningful arm gestures. A recent study has shown evidence that word and gesture are related at the level of translation of particular gesture aspects such as its motor goal and intention. This finding helps explain why, when this area is defective, those who use sign language also have language deficits. This finding, that aspects of gestures are translated in words within Broca's area, also explains language development in terms of evolution. Indeed, many authors have proposed that speech evolved from a primitive communication that arose from gestures. (See below.)\n\n\n### Speaking without Broca's area\nDamage to Broca's area is commonly associated with telegraphic speech made up of content vocabulary. For example, a person with Broca's aphasia may say something like, \"Drive, store. Mom.\" meaning to say, \"My mom drove me to the store today.\" Therefore, the content of the information is correct, but the grammar and fluidity of the sentence is missing.\nThe essential role of the Broca's area in speech production has been questioned since it can be destroyed while leaving language nearly intact. In one case of a computer engineer, a slow-growing glioma tumor was removed. The tumor and the surgery destroyed the left inferior and middle frontal gyrus, the head of the caudate nucleus, the anterior limb of the internal capsule, and the anterior insula. However, there were minimal language problems three months after removal and the individual returned to his professional work. These minor problems include the inability to create syntactically complex sentences including more than two subjects, multiple causal conjunctions, or reported speech. These were explained by researchers as due to working memory problems. They also attributed his lack of problems to extensive compensatory mechanisms enabled by neural plasticity in the nearby cerebral cortex and a shift of some functions to the homologous area in the right hemisphere.\n\n\n## Clinical significance\n\n\n\n### Stuttering\nA speech disorder known as stuttering is seen to be associated with underactivity in Broca's area.\n\n\n### Aphasia\nAphasia is an acquired language disorder affecting all modalities such as writing, reading, speaking, and listening and results from brain damage. It is often a chronic condition that creates changes in all areas of one's life.\n\n\n### Expressive aphasia vs. other aphasias\nPatients with expressive aphasia, also known as Broca's aphasia, are individuals who know \"what they want to say, they just cannot get it out\". They are typically able to comprehend words, and sentences with a simple syntactic structure (see above), but are more or less unable to generate fluent speech. Other symptoms that may be present include problems with fluency, articulation, word-finding, word repetition, and producing and comprehending complex grammatical sentences, both orally and in writing.\nThis specific group of symptoms distinguishes those who have expressive aphasia from individuals with other types of aphasia. There are several distinct \"types\" of aphasia, and each type is characterized by a different set of language deficits. Although those who have expressive aphasia tend to retain good spoken language comprehension, other types of aphasia can render patients completely unable to understand any language at all, unable to understand any spoken language (auditory verbal agnosia), whereas still other types preserve language comprehension, but with deficits. People with expressive aphasia may struggle less with reading and writing (see alexia) than those with other types of aphasia. Although individuals with expressive aphasia tend to have a good ability to self-monitor their language output (they \"hear what they say\" and make corrections), other types of aphasics can seem entirely unaware of their language deficits.\nIn the classical sense, expressive aphasia is the result of injury to Broca's area; it is often the case that lesions in specific brain areas cause specific, dissociable symptoms, although case studies show there is not always a one-to-one mapping between lesion location and aphasic symptoms. The correlation between damage to certain specific brain areas (usually in the left hemisphere) and the development of specific types of aphasia makes it possible to deduce (albeit very roughly) the location of a suspected brain lesion based only on the presence (and severity) of a certain type of aphasia, though this is complicated by the possibility that a patient may have damage to a number of brain areas and may exhibit symptoms of more than one type of aphasia. The examination of lesion data in order to deduce which brain areas are essential in the normal functioning of certain aspects of cognition is called the deficit-lesion method; this method is especially important in the branch of neuroscience known as aphasiology. Cognitive science \u2013 to be specific, cognitive neuropsychology \u2013 are branches of neuroscience that also make extensive use of the deficit-lesion method.\n\n\n### Newer implications related to lesions in Broca's area\nSince studies carried out in the late 1970s it has been understood that the relationship between Broca's area and Broca's aphasia is not as consistent as once thought. Lesions to Broca's area alone do not result in Broca's aphasia, nor do Broca's aphasic patients necessarily have lesions in Broca's area. Lesions to Broca's area alone are known to produce a transient mutism that resolves within 3\u20136 weeks. This discovery suggests that Broca's area may be included in some aspect of verbalization or articulation; however, this does not address its part in sentence comprehension. Still, Broca's area frequently emerges in functional imaging studies of sentence processing. However, it also becomes activated in word-level tasks. This suggests that Broca's area is not dedicated to sentence processing alone, but supports a function common to both. In fact, Broca's area can show activation in such non-linguistic tasks as imagery of motion.\nConsidering the hypothesis that Broca's area may be most involved in articulation, its activation in all of these tasks may be due to subjects' covert articulation while formulating a response. Despite this caveat, a consensus seems to be forming that whatever role Broca's area may play, it may relate to known working memory functions of the frontal areas. (There is a wide distribution of Talairach coordinates reported in the functional imaging literature that are referred to as part of Broca's area.) The processing of a passive voice sentence, for example, may require working memory to assist in the temporary retention of information while other relevant parts of the sentence are being manipulated (i.e. to resolve the assignment of thematic roles to arguments). Miyake, Carpenter, and Just have proposed that sentence processing relies on such general verbal working memory mechanisms, while Caplan and Waters consider Broca's area to be involved in working memory specifically for syntactic processing. Friederici (2002) breaks Broca's area into its component regions and suggests that Brodmann's area 44 is involved in working memory for both phonological and syntactic structure. This area becomes active first for phonology and later for syntax as the time course for the comprehension process unfolds. Brodmann's area 45 and Brodmann's area 47 are viewed as being specifically involved in working memory for semantic features and thematic structure where processes of syntactic reanalysis and repair are required. These areas come online after Brodmann's area 44 has finished its processing role and are active when comprehension of complex sentences must rely on general memory resources. All of these theories indicate a move towards a view that syntactic comprehension problems arise from a computational rather than a conceptual deficit. Newer theories take a more dynamic view of how the brain integrates different linguistic and cognitive components and are examining the time course of these operations.\nNeurocognitive studies have already implicated frontal areas adjacent to Broca's area as important for working memory in non-linguistic as well as linguistic tasks. Cabeza and Nyberg's analysis of imaging studies of working memory supports the view that BA45/47 is recruited for selecting or comparing information, while BA9/46 might be more involved in the manipulation of information in working memory. Since large lesions are typically required to produce a Broca's aphasia, it is likely that these regions may also become compromised in some patients and may contribute to their comprehension deficits for complex morphosyntactic structures.\n\n\n=### Broca's area as a key center in the linking of phonemic sequences=\nBroca's area has been previously associated with a variety of processes, including phonological segmentation, syntactic processing, and unification, all of which involve segmenting and linking different types of linguistic information. Although repeating and reading single words does not engage semantic and syntactic processing, it does require an operation linking phonemic sequences with motor gestures. Findings indicate that this linkage is coordinated by Broca's area through reciprocal interactions with temporal and frontal cortices responsible for phonemic and articulatory representations, respectively, including interactions with the motor cortex before the actual act of speech. Based on these unique findings, it has been proposed that Broca's area is not the seat of articulation, but rather is a key node in manipulating and forwarding neural information across large-scale cortical networks responsible for key components of speech production.\n\n\n## History\n\nIn a study published in 2007, the preserved brains of both Leborgne and Lelong (patients of Broca) were reinspected using high-resolution volumetric MRI. The purpose of this study was to scan the brains in three dimensions and to identify the extent of both cortical and subcortical lesions in more detail. The study also sought to locate the exact site of the lesion in the frontal lobe in relation to what is now called Broca's area with the extent of subcortical involvement.\n\n\n### Broca's patients\n\n\n=### Louis Victor Leborgne (Tan)=\nLeborgne was a patient of Broca's. At 30 years old, he was almost completely unable to produce any words or phrases. He was able to repetitively produce only the word temps (French word for \"time\"). After his death, a neurosyphilitic lesion was discovered on the surface of his left frontal lobe.\n\n\n=### Lelong=\nLelong was another patient of Broca's. He also exhibited reduced productive speech. He could only say five words, 'yes', 'no', 'three', 'always', and 'lelo' (a mispronunciation of his own name). A lesion within the lateral frontal lobe was discovered during Lelong's autopsy. Broca's previous patient, Leborgne, had a lesion in the same area of his frontal lobe. These two cases led Broca to believe that speech was localized to this particular area.\n\n\n### MRI findings\nExamination of the brains of Broca's two historic patients with high-resolution MRI has produced several interesting findings. First, the MRI findings suggest that other areas besides Broca's area may also have contributed to the patients' reduced productive speech. This finding is significant because it has been found that, though lesions to Broca's area alone can possibly cause temporary speech disruption, they do not result in severe speech arrest. Therefore, there is a possibility that the aphasia denoted by Broca as an absence of productive speech also could have been influenced by the lesions in the other region. Another finding is that the region, which was once considered to be critical for speech by Broca, is not precisely the same region as what is now known as Broca's area. This study provides further evidence to support the claim that language and cognition are far more complicated than once thought and involve various networks of brain regions.\n\n\n## Evolution of language\n\nThe pursuit of a satisfying theory that addresses the origin of language in humans has led to the consideration of a number of evolutionary \"models\". These models attempt to show how modern language might have evolved, and a common feature of many of these theories is the idea that vocal communication was initially used to complement a far more dominant mode of communication through gesture. Human language might have evolved as the \"evolutionary refinement of an implicit communication system already present in lower primates, based on a set of hand/mouth goal-directed action representations.\"\n\"Hand/mouth goal-directed action representations\" is another way of saying \"gestural communication\", \"gestural language\", or \"communication through body language\". The recent finding that Broca's area is active when people are observing others engaged in meaningful action is evidence in support of this idea. It was hypothesized that a precursor to the modern Broca's area was involved in translating gestures into abstract ideas by interpreting the movements of others as meaningful action with an intelligent purpose. It is argued that over time the ability to predict the intended outcome and purpose of a set of movements eventually gave this area the capability to deal with truly abstract ideas, and therefore (eventually) became capable of associating sounds (words) with abstract meanings. The observation that frontal language areas are activated when people observe hand shadows is further evidence that human language may have evolved from existing neural substrates that evolved for the purpose of gesture recognition. The study, therefore, claims that Broca's area is the \"motor center for speech\", which assembles and decodes speech sounds in the same way it interprets body language and gestures. Consistent with this idea is that the neural substrate that regulated motor control in the common ancestor of apes and humans was most likely modified to enhance cognitive and linguistic ability. Studies of speakers of American Sign Language and English suggest that the human brain recruited systems that had evolved to perform more basic functions much earlier; these various brain circuits, according to the authors, were tapped to work together in creating language.\nAnother recent finding has shown significant areas of activation in subcortical and neocortical areas during the production of communicative manual gestures and vocal signals in chimpanzees. Further, the data indicating that chimpanzees intentionally produce manual gestures as well as vocal signals to communicate with humans suggests that the precursors to human language are present at both the behavioral and neuronanatomical levels. More recently, the neocortical distribution of activity-dependent gene expression in marmosets provided direct evidence that the ventrolateral prefrontal cortex, which comprises Broca's area in humans and has been associated with auditory processing of species-specific vocalizations and orofacial control in macaques, is engaged during vocal output in a New World monkey. These findings putatively set the origin of vocalization-related neocortical circuits to at least 35 million years ago, when the Old and New World monkey lineages split.\n\n\n## Additional images\n\n\n\n## See also\n\nLobes of the brain\nProgressive nonfluent aphasia\nWernicke's area\nJerome of Sandy Cove\n\n\n## References\n\n\n\n## External links\n\n",
      "vector_count": 1,
      "vector_offset": 1
    },
    {
      "format": "md",
      "id": "PSY0007_Brodmann_area",
      "metadata": {
        "source_format": "md",
        "source_path": "/tmp/corpus_split_psychology/shard_001/PSY0007_Brodmann_area.md",
        "source_relpath": "PSY0007_Brodmann_area.md"
      },
      "path": "PSY0007_Brodmann_area.md",
      "text": "# Brodmann_area\n\nA Brodmann area is a region of the cerebral cortex, in the human or other primate brain, defined by its cytoarchitecture, or histological structure and organization of cells. The concept was first introduced by the German anatomist Korbinian Brodmann in the early 20th century. Brodmann mapped the human brain based on the varied cellular structure across the cortex and identified 52 distinct regions, which he numbered 1 to 52. These regions, or Brodmann areas, correspond with diverse functions including sensation, motor control, and cognition.\n\n\n## History\n\nBrodmann areas were originally defined and numbered by the German anatomist Korbinian Brodmann based on the cytoarchitectural organization of neurons he observed in the cerebral cortex using the Nissl method of cell staining. Brodmann published his maps of cortical areas in humans, monkeys, and other species in 1909, along with many other findings and observations regarding the general cell types and laminar organization of the mammalian cortex. The same Brodmann area number in different species does not necessarily indicate homologous areas. A similar, but more detailed cortical map was published by Constantin von Economo and Georg N. Koskinas in 1925.\n\n\n## Present importance\n\nBrodmann areas have been discussed, debated, refined, and renamed exhaustively for nearly a century and remain the most widely known and frequently cited cytoarchitectural organization of the human cortex. Many of the areas Brodmann defined based solely on their neuronal organization have since been correlated closely to diverse cortical functions. For example, Brodmann areas 1, 2 and 3 are the primary somatosensory cortex; area 4 is the primary motor cortex; area 17 is the primary visual cortex; and areas 41 and 42 correspond closely to primary auditory cortex. Higher order functions of the association cortical areas are also consistently localized to the same Brodmann areas by neurophysiological, functional imaging, and other methods (e.g., the consistent localization of Broca's speech and language area to the left Brodmann areas 44 and 45). However, functional imaging can only identify the approximate localization of brain activations in terms of Brodmann areas since their actual boundaries in any individual brain require its histological examination.\n\n\n## Overview\n\n\nDifferent parts of the cerebral cortex are involved in different cognitive and behavioral functions. The differences show up in a number of ways: the effects of localized brain damage, regional activity patterns exposed when the brain is examined using functional imaging techniques, connectivity with subcortical areas, and regional differences in the cellular architecture of the cortex. The neocortex is divided into six layers, but not all layers are apparent in all areas, and the thickness and cellular organization of a single layer may vary. Maps of cortical areas are constructed on the basis of variations in the appearance of the layers as seen with a microscope. \n\nKorbinian Brodmann created one of the most widely used schemes, splitting the cortex into 52 different areas and assigned each a number (many of these Brodmann areas have since been subdivided). For example, Brodmann area 1 is the primary somatosensory cortex, Brodmann area 17 is the primary visual cortex, and Brodmann area 25 is the anterior cingulate cortex.\nMany of the brain areas defined by Brodmann have their own complex internal structures. In a number of cases, brain areas are organized into topographic maps, where adjoining bits of the cortex correspond to adjoining parts of the body, or of some more abstract entity. A simple example of this type of correspondence is the primary motor cortex, a strip of tissue running along the anterior edge of the central sulcus. Motor areas innervating each part of the body arise from a distinct zone, with neighboring body parts represented by neighboring zones. Electrical stimulation of the cortex at any point causes a muscle-contraction in the represented body part. This \"somatotopic\" representation is not evenly distributed, however; the head, for example, is represented by a region about three times as large as the zone for the entire back and trunk. The size of any zone correlates to the precision of motor control and sensory discrimination possible. The areas for the lips, fingers, and tongue are particularly large, considering the proportional size of their represented body parts.\nThe maps for visual areas are retinotopic(reflecting the topography of the retina). This representation is uneven, with the fovea (the area at the center of the visual field) overrepresented compared to the periphery. The visual circuitry in the human cerebral cortex contains several dozen distinct retinotopic maps, each devoted to analyzing the visual input stream in a particular way. The primary visual cortex (Brodmann area 17) contains many neurons that are most easily activated by edges with a particular orientation moving across a particular point in the visual field. Visual areas farther downstream extract features such as color, motion, and shape.\nIn auditory areas, the primary map is tonotopic. Sounds are parsed according to frequency (i.e., high pitch vs. low pitch) by subcortical auditory areas, and this parsing is reflected by the primary auditory zone of the cortex. As with the visual system, there are a number of tonotopic cortical maps, each devoted to analyzing sound in a particular way.\nWithin a topographic map there can sometimes be finer levels of spatial structure. In the primary visual cortex, for example, where the main organization is retinotopic and the main responses are to moving edges, cells that respond to different edge-orientations are spatially segregated from one another.\n\n\n## For humans and other primates\n\n\nAreas 3, 1 and 2 \u2013 Primary somatosensory cortex in the postcentral gyrus (frequently referred to as Areas 3, 1, 2 by convention)\nArea 4\u2013 Primary motor cortex\nArea 5 \u2013 Superior parietal lobule\nArea 6 \u2013 Premotor cortex and supplementary motor cortex (secondary motor cortex) (supplementary motor area)\nArea 7 \u2013 Visuo-motor coordination\nArea 8 \u2013 Includes frontal eye fields\nArea 9 \u2013 Dorsolateral prefrontal cortex\nArea 10 \u2013 Anterior prefrontal cortex (most rostral part of superior and middle frontal gyri)\nArea 11 \u2013 Orbitofrontal area (orbital and rectus gyri, plus part of the rostral part of the superior frontal gyrus)\nArea 12 \u2013 Orbitofrontal area (used to be part of BA11, refers to the area between the superior frontal gyrus and the inferior rostral sulcus)\nArea 13 and Area 14* \u2013 Insular cortex\nArea 15* \u2013 Anterior temporal lobe\nArea 16 \u2013 Insular cortex\n Area 17 \u2013 Primary visual cortex (V1)\nArea 18 \u2013 Secondary visual cortex (V2)\nArea 19 \u2013 Associative visual cortex (V3, V4, V5)\nArea 20 \u2013 Inferior temporal gyrus\nArea 21 \u2013 Middle temporal gyrus\nArea 22 \u2013 Part of the superior temporal gyrus, included in Wernicke's area\nArea 23 \u2013 Ventral posterior cingulate cortex\nArea 24 \u2013 Ventral anterior cingulate cortex.\nArea 25 \u2013 Subgenual area (part of the ventromedial prefrontal cortex)\nArea 26 \u2013 Ectosplenial portion of the retrosplenial region of the cerebral cortex\nArea 27 \u2013 Presubiculum\nArea 28 \u2013 Ventral entorhinal cortex\nArea 29 \u2013 Retrosplenial cortex\nArea 30 \u2013 Subdivision of retrosplenial cortex\nArea 31 \u2013 Dorsal posterior cingulate cortex\nArea 32 \u2013 Dorsal anterior cingulate cortex\nArea 33 \u2013 Part of anterior cingulate cortex\nArea 34 \u2013 Dorsal entorhinal cortex (on the parahippocampal gyrus)\nArea 35 \u2013 Part of the perirhinal cortex (in the rhinal sulcus)\nArea 36 \u2013 Part of the perirhinal cortex (in the rhinal sulcus)\n Area 37 \u2013 Fusiform gyrus\nArea 38 \u2013 Temporopolar area (most rostral part of the superior and middle temporal gyri)\nArea 39 \u2013 Angular gyrus, considered by some to be part of Wernicke's area\nArea 40 \u2013 Supramarginal gyrus considered by some to be part of Wernicke's area\nAreas 41 and 42 \u2013 Auditory cortex\nArea 43 \u2013 Primary gustatory cortex\nAreas 44 and 45 \u2013 Broca's area, includes the opercular part and triangular part of the inferior frontal gyrus\nArea 46 \u2013 Dorsolateral prefrontal cortex\nArea 47 \u2013 Orbital part of inferior frontal gyrus\nArea 48 \u2013 Retrosubicular area (a small part of the medial surface of the temporal lobe)\nArea 49 \u2013 Parasubicular area in a rodent\nArea 52 \u2013 Parainsular area (at the junction of the temporal lobe and the insula)\n(*) Area only found in non-human primates.\nSome of the original Brodmann areas have been subdivided further, e.g., \"23a\" and \"23b\".\n\n\n### Clickable map: lateral surface\nNote: the lateral view, or side view, of the brain is denoted the 'lateral surface'\n\n\n### Clickable map: medial surface\nNote: the view of the section between the right and left hemispheres of the brain is denoted the 'medial surface'\n\n\n## Criticism\n\nWhen von Bonin and Bailey constructed a brain map for the macaque monkey, they found the description of Brodmann inadequate and wrote: \"Brodmann (1907), it is true, prepared a map of the human brain which has been widely reproduced, but, unfortunately, the data on which it was based was never published\" They instead used the cytoarchitectonic scheme of Constantin von Economo and Georg N. Koskinas published in 1925 which had the \"only acceptable detailed description of the human cortex\".\n\n\n## See also\n\nList of regions in the human brain\nTalairach coordinates\n\n\n## References\n\n\n\n## External links\n\n",
      "vector_count": 1,
      "vector_offset": 2
    },
    {
      "format": "md",
      "id": "PSY0008_Chemoreceptor",
      "metadata": {
        "source_format": "md",
        "source_path": "/tmp/corpus_split_psychology/shard_001/PSY0008_Chemoreceptor.md",
        "source_relpath": "PSY0008_Chemoreceptor.md"
      },
      "path": "PSY0008_Chemoreceptor.md",
      "text": "# Chemoreceptor\n\nA chemoreceptor, also known as chemosensor, is a specialized sensory receptor which transduces a chemical substance (endogenous or induced) to generate a biological signal. This signal may be in the form of an action potential, if the chemoreceptor is a neuron, or in the form of a neurotransmitter that can activate a nerve fiber if the chemoreceptor is a specialized cell, such as taste receptors, or an internal peripheral chemoreceptor, such as the carotid bodies. In physiology, a chemoreceptor detects changes in the normal environment, such as an increase in blood levels of carbon dioxide (hypercapnia) or a decrease in blood levels of oxygen (hypoxia), and transmits that information to the central nervous system which engages body responses to restore homeostasis.\nIn bacteria, chemoreceptors are essential in the mediation of chemotaxis.\n\n\n## Cellular chemoreceptors\n\n\n\n### In prokaryotes\nBacteria utilize complex long helical proteins as chemoreceptors, permitting signals to travel long distances across the cell's membrane. Chemoreceptors allow bacteria to react to chemical stimuli in their environment and regulate their movement accordingly. In archaea, transmembrane receptors comprise only 57% of chemoreceptors, while in bacteria the percentage rises to 87%. This is an indicator that chemoreceptors play a heightened role in the sensing of cytosolic signals in archaea.\n\n\n### In eukaryotes\nPrimary cilia, present in many types of mammalian cells, serve as cellular antennae. The motile function of these cilia is lost in favour of their sensory specialization.\n\n\n## Plant chemoreceptors\n\nPlants have various mechanisms to perceive danger in their environment. Plants are able to detect pathogens and microbes through surface level receptor kinases (PRK). Additionally, receptor-like proteins (RLPs) containing ligand binding receptor domains capture pathogen-associated molecular patterns (PAMPS) and damage-associated molecular patterns (DAMPS) which consequently initiates the plant's innate immunity for a defense response.\nPlant receptor kinases are also used for growth and hormone induction among other important biochemical processes. These reactions are triggered by a series of signaling pathways which are initiated by plant chemically sensitive receptors. Plant hormone receptors can either be integrated in plant cells or situate outside the cell, in order to facilitate chemical structure and composition. There are 5 major categories of hormones that are unique to plants which once bound to the receptor, will trigger a response in target cells. These include auxin, abscisic acid, gibberellin, cytokinin, and ethylene. Once bound, hormones can induce, inhibit, or maintain function of the target response.\n\n\n## Classes\n\nThere are two main classes of chemoreceptor: direct and distance. \n\nExamples of distance chemoreceptors are:\nolfactory receptor neurons in the olfactory system: Olfaction involves the ability to detect chemicals in the gaseous state. In vertebrates, the olfactory system detects odors and pheromones in the nasal cavity. Within the olfactory system there are two anatomically distinct organs: the main olfactory epithelium (MOE) and the vomeronasal organ (VNO). It was initially thought that the MOE is responsible for the detection of odorants, while the VNO detects pheromones. The current view, however, is that both systems can detect odorants and pheromones. Olfaction in invertebrates differs from olfaction in vertebrates. For example, in insects, olfactory sensilla are present on their antennae.\nExamples of direct chemoreceptors include:\nTaste receptors in the gustatory system: The primary use of gustation as a type of chemoreception is for the detection of tasteants. Aqueous chemical compounds come into contact with chemoreceptors in the mouth, such as taste buds on the tongue, and trigger responses. These chemical compounds can either trigger an appetitive response for nutrients, or a defensive response against toxins depending on which receptors fire. Fish and crustaceans, who are constantly in an aqueous environment, use their gustatory system to identify certain chemicals in the mixture for the purpose of localization and ingestion of food.\nInsects use contact chemoreception to recognize certain chemicals such as cuticular hydrocarbons and chemicals specific to host plants. Contact chemoreception is more commonly seen in insects but is also involved in the mating behavior of some vertebrates. The contact chemoreceptor is specific to one type of chemical.\n\n\n## Sensory organs\n\nOlfaction: In terrestrial vertebrates, olfaction occurs in the nose. Volatile chemical stimuli enter the nose and eventually reach the olfactory epithelium which houses the chemoreceptor cells known as olfactory sensory neurons often referred to as OSNs. Embedded in the olfactory epithelium are three types of cells: supporting cells, basal cells, and OSNs. While all three types of cells are integral to normal function of the epithelium, only OSN serve as receptor cells, i.e. responding to the chemicals and generating an action potential that travels down the olfactory nerve to reach the brain. In insects, antennae act as distance chemoreceptors. For example, antennae on moths are made up of long feathery hairs that increase sensory surface area. Each long hair from the main antenna also has smaller sensilla that are used for volatile olfaction. Since moths are mainly nocturnal animals, the development of greater olfaction aids them in navigating the night.\nGustation: In many terrestrial vertebrates, the tongue serves as the primary gustatory sensory organ. As a muscle located in the mouth, it acts to manipulate and discern the composition of food in the initial stages of digestion. The tongue is rich in vasculature, allowing the chemoreceptors located on the top surface of the organ to transmit sensory information to the brain. Salivary glands in the mouth allow for molecules to reach chemoreceptors in an aqueous solution. The chemoreceptors of the tongue fall into two distinct superfamilies of G protein-coupled receptors. GPCR's are intramembrane proteins than bind to an extracellular ligand- in this case chemicals from food- and begin a diverse array of signaling cascades that can result in an action potential registering as input in an organism's brain. Large quantities of chemoreceptors with discrete ligand-binding domains provide for the five basic tastes: sour, salty, bitter, sweet, and savory. The salty and sour tastes work directly through the ion channels, the sweet and bitter taste work through G protein-coupled receptors, and the savory sensation is activated by glutamate.Gustatory chemosensors are not just present on the tongue but also on different cells of the gut epithelium where they communicates the sensory information to several effector systems involved in the regulation of appetite, immune responses, and gastrointestinal motility.\nContact Chemoreception: Contact chemoreception is dependent on the physical contact of the receptor with the stimulus. The receptors are short hairs or cones that have a single pore at, or close to the tip of the projection. They are known as uniporous receptors. Some receptors are flexible, while others are rigid and do not bend with contact. They are mostly found in the mouthparts, but can also occur on the antennae or legs of some insects. There is a collection of dendrites located near the pores of the receptors, yet the distribution of these dendrites changes depending on the organism being examined. The method of transduction of the signal from the dendrites differs depending on the organism and the chemical it is responding to.\nWhen inputs from the environment are significant to the survival of the organism, the input must be detected. As all life processes are ultimately based on chemistry it is natural that detection and passing on of the external input will involve chemical events. The chemistry of the environment is, of course, relevant to survival, and detection of chemical input from the outside may well articulate directly with cell chemicals.\nChemoreception is important for the detection of food, habitat, conspecifics including mates, and predators. For example, the emissions of a predator's food source, such as odors or pheromones, may be in the air or on a surface where the food source has been. Cells in the head, usually the air passages or mouth, have chemical receptors on their surface that change when in contact with the emissions. It passes in either chemical or electrochemical form to the central processor, the brain or spinal cord. The resulting output from the CNS (central nervous system) makes body actions that will engage the food and enhance survival.\n\n\n## Physiology\n\nCarotid bodies and aortic bodies detect changes primarily in pCO2 and H+ ion concentration. They also sense decrease in partial pressure of O2, but to a lesser degree than for pCO2 and H+ ion concentration.\nThe chemoreceptor trigger zone is an area of the medulla in the brain that receives inputs from blood-borne drugs or hormones, and communicates with the vomiting center (area postrema) to induce vomiting.\nPrimary cilia play important roles in chemosensation. In adult tissues, these cilia regulate cell proliferation in response to external stimuli, such as tissue damage. In humans, improper functioning of primary cilia is associated with important diseases known as ciliopathies.\n\n\n### Control of breathing\nParticular chemoreceptors, called ASICs, detect the levels of carbon dioxide in the blood. To do this, they monitor the concentration of hydrogen ions in the blood, which decrease the pH of the blood. This can be a direct consequence of an increase in carbon dioxide concentration, because aqueous carbon dioxide in the presence of carbonic anhydrase reacts to form a proton and a bicarbonate ion.\nThe response is that the respiratory centre (in the medulla), sends nervous impulses to the external intercostal muscles and the diaphragm, via the intercostal nerve and the phrenic nerve, respectively, to increase breathing rate and the volume of the lungs during inhalation.\nChemoreceptors that regulate the depth and rhythm of breathing are broken down into two categories.\n\ncentral chemoreceptors are located on the ventrolateral surface of medulla oblongata and detect changes in pH of cerebrospinal fluid. They have also been shown experimentally to respond to hypercapnic hypoxia (elevated CO2, decreased O2), and eventually desensitize, partly due to redistribution of bicarbonate out of the cerebrospinal fluid (CSF) and increased renal excretion of bicarbonate. These are sensitive to pH and CO2.\nperipheral chemoreceptors: consists of aortic and carotid bodies. Aortic body detects changes in blood oxygen and carbon dioxide, but not pH, while carotid body detects all three. They do not desensitize. Their effect on breathing rate is less than that of the central chemoreceptors.\n\n\n### Heart rate\nThe response to stimulation of chemoreceptors on the heart rate is complicated. Chemoreceptors in the heart or nearby large arteries, as well as chemoreceptors in the lungs, can affect heart rate. Activation of these peripheral chemoreceptors from sensing decreased O2, increased CO2 and a decreased pH is relayed to cardiac centers by the vagus and glossopharyngeal nerves to the [medulla oblongata|medulla] of the brainstem. This increases the sympathetic nervous stimulation on the heart and a corresponding increase in heart rate and contractility in most cases. These factors include activation of stretch receptors due to increased ventilation and the release of circulating catecholamines.\nHowever, if respiratory activity is arrested (e.g. in a patient with a high cervical spinal cord injury), then the primary cardiac reflex to transient hypercapnia and hypoxia is a profound bradycardia and coronary vasodilation through vagal stimulation and systemic vasoconstriction by sympathetic stimulation. In normal cases, if there is reflexive increase in respiratory activity in response to chemoreceptor activation, the increased sympathetic activity on the cardiovascular system would act to increase heart rate and contractility.\n\n\n## See also\n\nList of distinct cell types in the adult human body\n\n\n## References\n\n\n\n## External links\n\n",
      "vector_count": 1,
      "vector_offset": 3
    },
    {
      "format": "md",
      "id": "PSY0009_Classical_conditioning",
      "metadata": {
        "source_format": "md",
        "source_path": "/tmp/corpus_split_psychology/shard_001/PSY0009_Classical_conditioning.md",
        "source_relpath": "PSY0009_Classical_conditioning.md"
      },
      "path": "PSY0009_Classical_conditioning.md",
      "text": "# Classical_conditioning\n\nClassical conditioning (also respondent conditioning and Pavlovian conditioning) is a behavioral procedure in which a biologically potent stimulus (e.g. food, a puff of air on the eye, a potential rival) is paired with a neutral stimulus (e.g. the sound of a musical triangle). The term classical conditioning refers to the process of an automatic, conditioned response that is paired with a specific stimulus. It is essentially equivalent to a signal.\nIvan Pavlov, the Russian physiologist, studied classical conditioning with detailed experiments with dogs, and published the experimental results in 1897. In the study of digestion, Pavlov observed that the experimental dogs salivated when fed red meat. Pavlovian conditioning is distinct from operant conditioning (instrumental conditioning), through which the strength of a voluntary behavior is modified, either by reinforcement or by punishment. However, classical conditioning can affect operant conditioning; classically conditioned stimuli can reinforce operant responses.\nClassical conditioning is a basic behavioral mechanism, and its neural substrates are now beginning to be understood. Though it is sometimes hard to distinguish classical conditioning from other forms of associative learning (e.g., instrumental learning and human associative memory), a number of observations differentiate them, especially the contingencies whereby learning occurs.\nTogether with operant conditioning, classical conditioning became the foundation of behaviorism, a school of psychology which was dominant in the mid-20th century and is still an important influence on the practice of psychological therapy and the study of animal behavior. Classical conditioning has been applied in other areas as well. For example, it may affect the body's response to psychoactive drugs, the regulation of hunger, research on the neural basis of learning and memory, and in certain social phenomena such as the false consensus effect.\n\n\n## Definition\n\nClassical conditioning occurs when a conditioned stimulus (CS) is paired with an unconditioned stimulus (US). Usually, the conditioned stimulus is a neutral stimulus (e.g., the sound of a tuning fork), the unconditioned stimulus is biologically potent (e.g., the taste of food) and the unconditioned response (UR) to the unconditioned stimulus is an innate reflex response (e.g., salivation). After pairing is repeated the organism exhibits a conditioned response (CR) to the conditioned stimulus when the conditioned stimulus is presented alone. (A conditioned response may occur after only one pairing.) Thus, unlike the UR, the CR is acquired through experience, and it is also less permanent than the UR.\nUsually the conditioned response is similar to the unconditioned response, but sometimes it is quite different. For this and other reasons, most learning theorists suggest that the conditioned stimulus comes to signal or predict the unconditioned stimulus, and go on to analyse the consequences of this signal. Robert A. Rescorla provided a clear summary of this change in thinking, and its implications, in his 1988 article \"Pavlovian conditioning: It's not what you think it is\". Despite its widespread acceptance, Rescorla's theory also has shortcomings.\nA false-positive involving classical conditioning from chance (where the unconditioned stimulus has the same chance of happening with or without the conditioned stimulus) has been proven to be improbable in successfully conditioning a response. The element of contingency has been further tested and is said to have \"outlived any usefulness in the analysis of conditioning.\"\nClassical conditioning differs from operant or instrumental conditioning: in classical conditioning, behaviors are modified through the association of stimuli as described above, whereas in operant conditioning behaviors are modified by the effect they produce (i.e., reward or punishment).\n\n\n### Evaluative conditioning\nEvaluative conditioning is a form of classical conditioning, in that it involves a change in the responses to the conditioned stimulus that results from pairing the conditioned stimulus with an unconditioned stimulus. Whereas classic conditioning can refer to a change in any type of response, evaluative conditioning concerns only a change in the evaluative responses to the conditioned stimulus, that is, a change in the liking of the conditioned stimulus. Evaluative conditioning is defined as a change in the association of a stimulus that is due to the pairing of that stimulus with another positive or negative stimulus. The first stimulus is often referred to as the conditioned stimulus and the second stimulus as the unconditioned stimulus. A conditioned stimulus becomes more positive when it has been paired with a positive unconditioned stimulus and more negative when it has been paired with a negative unconditioned stimulus. Evaluative conditioning thus refers to attitude formation or change toward an object due to that object's mere co-occurrence with another object.\nA classic example of the formation of attitudes through conditioning is the 1958 experiment by Staats and Staats. Subjects first were asked to learn a list of words that were presented visually, and were tested on their learning of the list. They then did the same with a list of words presented orally, all of which set the stage for the critical phase of the experiment which was portrayed as an assessment of subjects' ability to learn via both visual and auditory channels at once. During this phase, subjects were exposed visually to a set of nationality names, specifically Dutch and Swedish. Approximately one second after the nationality appeared on the screen, the experimenter announced a word aloud. Most of these latter words, none of which were repeated, were neutral (e.g., chair, with, twelve). Included, however, were a few positive words (e.g., gift, sacred, happy) and a few negative words (e.g., bitter, ugly, failure). These words were systematically paired with the two conditional stimuli nationalities such that one always appeared with positive words and the other with negative words. Thus, the conditioning trials were embedded within a stream of visually presented nationality names and orally presented words. When the conditioning phase was completed, the subjects were first asked to recall the words that had been presented visually and then to evaluate them, presumably because how they felt about those words might have affected their learning. The conditioning was successful. The nationality that had been paired with the more positive unconditional stimuli was rated as more pleasant than the one paired with the negative unconditional stimuli.\n\n\n## Procedures\n\n\n\n### Pavlov's research\nThe best-known and most thorough early work on classical conditioning was done by Ivan Pavlov, although Edwin Twitmyer published some related findings a year earlier. During his research on the physiology of digestion in dogs, Pavlov developed a procedure that enabled him to study the digestive processes of animals over long periods of time. He redirected the animals' digestive fluids outside the body, where they could be measured.\nPavlov noticed that his dogs began to salivate in the presence of the technician who normally fed them, rather than simply salivating in the presence of food. Pavlov called the dogs' anticipatory salivation \"psychic secretion\". Putting these informal observations to an experimental test, Pavlov presented a stimulus (e.g. the sound of a metronome) and then gave the dog food; after a few repetitions, the dogs started to salivate in response to the stimulus. Pavlov concluded that if a particular stimulus in the dog's surroundings was present when the dog was given food then that stimulus could become associated with food and cause salivation on its own.\n\n\n### Terminology\nIn Pavlov's experiments the unconditioned stimulus (US) was the food because its effects did not depend on previous experience. The metronome's sound is originally a neutral stimulus (NS) because it does not elicit salivation in the dogs. After conditioning, the metronome's sound becomes the conditioned stimulus (CS) or conditional stimulus; because its effects depend on its association with food. Likewise, the responses of the dog follow the same conditioned-versus-unconditioned arrangement. The conditioned response (CR) is the response to the conditioned stimulus, whereas the unconditioned response (UR) corresponds to the unconditioned stimulus.\nPavlov reported many basic facts about conditioning; for example, he found that learning occurred most rapidly when the interval between the CS and the appearance of the US was relatively short.\nAs noted earlier, it is often thought that the conditioned response is a replica of the unconditioned response, but Pavlov noted that saliva produced by the CS differs in composition from that produced by the US. In fact, the CR may be any new response to the previously neutral CS that can be clearly linked to experience with the conditional relationship of CS and US. It was also thought that repeated pairings are necessary for conditioning to emerge, but many CRs can be learned with a single trial, especially in fear conditioning and taste aversion learning.\n\n\n### Forward conditioning\nLearning is fastest in forward conditioning. During forward conditioning, the onset of the CS precedes the onset of the US in order to signal that the US will follow. Two common forms of forward conditioning are delay and trace conditioning.\n\nDelay conditioning: In delay conditioning, the CS is presented and is overlapped by the presentation of the US. For example, if a person hears a buzzer for five seconds, during which time air is puffed into their eye, the person will blink. After several pairings of the buzzer and the puff, the person will blink at the sound of the buzzer alone. This is delay conditioning.\nTrace conditioning: During trace conditioning, the CS and US do not overlap. Instead, the CS begins and ends before the US is presented. The stimulus-free period is called the trace interval or the conditioning interval. If in the above buzzer example, the puff came a second after the sound of the buzzer stopped, that would be trace conditioning, with a trace or conditioning interval of one second.\n\n\n### Simultaneous conditioning\n\nDuring simultaneous conditioning, the CS and US are presented and terminated at the same time. For example: If a person hears a bell and has air puffed into their eye at the same time, and repeated pairings like this led to the person blinking when they hear the bell despite the puff of air being absent, this demonstrates that simultaneous conditioning has occurred.\n\n\n### Second-order and higher-order conditioning\n\nSecond-order or higher-order conditioning follow a two-step procedure. First a neutral stimulus (\"CS1\") comes to signal a US through forward conditioning. Then a second neutral stimulus (\"CS2\") is paired with the first (CS1) and comes to yield its own conditioned response. For example: A bell might be paired with food until the bell elicits salivation. If a light is then paired with the bell, then the light may come to elicit salivation as well. The bell is the CS1 and the food is the US. The light becomes the CS2 once it is paired with the CS1.\n\n\n### Backward conditioning\nBackward conditioning occurs when a CS immediately follows a US. Unlike the usual conditioning procedure, in which the CS precedes the US, the conditioned response given to the CS tends to be inhibitory. This presumably happens because the CS serves as a signal that the US has ended, rather than as a signal that the US is about to appear. For example, a puff of air directed at a person's eye could be followed by the sound of a buzzer.\n\n\n### Temporal conditioning\nIn temporal conditioning, a US is presented at regular intervals, for instance every 10 minutes. Conditioning is said to have occurred when the CR tends to occur shortly before each US. This suggests that animals have a biological clock that can serve as a CS. This method has also been used to study timing ability in animals (see Animal cognition).\nThe example below shows the temporal conditioning, as US such as food to a hungry mouse is simply delivered on a regular time schedule such as every thirty seconds. After sufficient exposure the mouse will begin to salivate just before the food delivery. This then makes it temporal conditioning as it would appear that the mouse is conditioned to the passage of time.\n\n\n### Zero contingency procedure\nIn this procedure, the CS is paired with the US, but the US also occurs at other times. If this occurs, it is predicted that the US is likely to happen in the absence of the CS. In other words, the CS does not \"predict\" the US. In this case, conditioning fails and the CS does not come to elicit a CR. This finding \u2013 that prediction rather than CS-US pairing is the key to conditioning \u2013 greatly influenced subsequent conditioning research and theory.\n\n\n### Extinction\n\nIn the extinction procedure, the CS is presented repeatedly in the absence of a US. This is done after a CS has been conditioned by one of the methods above. When this is done, the CR frequency eventually returns to pre-training levels. However, extinction does not eliminate the effects of the prior conditioning. This is demonstrated by spontaneous recovery \u2013 when there is a sudden appearance of the (CR) after extinction occurs \u2013 and other related phenomena (see \"Recovery from extinction\" below). These phenomena can be explained by postulating accumulation of inhibition when a weak stimulus is presented.\n\n\n## Phenomena observed\n\n\n\n### Acquisition\nDuring acquisition, the CS and US are paired as described above. The extent of conditioning may be tracked by test trials. In these test trials, the CS is presented alone and the CR is measured. A single CS-US pairing may suffice to yield a CR on a test, but usually a number of pairings are necessary and there is a gradual increase in the conditioned response to the CS. This repeated number of trials increase the strength and/or frequency of the CR gradually. The speed of conditioning depends on a number of factors, such as the nature and strength of both the CS and the US, previous experience and the animal's motivational state. The process slows down as it nears completion.\n\n\n### Extinction\nIf the CS is presented without the US, and this process is repeated often enough, the CS will eventually stop eliciting a CR. At this point the CR is said to be \"extinguished.\"\n\n\n### External inhibition\nExternal inhibition may be observed if a strong or unfamiliar stimulus is presented just before, or at the same time as, the CS. This causes a reduction in the conditioned response to the CS.\n\n\n### Recovery from extinction\nSeveral procedures lead to the recovery of a CR that had been first conditioned and then extinguished. This illustrates that the extinction procedure does not eliminate the effect of conditioning. These procedures are the following:\n\nReacquisition: If the CS is again paired with the US, a CR is again acquired, but this second acquisition usually happens much faster than the first one.\nSpontaneous recovery: Spontaneous recovery is defined as the reappearance of a previously extinguished conditioned response after a rest period. That is, if the CS is tested at a later time (for example an hour or a day) after extinction it will again elicit a CR. This renewed CR is usually much weaker than the CR observed prior to extinction.\nDisinhibition: If the CS is tested just after extinction and an intense but associatively neutral stimulus has occurred, there may be a temporary recovery of the conditioned response to the CS.\nReinstatement: If the US used in conditioning is presented to a subject in the same place where conditioning and extinction occurred, but without the CS being present, the CS often elicits a response when it is tested later.\nRenewal: Renewal is a reemergence of a conditioned response following extinction when an animal is returned to the environment (or similar environment) in which the conditioned response was acquired.\n\n\n### Stimulus generalization\nStimulus generalization is said to occur if, after a particular CS has come to elicit a CR, a similar test stimulus is found to elicit the same CR. Usually the more similar the test stimulus is to the CS the stronger the CR will be to the test stimulus. Conversely, the more the test stimulus differs from the CS, the weaker the CR will be, or the more it will differ from that previously observed.\n\n\n### Stimulus discrimination\nOne observes stimulus discrimination when one stimulus (\"CS1\") elicits one CR and another stimulus (\"CS2\") elicits either another CR or no CR at all. This can be brought about by, for example, pairing CS1 with an effective US and presenting CS2 with no US.\n\n\n### Latent inhibition\n\nLatent inhibition refers to the observation that it takes longer for a familiar stimulus to become a CS than it does for a novel stimulus to become a CS, when the stimulus is paired with an effective US.\n\n\n### Conditioned suppression\nThis is one of the most common ways to measure the strength of learning in classical conditioning. A typical example of this procedure is as follows: a rat first learns to press a lever through operant conditioning. Then, in a series of trials, the rat is exposed to a CS, a light or a noise, followed by the US, a mild electric shock. An association between the CS and US develops, and the rat slows or stops its lever pressing when the CS comes on. The rate of pressing during the CS measures the strength of classical conditioning; that is, the slower the rat presses, the stronger the association of the CS and the US. (Slow pressing indicates a \"fear\" conditioned response, and it is an example of a conditioned emotional response; see section below.)\n\n\n### Conditioned inhibition\nTypically, three phases of conditioning are used.\n\n\n=### Phase 1=\nA CS (CS+) is paired with a US until asymptotic CR levels are reached.\n\n\n=### Phase 2=\nCS+/US trials are continued, but these are interspersed with trials on which the CS+ is paired with a second CS, (the CS-) but not with the US (i.e. CS+/CS- trials). Typically, organisms show CRs on CS+/US trials, but stop responding on CS+/CS\u2212 trials.\n\n\n=### Phase 3=\nSummation test for conditioned inhibition: The CS- from phase 2 is presented together with a new CS+ that was conditioned as in phase 1. Conditioned inhibition is found if the response is less to the CS+/CS- pair than it is to the CS+ alone.\nRetardation test for conditioned inhibition: The CS- from phase 2 is paired with the US. If conditioned inhibition has occurred, the rate of acquisition to the previous CS\u2212 should be less than the rate of acquisition that would be found without the phase 2 treatment.\n\n\n### Blocking\n\nThis form of classical conditioning involves two phases.\n\n\n=### Phase 1=\nA CS (CS1) is paired with a US.\n\n\n=### Phase 2=\nA compound CS (CS1+CS2) is paired with a US.\n\n\n=### Test=\nA separate test for each CS (CS1 and CS2) is performed. The blocking effect is observed in a lack of conditional response to CS2, suggesting that the first phase of training blocked the acquisition of the second CS.\n\n\n## Theories\n\n\n\n### Data sources\nExperiments on theoretical issues in conditioning have mostly been done on vertebrates, especially rats and pigeons. However, conditioning has also been studied in invertebrates, and very important data on the neural basis of conditioning has come from experiments on the sea slug, Aplysia. Most relevant experiments have used the classical conditioning procedure, although instrumental (operant) conditioning experiments have also been used, and the strength of classical conditioning is often measured through its operant effects, as in conditioned suppression (see Phenomena section above) and autoshaping.\n\n\n### Stimulus-substitution theory\n\nAccording to Pavlov, conditioning does not involve the acquisition of any new behavior, but rather the tendency to respond in old ways to new stimuli. Thus, he theorized that the CS merely substitutes for the US in evoking the reflex response. This explanation is called the stimulus-substitution theory of conditioning. A critical problem with the stimulus-substitution theory is that the CR and UR are not always the same. Pavlov himself observed that a dog's saliva produced as a CR differed in composition from that produced as a UR. The CR is sometimes even the opposite of the UR. For example: the unconditional response to an electric shock is an increase in heart rate, whereas a CS that has been paired with the electric shock elicits a decrease in heart rate. (However, it has been proposed that only when the UR does not involve the central nervous system are the CR and the UR opposites.)\n\n\n### Rescorla\u2013Wagner model\n\nThe Rescorla\u2013Wagner (R\u2013W) model is a relatively simple yet powerful model of conditioning. The model predicts a number of important phenomena, but it also fails in important ways, thus leading to a number of modifications and alternative models. However, because much of the theoretical research on conditioning in the past 40 years has been instigated by this model or reactions to it, the R\u2013W model deserves a brief description here.\nThe Rescorla-Wagner model argues that there is a limit to the amount of conditioning that can occur in the pairing of two stimuli. One determinant of this limit is the nature of the US. For example: pairing a bell with a juicy steak is more likely to produce salivation than pairing the bell with a piece of dry bread, and dry bread is likely to work better than a piece of cardboard. A key idea behind the R\u2013W model is that a CS signals or predicts the US. One might say that before conditioning, the subject is surprised by the US. However, after conditioning, the subject is no longer surprised, because the CS predicts the coming of the US. (The model can be described mathematically and that words like predict, surprise, and expect are only used to help explain the model.) Here the workings of the model are illustrated with brief accounts of acquisition, extinction, and blocking. The model also predicts a number of other phenomena, see main article on the model.\n\n\n=### Equation=\n\n  \n    \n      \n        \u0394\n        V\n        =\n        \u03b1\n        \u03b2\n        (\n        \u03bb\n        \u2212\n        \u03a3\n        V\n        )\n      \n    \n    {\\displaystyle \\Delta V=\\alpha \\beta (\\lambda -\\Sigma V)}\n  \n\nThis is the Rescorla-Wagner equation. It specifies the amount of learning that will occur on a single pairing of a conditioning stimulus (CS) with an unconditioned stimulus (US). The above equation is solved repeatedly to predict the course of learning over many such trials.\nIn this model, the degree of learning is measured by how well the CS predicts the US, which is given by the \"associative strength\" of the CS. In the equation, V represents the current associative strength of the CS, and \u2206V is the change in this strength that happens on a given trial. \u03a3V is the sum of the strengths of all stimuli present in the situation. \u03bb is the maximum associative strength that a given US will support; its value is usually set to 1 on trials when the US is present, and 0 when the US is absent. \u03b1 and \u03b2 are constants related to the salience of the CS and the speed of learning for a given US. How the equation predicts various experimental results is explained in following sections. For further details, see the main article on the model.\n\n\n=### R\u2013W model: acquisition=\nThe R\u2013W model measures conditioning by assigning an \"associative strength\" to the CS and other local stimuli. Before a CS is conditioned it has an associative strength of zero. Pairing the CS and the US causes a gradual increase in the associative strength of the CS. This increase is determined by the nature of the US (e.g. its intensity). The amount of learning that happens during any single CS-US pairing depends on the difference between the total associative strengths of CS and other stimuli present in the situation (\u03a3V in the equation), and a maximum set by the US (\u03bb in the equation). On the first pairing of the CS and US, this difference is large and the associative strength of the CS takes a big step up. As CS-US pairings accumulate, the US becomes more predictable, and the increase in associative strength on each trial becomes smaller and smaller. Finally, the difference between the associative strength of the CS (plus any that may accrue to other stimuli) and the maximum strength reaches zero. That is, the US is fully predicted, the associative strength of the CS stops growing, and conditioning is complete.\n\n\n=### R\u2013W model: extinction=\n\nThe associative process described by the R\u2013W model also accounts for extinction (see \"procedures\" above). The extinction procedure starts with a positive associative strength of the CS, which means that the CS predicts that the US will occur. On an extinction trial the US fails to occur after the CS. As a result of this \"surprising\" outcome, the associative strength of the CS takes a step down. Extinction is complete when the strength of the CS reaches zero; no US is predicted, and no US occurs. However, if that same CS is presented without the US but accompanied by a well-established conditioned inhibitor (CI), that is, a stimulus that predicts the absence of a US (in R-W terms, a stimulus with a negative associate strength) then R-W predicts that the CS will not undergo extinction (its V will not decrease in size).\n\n\n=### R\u2013W model: blocking=\n\nThe most important and novel contribution of the R\u2013W model is its assumption that the conditioning of a CS depends not just on that CS alone, and its relationship to the US, but also on all other stimuli present in the conditioning situation. In particular, the model states that the US is predicted by the sum of the associative strengths of all stimuli present in the conditioning situation. Learning is controlled by the difference between this total associative strength and the strength supported by the US. When this sum of strengths reaches a maximum set by the US, conditioning ends as just described.\nThe R\u2013W explanation of the blocking phenomenon illustrates one consequence of the assumption just stated. In blocking (see \"phenomena\" above), CS1 is paired with a US until conditioning is complete. Then on additional conditioning trials a second stimulus (CS2) appears together with CS1, and both are followed by the US. Finally CS2 is tested and shown to produce no response because learning about CS2 was \"blocked\" by the initial learning about CS1. The R\u2013W model explains this by saying that after the initial conditioning, CS1 fully predicts the US. Since there is no difference between what is predicted and what happens, no new learning happens on the additional trials with CS1+CS2, hence CS2 later yields no response.\n\n\n### Theoretical issues and alternatives to the Rescorla\u2013Wagner model\nOne of the main reasons for the importance of the R\u2013W model is that it is relatively simple and makes clear predictions. Tests of these predictions have led to a number of important new findings and a considerably increased understanding of conditioning. Some new information has supported the theory, but much has not, and it is generally agreed that the theory is, at best, too simple. However, no single model seems to account for all the phenomena that experiments have produced. Following are brief summaries of some related theoretical issues.\n\n\n=### Content of learning=\nThe R\u2013W model reduces conditioning to the association of a CS and US, and measures this with a single number, the associative strength of the CS. A number of experimental findings indicate that more is learned than this. Among these are two phenomena described earlier in this article\n\nLatent inhibition: If a subject is repeatedly exposed to the CS before conditioning starts, then conditioning takes longer. The R\u2013W model cannot explain this because preexposure leaves the strength of the CS unchanged at zero.\nRecovery of responding after extinction: It appears that something remains after extinction has reduced associative strength to zero because several procedures cause responding to reappear without further conditioning.\n\n\n=### Role of attention in learning=\nLatent inhibition might happen because a subject stops focusing on a CS that is seen frequently before it is paired with a US. In fact, changes in attention to the CS are at the heart of two prominent theories that try to cope with experimental results that give the R\u2013W model difficulty. In one of these, proposed by Nicholas Mackintosh, the speed of conditioning depends on the amount of attention devoted to the CS, and this amount of attention depends in turn on how well the CS predicts the US. Pearce and Hall proposed a related model based on a different attentional principle Both models have been extensively tested, and neither explains all the experimental results. Consequently, various authors have attempted hybrid models that combine the two attentional processes. Pearce and Hall in 2010 integrated their attentional ideas and even suggested the possibility of incorporating the Rescorla-Wagner equation into an integrated model.\n\n\n=### Context=\nAs stated earlier, a key idea in conditioning is that the CS signals or predicts the US (see \"zero contingency procedure\" above). However, for example, the room in which conditioning takes place also \"predicts\" that the US may occur. Still, the room predicts with much less certainty than does the experimental CS itself, because the room is also there between experimental trials, when the US is absent. The role of such context is illustrated by the fact that the dogs in Pavlov's experiment would sometimes start salivating as they approached the experimental apparatus, before they saw or heard any CS. Such so-called \"context\" stimuli are always present, and their influence helps to account for some otherwise puzzling experimental findings. The associative strength of context stimuli can be entered into the Rescorla-Wagner equation, and they play an important role in the comparator and computational theories outlined below.\n\n\n=### Comparator theory=\nTo find out what has been learned, we must somehow measure behavior (\"performance\") in a test situation. However, as students know all too well, performance in a test situation is not always a good measure of what has been learned. As for conditioning, there is evidence that subjects in a blocking experiment do learn something about the \"blocked\" CS, but fail to show this learning because of the way that they are usually tested.\n\"Comparator\" theories of conditioning are \"performance based\", that is, they stress what is going on at the time of the test. In particular, they look at all the stimuli that are present during testing and at how the associations acquired by these stimuli may interact. To oversimplify somewhat, comparator theories assume that during conditioning the subject acquires both CS-US and context-US associations. At the time of the test, these associations are compared, and a response to the CS occurs only if the CS-US association is stronger than the context-US association. After a CS and US are repeatedly paired in simple acquisition, the CS-US association is strong and the context-US association is relatively weak. This means that the CS elicits a strong CR. In \"zero contingency\" (see above), the conditioned response is weak or absent because the context-US association is about as strong as the CS-US association. Blocking and other more subtle phenomena can also be explained by comparator theories, though, again, they cannot explain everything.\n\n\n=### Computational theory=\nAn organism's need to predict future events is central to modern theories of conditioning. Most theories use associations between stimuli to take care of these predictions. For example: In the R\u2013W model, the associative strength of a CS tells us how strongly that CS predicts a US. A different approach to prediction is suggested by models such as that proposed by Gallistel & Gibbon (2000, 2002). Here the response is not determined by associative strengths. Instead, the organism records the times of onset and offset of CSs and USs and uses these to calculate the probability that the US will follow the CS. A number of experiments have shown that humans and animals can learn to time events (see Animal cognition), and the Gallistel & Gibbon model yields very good quantitative fits to a variety of experimental data. However, recent studies have suggested that duration-based models cannot account for some empirical findings as well as associative models.\n\n\n=### Element-based models=\nThe Rescorla-Wagner model treats a stimulus as a single entity, and it represents the associative strength of a stimulus with one number, with no record of how that number was reached. As noted above, this makes it hard for the model to account for a number of experimental results. More flexibility is provided by assuming that a stimulus is internally represented by a collection of elements, each of which may change from one associative state to another. For example, the similarity of one stimulus to another may be represented by saying that the two stimuli share elements in common. These shared elements help to account for stimulus generalization and other phenomena that may depend upon generalization. Also, different elements within the same set may have different associations, and their activations and associations may change at different times and at different rates. This allows element-based models to handle some otherwise inexplicable results.\n\n\n==### The SOP model==\nA prominent example of the element approach is the \"SOP\" model of Wagner. The model has been elaborated in various ways since its introduction, and it can now account in principle for a very wide variety of experimental findings. The model represents any given stimulus with a large collection of elements. The time of presentation of various stimuli, the state of their elements, and the interactions between the elements, all determine the course of associative processes and the behaviors observed during conditioning experiments.\nThe SOP account of simple conditioning exemplifies some essentials of the SOP model. To begin with, the model assumes that the CS and US are each represented by a large group of elements. Each of these stimulus elements can be in one of three states: \n\nprimary activity (A1) - Roughly speaking, the stimulus is \"attended to.\" (References to \"attention\" are intended only to aid understanding and are not part of the model.)\nsecondary activity (A2) - The stimulus is \"peripherally attended to.\"\ninactive (I) \u2013 The stimulus is \"not attended to.\"\nOf the elements that represent a single stimulus at a given moment, some may be in state A1, some in state A2, and some in state I.\nWhen a stimulus first appears, some of its elements jump from inactivity I to primary activity A1. From the A1 state they gradually decay to A2, and finally back to I. Element activity can only change in this way; in particular, elements in A2 cannot go directly back to A1. If the elements of both the CS and the US are in the A1 state at the same time, an association is learned between the two stimuli. This means that if, at a later time, the CS is presented ahead of the US, and some CS elements enter A1, these elements will activate some US elements. However, US elements activated indirectly in this way only get boosted to the A2 state. (This can be thought of the CS arousing a memory of the US, which will not be as strong as the real thing.) With repeated CS-US trials, more and more elements are associated, and more and more US elements go to A2 when the CS comes on. This gradually leaves fewer and fewer US elements that can enter A1 when the US itself appears. In consequence, learning slows down and approaches a limit. One might say that the US is \"fully predicted\" or \"not surprising\" because almost all of its elements can only enter A2 when the CS comes on, leaving few to form new associations.\nThe model can explain the findings that are accounted for by the Rescorla-Wagner model and a number of additional findings as well. For example, unlike most other models, SOP takes time into account. The rise and decay of element activation enables the model to explain time-dependent effects such as the fact that conditioning is strongest when the CS comes just before the US, and that when the CS comes after the US (\"backward conditioning\") the result is often an inhibitory CS. Many other more subtle phenomena are explained as well.\nA number of other powerful models have appeared in recent years which incorporate element representations. These often include the assumption that associations involve a network of connections between \"nodes\" that represent stimuli, responses, and perhaps one or more \"hidden\" layers of intermediate interconnections. Such models make contact with a current explosion of research on neural networks, artificial intelligence and machine learning.\n\n\n## Applications\n\n\n\n### Neural basis of learning and memory\nPavlov proposed that conditioning involved a connection between brain centers for conditioned and unconditioned stimuli. His physiological account of conditioning has been abandoned, but classical conditioning continues to be used to study the neural structures and functions that underlie learning and memory. Forms of classical conditioning that are used for this purpose include, among others, fear conditioning, eyeblink conditioning, and the foot contraction conditioning of Hermissenda crassicornis, a sea-slug. Both fear and eyeblink conditioning involve a neutral stimulus, frequently a tone, becoming paired with an unconditioned stimulus. In the case of eyeblink conditioning, the US is an air-puff, while in fear conditioning the US is threatening or aversive such as a foot shock.\nThe American neuroscientist David A. McCormick performed experiments that demonstrated \"...discrete regions of the cerebellum and associated brainstem areas contain neurons that alter their activity during conditioning \u2013 these regions are critical for the acquisition and performance of this simple learning task. It appears that other regions of the brain, including the hippocampus, amygdala, and prefrontal cortex, contribute to the conditioning process, especially when the demands of the task get more complex.\"\nFear and eyeblink conditioning involve generally non overlapping neural circuitry, but share molecular mechanisms. Fear conditioning occurs in the basolateral amygdala, which receives glutaminergic input directly from thalamic afferents, as well as indirectly from prefrontal projections. The direct projections are sufficient for delay conditioning, but in the case of trace conditioning, where the CS needs to be internally represented despite a lack of external stimulus, indirect pathways are necessary. The anterior cingulate is one candidate for intermediate trace conditioning, but the hippocampus may also play a major role. Presynaptic activation of protein kinase A and postsynaptic activation of NMDA receptors and its signal transduction pathway are necessary for conditioning related plasticity. CREB is also necessary for conditioning related plasticity, and it may induce downstream synthesis of proteins necessary for this to occur. As NMDA receptors are only activated after an increase in presynaptic calcium(thereby releasing the Mg2+ block), they are a potential coincidence detector that could mediate spike timing dependent plasticity. STDP constrains LTP to situations where the CS predicts the US, and LTD to the reverse.\n\n\n### Behavioral therapies\n\nSome therapies associated with classical conditioning are aversion therapy, systematic desensitization and flooding.\nAversion therapy is a type of behavior therapy designed to make patients cease an undesirable habit by associating the habit with a strong unpleasant unconditioned stimulus. For example, a medication might be used to associate the taste of alcohol with stomach upset. Systematic desensitization is a treatment for phobias in which the patient is trained to relax while being exposed to progressively more anxiety-provoking stimuli (e.g. angry words). This is an example of counterconditioning, intended to associate the feared stimuli with a response (relaxation) that is incompatible with anxiety. Flooding is a form of desensitization that attempts to eliminate phobias and anxieties by repeated exposure to highly distressing stimuli until the lack of reinforcement of the anxiety response causes its extinction. \"Flooding\" usually involves actual exposure to the stimuli, whereas the term \"implosion\" refers to imagined exposure, but the two terms are sometimes used synonymously.\nConditioning therapies usually take less time than humanistic therapies.\n\n\n### Conditioned drug response\nA stimulus that is present when a drug is administered or consumed may eventually evoke a conditioned physiological response that mimics the effect of the drug. This is sometimes the case with caffeine; habitual coffee drinkers may find that the smell of coffee gives them a feeling of alertness. In other cases, the conditioned response is a compensatory reaction that tends to offset the effects of the drug. For example, if a drug causes the body to become less sensitive to pain, the compensatory conditioned reaction may be one that makes the user more sensitive to pain. This compensatory reaction may contribute to drug tolerance. If so, a drug user may increase the amount of drug consumed in order to feel its effects, and end up taking very large amounts of the drug. In this case a dangerous overdose reaction may occur if the CS happens to be absent, so that the conditioned compensatory effect fails to occur. For example, if the drug has always been administered in the same room, the stimuli provided by that room may produce a conditioned compensatory effect; then an overdose reaction may happen if the drug is administered in a different location where the conditioned stimuli are absent.\n\n\n### Conditioned hunger\nSignals that consistently precede food intake can become conditioned stimuli for a set of bodily responses that prepares the body for food and digestion. These reflexive responses include the secretion of digestive juices into the stomach and the secretion of certain hormones into the blood stream, and they induce a state of hunger. An example of conditioned hunger is the \"appetizer effect.\" Any signal that consistently precedes a meal, such as a clock indicating that it is time for dinner, can cause people to feel hungrier than before the signal. The lateral hypothalamus (LH) is involved in the initiation of eating. The nigrostriatal pathway, which includes the substantia nigra, the lateral hypothalamus, and the basal ganglia have been shown to be involved in hunger motivation.\n\n\n### Conditioned emotional response\n\nThe influence of classical conditioning can be seen in emotional responses such as phobia, disgust, nausea, anger, and sexual arousal. A common example is conditioned nausea, in which the CS is the sight or smell of a particular food that in the past has resulted in an unconditioned stomach upset. Similarly, when the CS is the sight of a dog and the US is the pain of being bitten, the result may be a conditioned fear of dogs. An example of conditioned emotional response is conditioned suppression.\nAs an adaptive mechanism, emotional conditioning helps shield an individual from harm or prepare it for important biological events such as sexual activity. Thus, a stimulus that has occurred before sexual interaction comes to cause sexual arousal, which prepares the individual for sexual contact. For example, sexual arousal has been conditioned in human subjects by pairing a stimulus like a picture of a jar of pennies with views of an erotic film clip. Similar experiments involving blue gourami fish and domesticated quail have shown that such conditioning can increase the number of offspring. These results suggest that conditioning techniques might help to increase fertility rates in infertile individuals and endangered species.\n\n\n### Pavlovian-instrumental transfer\n\nPavlovian-instrumental transfer is a phenomenon that occurs when a conditioned stimulus (CS, also known as a \"cue\") that has been associated with rewarding or aversive stimuli via classical conditioning alters motivational salience and operant behavior. In a typical experiment, a rat is presented with sound-food pairings (classical conditioning). Separately, the rat learns to press a lever to get food (operant conditioning). Test sessions now show that the rat presses the lever faster in the presence of the sound than in silence, although the sound has never been associated with lever pressing.\nPavlovian-instrumental transfer is suggested to play a role in the differential outcomes effect, a procedure which enhances operant discrimination by pairing stimuli with specific outcomes.\n\n\n## See also\n\n\n\n## References\n\n\n\n## Further reading\n\n\n\n## External links\n\n",
      "vector_count": 1,
      "vector_offset": 4
    }
  ]
}