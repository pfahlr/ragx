{
  "documents": [
    {
      "format": "md",
      "id": "PSY0025_Electroreception_and_electrogenesis",
      "metadata": {
        "source_format": "md",
        "source_path": "/tmp/corpus_split_psychology/shard_005/PSY0025_Electroreception_and_electrogenesis.md",
        "source_relpath": "PSY0025_Electroreception_and_electrogenesis.md"
      },
      "path": "PSY0025_Electroreception_and_electrogenesis.md",
      "text": "# Electroreception_and_electrogenesis\n\nElectroreception and electrogenesis are the closely related biological abilities to perceive electrical stimuli and to generate electric fields. Both are used to locate prey; stronger electric discharges are used in a few groups of fishes, such as the electric eel, to stun prey. The capabilities are found almost exclusively in aquatic or amphibious animals, since water is a much better conductor of electricity than air. In passive electrolocation, objects such as prey are detected by sensing the electric fields they create. In active electrolocation, fish generate a weak electric field and sense the different distortions of that field created by objects that conduct or resist electricity. Active electrolocation is practised by two groups of weakly electric fish, the order Gymnotiformes (knifefishes) and family Mormyridae (elephantfishes), and by the monotypic genus Gymnarchus (African knifefish). An electric fish generates an electric field using an electric organ, modified from muscles in its tail. The field is called weak if it is only enough to detect prey, and strong if it is powerful enough to stun or kill. The field may be in brief pulses, as in the elephantfishes, or a continuous wave, as in the knifefishes. Some strongly electric fish, such as the electric eel, locate prey by generating a weak electric field, and then discharge their electric organs strongly to stun the prey; other strongly electric fish, such as the electric ray, electrolocate passively. The stargazers are unique in being strongly electric but not using electrolocation.\nThe electroreceptive ampullae of Lorenzini evolved early in the history of the vertebrates; they are found in both cartilaginous fishes such as sharks, and in bony fishes such as coelacanths and sturgeons, and must therefore be ancient. Most bony fishes have secondarily lost their ampullae of Lorenzini, but other non-homologous electroreceptors have repeatedly evolved, including in two groups of mammals, the monotremes (platypus and echidnas) and the cetaceans (Guiana dolphin).\n\n\n## History\n\n\nIn 1678, while doing dissections of sharks, the Italian physician Stefano Lorenzini discovered organs on their heads now called ampullae of Lorenzini. He published his findings in Osservazioni intorno alle torpedini. The electroreceptive function of these organs was established by R. W. Murray in 1960.\nIn 1921, the German anatomist Viktor Franz described the knollenorgans (tuberous organs) in the skin of the elephantfishes, again without knowledge of their function as electroreceptors.\n\nIn 1949, the Ukrainian-British zoologist Hans Lissmann noticed that the African knife fish (Gymnarchus niloticus) was able to swim backwards at the same speed and with the same dexterity around obstacles as when it swam forwards, avoiding collisions. He demonstrated in 1950 that the fish was producing a variable electric field, and that the fish reacted to any change in the electric field around it.\n\n\n## Electrolocation\n\n\nElectroreceptive animals use the sense to locate objects around them. This is important in ecological niches where the animal cannot depend on vision: for example in caves, in murky water, and at night. Electrolocation can be passive, sensing electric fields such as those generated by the muscle movements of buried prey, or active, the electrogenic predator generating a weak electric field to allow it to distinguish between conducting and non-conducting objects in its vicinity.\n\n\n### Passive electrolocation\nIn passive electrolocation, the animal senses the weak bioelectric fields generated by other animals and uses it to locate them. These electric fields are generated by all animals due to the activity of their nerves and muscles. A second source of electric fields in fish is the ion pump associated with osmoregulation at the gill membrane. This field is modulated by the opening and closing of the mouth and gill slits.\nPassive electroreception usually relies upon ampullary receptors such as ampullae of Lorenzini which are sensitive to low frequency stimuli, below 50 Hz. These receptors have a jelly-filled canal leading from the sensory receptors to the skin surface.\n\n\n### Active electrolocation\n\nIn active electrolocation, the animal senses its surrounding environment by generating weak electric fields (electrogenesis) and detecting distortions in these fields using electroreceptor organs. This electric field is generated by means of a specialised electric organ consisting of modified muscle or nerves. Animals that use active electroreception include the weakly electric fish, which either generate small electrical pulses (termed \"pulse-type\"), as in the Mormyridae, or produce a quasi-sinusoidal discharge from the electric organ (termed \"wave-type\"), as in the Gymnotidae.\nMany of these fish, such as Gymnarchus and Apteronotus, keep their body rather rigid, swimming forwards or backwards with equal facility by undulating fins that extend most of the length of their bodies. Swimming backwards may help them to search for and assess prey using electrosensory cues. Experiments by Lannoo and Lannoo in 1993 support Lissmann's proposal that this style of swimming with a straight back works effectively given the constraints of active electrolocation. Apteronotus can select and catch larger Daphnia water fleas among smaller ones, and they do not discriminate against artificially-darkened water fleas, in both cases with or without light.\nThese fish create a potential usually smaller than one volt (1 V). Weakly electric fish can discriminate between objects with different resistance and capacitance values, which may help in identifying objects. Active electroreception typically has a range of about one body length, though objects with an electrical impedance similar to that of the surrounding water are nearly undetectable.\nActive electrolocation relies upon tuberous electroreceptors which are sensitive to high frequency (20\u201320,000 Hz) stimuli. These receptors have a loose plug of epithelial cells which capacitively couples the sensory receptor cells to the external environment. Elephantfish (Mormyridae) from Africa have tuberous electroreceptors known as Knollenorgans and Mormyromasts in their skin.\nElephantfish emit short pulses to locate their prey. Capacitative and resistive objects affect the electric field differently, enabling the fish to locate objects of different types within a distance of about a body length. Resistive objects increase the amplitude of the pulse; capacitative objects introduce distortions.\n\nThe Gymnotiformes, including the glass knifefish (Sternopygidae) and the electric eel (Gymnotidae), differ from the Mormyridae in emitting a continuous wave, approximating a sine wave, from their electric organ. As in the Mormyridae, the generated electric field enables them to discriminate accurately between capacitative and resistive objects.\n\n\n## Electrocommunication\n\n\nWeakly electric fish can communicate by modulating the electrical waveform they generate. They may use this to attract mates and in territorial displays. Electric catfish frequently use their electric discharges to ward off other species from their shelter sites, whereas with their own species they have ritualized fights with open-mouth displays and sometimes bites, but rarely use electric organ discharges.\nWhen two glass knifefishes (Sternopygidae) come close together, both individuals shift their discharge frequencies in a jamming avoidance response.\nIn bluntnose knifefishes, Brachyhypopomus, the electric discharge pattern is similar to the low voltage electrolocative discharge of the electric eel, Electrophorus. This is hypothesized to be Batesian mimicry of the powerfully-protected electric eel. Brachyhypopomus males produce a continuous electric \"hum\" to attract females; this consumes 11\u201322% of their total energy budget, whereas female electrocommunication consumes only 3%. Large males produced signals of larger amplitude, and these are preferred by the females. The cost to males is reduced by a circadian rhythm, with more activity coinciding with night-time courtship and spawning, and less at other times.\nFish that prey on electrolocating fish may \"eavesdrop\" on the discharges of their prey to detect them. The electroreceptive African sharptooth catfish (Clarias gariepinus) may hunt the weakly electric mormyrid, Marcusenius macrolepidotus in this way. This has driven the prey, in an evolutionary arms race, to develop more complex or higher frequency signals that are harder to detect.\nSome shark embryos and pups \"freeze\" when they detect the characteristic electric signal of their predators.\n\n\n## Evolution and taxonomic distribution\n\nIn vertebrates, passive electroreception is an ancestral trait, meaning that it was present in their last common ancestor. The ancestral mechanism is called ampullary electroreception, from the name of the receptive organs involved, ampullae of Lorenzini. These evolved from the mechanical sensors of the lateral line, and exist in cartilaginous fishes (sharks, rays, and chimaeras), lungfishes, bichirs, coelacanths, sturgeons, paddlefishes, aquatic salamanders, and caecilians. Ampullae of Lorenzini appear to have been lost early in the evolution of bony fishes and tetrapods, though the evidence for absence in many groups is incomplete and unsatisfactory.  Where electroreception does occur in these groups, it has secondarily been acquired in evolution, using organs other than and not homologous with ampullae of Lorenzini.\nElectric organs have evolved at least eight separate times, each one forming a clade: twice during the evolution of cartilaginous fishes, creating the electric skates and rays, and six times during the evolution of the bony fishes. Passively-electrolocating groups, including those that move their heads to direct their electroreceptors, are shown without symbols. Non-electrolocating species are not shown.  Actively electrolocating fish are marked with a small yellow lightning flash  and their characteristic discharge waveforms. Fish able to deliver electric shocks are marked with a red lightning flash .\n\n\n### Cartilaginous fish\nSharks and rays (Elasmobranchii) rely on electrolocation using their ampullae of Lorenzini in the final stages of their attacks, as can be demonstrated by the robust feeding response elicited by electric fields similar to those of their prey. Sharks are the most electrically sensitive animals known, responding to direct current fields as low as 5 nV/cm.\n\n\n### Bony fish\nTwo groups of teleost fishes are weakly electric and actively electroreceptive: the Neotropical knifefishes (Gymnotiformes) and the African elephantfishes (Notopteroidei), enabling them to navigate and find food in turbid water. The Gymnotiformes include the electric eel, which besides the group's use of low-voltage electrolocation, is able to generate high voltage electric shocks to stun its prey. Such powerful electrogenesis makes use of large electric organs modified from muscles. These consist of a stack of electrocytes, each capable of generating a small voltage; the voltages are effectively added together (in series) to provide a powerful electric organ discharge.\n\n\n### Monotremes\n\nThe monotremes, including the semi-aquatic platypus and the terrestrial echidnas, are one of the only groups of mammals that have evolved electroreception. While the electroreceptors in fish and amphibians evolved from mechanosensory lateral line organs, those of monotremes are based on cutaneous glands innervated by trigeminal nerves.  The electroreceptors of monotremes consist of free nerve endings located in the mucous glands of the snout. Among the monotremes, the platypus (Ornithorhynchus anatinus) has the most acute electric sense.  The platypus localises its prey using almost 40,000 electroreceptors arranged in front-to-back stripes along the bill. The arrangement is highly directional, being most sensitive off to the sides and below. By making short quick head movements called saccades, platypuses accurately locate their prey. The platypus appears to use electroreception along with pressure sensors to determine the distance to prey from the delay between the arrival of electrical signals and pressure changes in water.\nThe electroreceptive capabilities of the four species of echidna are much simpler. Long-beaked echidnas (genus Zaglossus) have some 2,000 receptors, while short-beaked echidnas (Tachyglossus aculeatus) have around 400, near the end of the snout. This difference can be attributed to their habitat and feeding methods. Western long-beaked echidnas feed on earthworms in leaf litter in tropical forests, wet enough to conduct electrical signals well. Short-beaked echidnas feeds mainly on termites and ants, which live in nests in dry areas; the nest interiors are presumably humid enough for electroreception to work. Experiments have shown that echidnas can be trained to respond to weak electric fields in water and moist soil. The electric sense of the echidna is hypothesised to be an evolutionary remnant from a platypus-like ancestor.\n\n\n### Dolphins\nDolphins have evolved electroreception in structures different from those of fish, amphibians and monotremes. The hairless vibrissal crypts on the rostrum of the Guiana dolphin (Sotalia guianensis), originally associated with mammalian whiskers, are capable of electroreception as low as 4.8 \u03bcV/cm, sufficient to detect small fish. This is comparable to the sensitivity of electroreceptors in the platypus.\n\n\n### Bees\nUntil recently, electroreception was known only in vertebrates. Recent research has shown that bees can detect the presence and pattern of a static charge on flowers.\n\n\n## See also\n\nActive sensory systems\nFeature detection (nervous system)\nMagnetoreception\n\n\n## References\n\n\n\n## Further reading\n\nBullock, Theodore Holmes (2005). Electroreception. New York: Springer. ISBN 978-0-387-23192-1. OCLC 77005918.\n\n\n## External links\n\n",
      "vector_count": 1,
      "vector_offset": 0
    },
    {
      "format": "md",
      "id": "PSY0026_Enactivism",
      "metadata": {
        "source_format": "md",
        "source_path": "/tmp/corpus_split_psychology/shard_005/PSY0026_Enactivism.md",
        "source_relpath": "PSY0026_Enactivism.md"
      },
      "path": "PSY0026_Enactivism.md",
      "text": "# Enactivism\n\nEnactivism is a position in cognitive science that argues that cognition arises through a dynamic interaction between an acting organism and its environment. It claims that the environment of an organism is brought about, or enacted, by the active exercise of that organism's sensorimotor processes. \"The key point, then, is that the species brings forth and specifies its own domain of problems ...this domain does not exist \"out there\" in an environment that acts as a landing pad for organisms that somehow drop or parachute into the world. Instead, living beings and their environments stand in relation to each other through mutual specification or codetermination\" (p. 198). \"Organisms do not passively receive information from their environments, which they then translate into internal representations. Natural cognitive systems...participate in the generation of meaning ...engaging in transformational and not merely informational interactions: they enact a world.\" These authors suggest that the increasing emphasis upon enactive terminology presages a new era in thinking about cognitive science. How the actions involved in enactivism relate to age-old questions about free will remains a topic of active debate.\nThe term 'enactivism' is close in meaning to 'enaction', defined as \"the manner in which a subject of perception creatively matches its actions to the requirements of its situation\". The introduction of the term enaction in this context is attributed to  Francisco Varela, Evan Thompson, and Eleanor Rosch in The Embodied Mind (1991), who proposed the name to \"emphasize the growing conviction that cognition is not the representation of a pre-given world by a pre-given mind but is rather the enactment of a world and a mind on the basis of a history of the variety of actions that a being in the world performs\". This was further developed by Thompson and others, to place emphasis upon the idea that experience of the world is a result of mutual interaction between the sensorimotor capacities of the organism and its environment. However, some writers maintain that there remains a need for some degree of the mediating function of representation in this new approach to the science of the mind.\nThe initial emphasis of enactivism upon sensorimotor skills has been criticized as \"cognitively marginal\", but it has been extended to apply to higher level cognitive activities, such as social interactions. \"In the enactive view,... knowledge is constructed: it is constructed by an agent through its sensorimotor interactions with its environment, co-constructed between and within living species through their meaningful interaction with each other. In its most abstract form, knowledge is co-constructed between human individuals in socio-linguistic interactions...Science is a particular form of social knowledge construction...[that] allows us to perceive and predict events beyond our immediate cognitive grasp...and also to construct further, even more powerful scientific knowledge.\"\nEnactivism is closely related to situated cognition and embodied cognition, and is presented as an alternative to cognitivism, computationalism, and Cartesian dualism.\n\n\n## Philosophical aspects\n\nEnactivism is one of  a cluster of related theories sometimes known as the 4Es, also known as 4E cognition. As described by Mark Rowlands, mental processes are:\n\nEmbodied involving more than the brain, including a more general involvement of bodily structures and processes.\nEmbedded functioning only in a related external environment.\nEnacted involving not only neural processes, but also things an organism does.\nExtended into the organism's environment.\nEnactivism proposes an alternative to dualism as a philosophy of mind, in that it emphasises the interactions between mind, body and the environment, seeing them all as inseparably intertwined in mental processes. The self arises as part of the process of an embodied entity interacting with the environment in precise ways determined by its physiology.   In this sense, individuals can be seen to \"grow into\" or arise from their interactive role with the world.\n\n\"Enaction is the idea that organisms create their own experience through their actions. Organisms are not passive receivers of input from the environment, but are actors in the environment such that what they experience is shaped by how they act.\"\nIn The Tree of Knowledge Maturana & Varela proposed the term enactive \"to evoke the view of knowledge that what is known is brought forth, in contraposition to the more classical views of either cognitivism or connectionism. They see enactivism as providing a middle ground between the two extremes of representationalism and solipsism. They seek to \"confront the problem of understanding how our existence-the praxis of our living- is coupled to a surrounding world which appears filled with regularities that are at every instant the result of our biological and social histories.... to find a via media: to understand the regularity of the world we are experiencing at every moment, but without any point of reference independent of ourselves that would give certainty to our descriptions and cognitive assertions.  Indeed the whole mechanism of generating ourselves, as describers and observers tells us that our world, as the world which we bring forth in our coexistence with others, will always have precisely that mixture of regularity and mutability, that combination of solidity and shifting sand, so typical of human experience when we look at it up close.\"[Tree of Knowledge, p. 241] Another important notion relating to enactivism is autopoiesis. The word refers to a system that is able to reproduce and maintain itself. Maturana & Varela describe that \"This was a word without a history, a word that could directly mean what takes place in the dynamics of the autonomy proper to living systems\" Using the term autopoiesis, they argue that any closed system that has autonomy, self-reference and self-construction (or, that has autopoietic activities) has cognitive capacities. Therefore, cognition is present in all living systems. This view is also called autopoietic enactivism.\nRadical enactivism is another form of enactivist view of cognition. Radical enactivists often adopt a thoroughly non-representational, enactive account of basic cognition. Basic cognitive capacities mentioned by Hutto and Myin include  perceiving, imagining and remembering. They argue that those forms of basic cognition can be explained without positing mental representations. With regard to complex forms of cognition such as language, they think mental representations are needed, because there needs explanations of content. In human being's public practices, they claim that \"such intersubjective practices and sensitivity to the relevant norms comes with the mastery of the use of public symbol systems\" (2017, p. 120), and so \"as it happens, this appears only to have occurred in full form with construction of sociocultural cognitive niches in the human lineage\" (2017, p. 134). They conclude that basic cognition as well as cognition in simple organisms such as bacteria are best characterized as non-representational.\nEnactivism also addresses the hard problem of consciousness, referred to by Thompson as part of the explanatory gap in explaining how consciousness and subjective experience are related to brain and body.  \"The problem with the dualistic concepts of consciousness and life in standard formulations of the hard problem is that they exclude each other by construction\". Instead, according to Thompson's view of enactivism, the study of consciousness or phenomenology as exemplified by Husserl and Merleau-Ponty is to complement science and its objectification of the world. \"The whole universe of science is built upon the world as directly experienced, and if we want to subject science itself to rigorous scrutiny and arrive at a precise assessment of its meaning and scope, we must begin by reawakening the basic experience of the world of which science is the second-order expression\" (Merleau-Ponty, The phenomenology of perception as quoted by Thompson, p. 165). In this interpretation, enactivism asserts that science is formed or enacted as part of humankind's interactivity with its world, and by embracing phenomenology \"science itself is properly situated in relation to the rest of human life and is thereby secured on a sounder footing.\"\nEnaction has been seen as a move to conjoin representationalism with phenomenalism, that is, as adopting a constructivist epistemology, an epistemology centered upon the active participation of the subject in constructing reality. However, 'constructivism' focuses upon more than a simple 'interactivity' that could be described as a minor adjustment to 'assimilate' reality or 'accommodate' to it. Constructivism looks upon interactivity as a radical, creative, revisionist process in which the knower constructs a personal 'knowledge system' based upon their experience and tested by its viability in practical encounters with their environment. Learning is a result of perceived anomalies that produce dissatisfaction with existing conceptions.\nShaun Gallagher also points out that pragmatism is a forerunner of enactive and extended approaches to cognition. According to him, enactive conceptions of cognition can be found in many pragmatists such as Charles Sanders Peirce and John Dewey. For example, Dewey says that \"The brain is essentially an organ for effecting the reciprocal adjustment to each other of the stimuli received from the environment and responses directed upon it\" (1916, pp. 336\u2013337). This view  is fully consistent with enactivist arguments that cognition is not just a matter of brain processes and brain is one part of the body consisting of the dynamical regulation. Robert Brandom, a neo-pragmatist, comments that \"A founding idea of pragmatism is that the most fundamental kind of intentionality (in the sense of directedness towards objects) is the practical involvement with objects exhibited by a sentient creature dealing skillfully with its world\" (2008, p. 178).\nHow does constructivism relate to enactivism? From the above remarks it can be seen that Glasersfeld expresses an interactivity between the knower and the known quite acceptable to an enactivist, but does not emphasize  the structured probing of the environment by the knower that leads to the \"perturbation relative to some expected result\" that then leads to a new understanding. It is this probing activity, especially where it is not accidental but deliberate, that characterizes enaction, and invokes affect, that is, the motivation and planning that lead to doing and to fashioning the probing, both observing and modifying the environment, so that \"perceptions and nature condition one another through generating one another.\" The questioning nature of this probing activity is not an emphasis of Piaget and Glasersfeld.\nSharing enactivism's stress upon both action and embodiment in the incorporation of knowledge, but giving Glasersfeld's mechanism of viability an evolutionary emphasis, is evolutionary epistemology. Inasmuch as an organism must reflect its environment well enough for the organism to be able to survive in it, and to be competitive enough to be able to reproduce at sustainable rate, the structure and reflexes of the organism itself embody knowledge of its environment. This biology-inspired theory of the growth of knowledge is closely tied to universal Darwinism, and is associated with evolutionary epistemologists such as Karl Popper, Donald T. Campbell, Peter Munz, and Gary Cziko. According to Munz, \"an organism is an embodied theory about its environment... Embodied theories are also no longer expressed in language, but in anatomical structures or reflex responses, etc.\"\nOne objection to enactive approaches to cognition is the so-called \"scale-up objection\". According to this objection, enactive theories only have limited value because they cannot \"scale up\" to explain more complex cognitive capacities like human thoughts. Those phenomena are extremely difficult to explain without positing representation. But recently, some philosophers are trying to respond to such objection. For example, Adrian Downey (2020) provides a non-representational account of Obsessive-compulsive disorder, and then argues that ecological-enactive approaches can respond to the \"scaling up\" objection.\n\n\n## Psychological aspects\n\nMcGann & others argue that enactivism attempts to mediate between the explanatory role of the coupling between cognitive agent and environment and the traditional emphasis on brain mechanisms found in neuroscience and psychology.  In the interactive approach to social cognition developed by De Jaegher &  others, the dynamics of interactive processes are seen to play significant roles in coordinating interpersonal understanding, processes that in part include what they call participatory sense-making. Recent developments of enactivism in the area of social neuroscience involve the proposal of The Interactive Brain Hypothesis where social cognition brain mechanisms, even those used in non-interactive situations, are proposed to have interactive origins.\n\n\n### Enactive views of perception\nIn the enactive view, perception \"is not conceived as the transmission of information but more as an exploration of the world by various means. Cognition is not tied into the workings of an 'inner mind', some cognitive core, but occurs in directed interaction between the body and the world it inhabits.\"\nAlva No\u00eb in advocating an enactive view of perception sought to resolve how we perceive three-dimensional objects, on the basis of two-dimensional input.  He argues that we perceive this solidity (or 'volumetricity') by appealing to patterns of sensorimotor expectations. These arise from our agent-active  'movements and interaction' with objects, or 'object-active' changes in the object itself. The solidity is perceived through our expectations and skills in knowing how the object's appearance would change with changes in how we relate to it. He saw all perception as an active exploration of the world, rather than being a passive process, something which happens to us.\nNo\u00eb's idea of the role of 'expectations' in three-dimensional perception has been opposed by several philosophers, notably by Andy Clark. Clark points to difficulties of the enactive approach.  He points to internal processing of visual signals, for example, in the ventral and dorsal pathways, the two-streams hypothesis. This results in an integrated perception of objects (their recognition and location, respectively) yet this processing cannot be described as an action or actions. In a more general criticism, Clark suggests that perception is not a matter of expectations about sensorimotor mechanisms guiding perception. Rather, although the limitations of sensorimotor mechanisms constrain perception, this sensorimotor activity is drastically filtered to fit current needs and purposes of the organism, and it is these imposed 'expectations' that govern perception, filtering for the 'relevant' details of sensorimotor input (called \"sensorimotor summarizing\").\nThese sensorimotor-centered and purpose-centered views appear to agree on the general scheme but disagree on the dominance issue \u2013 is the dominant component peripheral or central. Another view, the closed-loop perception one, assigns equal a-priori dominance to the peripheral and central components. In closed-loop perception, perception emerges through the process of inclusion of an item in a motor-sensory-motor loop, i.e., a loop (or loops) connecting the peripheral and central components that are relevant to that item. The item can be a body part (in which case the loops are in steady-state) or an external object (in which case the loops are perturbed and gradually converge to a steady state). These enactive loops are always active, switching dominance by the need.\nAnother application of enaction to perception is analysis of the human hand. The many remarkably demanding uses of the hand are not learned by instruction, but through a history of engagements that lead to the acquisition of skills. According to one interpretation, it is suggested that \"the hand [is]...an organ of cognition\", not a faithful subordinate working under top-down instruction, but a partner in a \"bi-directional interplay between manual and brain activity.\" According to Daniel Hutto: \"Enactivists are concerned to defend the view that our most elementary ways of engaging with the world and others - including our basic forms of perception and perceptual experience - are mindful in the sense of being phenomenally charged and intentionally directed, despite being non-representational and content-free.\" Hutto calls this position 'REC' (Radical Enactive Cognition): \"According to REC, there is no way to distinguish neural activity that is imagined to be genuinely content involving (and thus truly mental, truly cognitive) from other non-neural activity that merely plays a supporting or enabling role in making mind and cognition possible.\"\n\n\n### Participatory sense-making\nHanne De Jaegher and Ezequiel Di Paolo (2007) have extended the enactive concept of sense-making into the social domain. The idea takes as its departure point the process of interaction between individuals in a social encounter. De Jaegher and Di Paolo argue that the interaction process itself can take on a form of autonomy (operationally defined). This allows them to define social cognition as the generation of meaning and its transformation through interacting individuals.\nThe notion of participatory sense-making has led to the proposal that interaction processes can sometimes play constitutive roles in social cognition (De Jaegher, Di Paolo, Gallagher, 2010). It has been applied to research in social neuroscience and autism.\nIn a similar vein, \"an inter-enactive approach to agency holds that the behavior of agents in a social situation unfolds not only according to their individual abilities and goals, but also according to the conditions and constraints imposed by the autonomous dynamics of the interaction process itself\". According to Torrance, enactivism involves five interlocking themes related to the question \"What is it to be a (cognizing, conscious) agent?\" It is:\n\n1. to be a biologically autonomous (autopoietic) organism\n2. to generate significance or meaning, rather than to act via...updated internal representations of the external world\n3. to engage in sense-making via dynamic coupling with the environment\n4. to 'enact' or 'bring forth' a world of significances by mutual co-determination of the organism with its enacted world\n5. to arrive at an experiential awareness via lived embodiment in the world.\nTorrance adds that \"many kinds of agency, in particular the agency of human beings, cannot be understood separately from understanding the nature of the interaction that occurs between agents.\" That view introduces the social applications of enactivism. \"Social cognition is regarded as the result of a special form of action, namely social interaction...the enactive approach looks at the circular dynamic within a dyad of embodied agents.\"\nIn cultural psychology, enactivism is seen as a way to uncover cultural influences upon feeling, thinking and acting.  Baerveldt and Verheggen argue that \"It appears that seemingly natural experience is thoroughly intertwined with sociocultural realities.\" They suggest that the social patterning of experience is to be understood through enactivism, \"the idea that the reality we have in common, and in which we find ourselves, is neither a world that exists independently from us, nor a socially shared way of representing such a pregiven world, but a world itself brought forth by our ways of communicating and our joint action....The world we inhabit is manufactured of 'meaning' rather than 'information'.\nLuhmann attempted to apply Maturana and Varela's notion of autopoiesis to social systems. \"A core concept of social systems theory is derived from biological systems theory: the concept of autopoiesis. Chilean biologist Humberto Maturana come up with the concept to explain how biological systems such as cells are a product of their own production.\" \"Systems exist by way of operational closure and this means that they each construct themselves and their own realities.\"\n\n\n## Educational aspects\n\nThe first definition of enaction was introduced by psychologist Jerome Bruner, who introduced enaction as 'learning by doing' in his discussion of how children learn, and how they can best be helped to learn. He associated enaction with two other ways of knowledge organization: Iconic and Symbolic.\n\n\"Any domain of knowledge (or any problem within that domain of knowledge) can be represented in three ways: by a set of actions appropriate for achieving a certain result (enactive representation); by a set of summary images or graphics that stand for a concept without defining it fully  (iconic representation); and by a set of symbolic or logical propositions drawn from a symbolic system that is governed by rules or laws for forming and transforming propositions (symbolic representation)\"\nThe term 'enactive framework' was elaborated upon by Francisco Varela and Humberto Maturana.\nSriramen argues that enactivism provides \"a rich and powerful explanatory theory for learning and being.\" and that it is closely related to both the ideas of cognitive development of Piaget, and also the social constructivism of Vygotsky. Piaget focused on the child's immediate environment, and suggested cognitive structures like spatial perception emerge as a result of the child's interaction with the world. According to Piaget, children construct knowledge, using what they know in new ways and testing it, and the environment provides feedback concerning the adequacy of their construction. In a cultural context, Vygotsky suggested that the kind of cognition that can take place is not dictated by the engagement of the isolated child, but is also a function of social interaction and dialogue that is contingent upon a sociohistorical context.  Enactivism in educational theory \"looks at each learning situation as a complex system consisting of teacher, learner, and context, all of which frame and co-create the learning situation.\" Enactivism in education is very closely related to situated cognition, which holds that \"knowledge is situated, being in part a product of the activity, context, and culture in which it is developed and used.\" This approach challenges the \"separating of what is learned from how it is learned and used.\"\n\n\n## Artificial intelligence aspects\n\n\nThe ideas of enactivism regarding how organisms engage with their environment have interested those involved in robotics and man-machine interfaces. The analogy is drawn that a robot can be designed to interact and learn from its environment in a manner similar to the way an organism does, and a human can interact with a computer-aided design tool or data base using an interface that creates an enactive environment for the user, that is, all the user's tactile, auditory, and visual capabilities are enlisted in a mutually explorative engagement, capitalizing upon all the user's abilities, and not at all limited to cerebral engagement. In these areas it is common to refer to affordances as a design concept, the idea that an environment or an interface affords opportunities for enaction, and good design involves optimizing the role of such affordances.\nThe activity in the AI community has influenced enactivism as a whole. Referring extensively to modeling techniques for evolutionary robotics by Beer, the modeling of learning behavior by Kelso, and to modeling of sensorimotor activity by Saltzman, McGann, De Jaegher, and Di Paolo discuss how this work makes the dynamics of coupling between an agent and its environment, the foundation of enactivism, \"an operational, empirically observable phenomenon.\" That is, the AI environment invents examples of enactivism using concrete examples that, although not as complex as living organisms, isolate and illuminate basic principles.\n\n\n### Mathematical formalisms\n\nEnactive cognition has been formalised in order to address subjectivity in artificial general intelligence.\nA mathematical formalism of AGI is an agent proven to maximise a measure of intelligence. Prior to 2022, the only such formalism was AIXI, which maximised \u201cthe ability to satisfy goals in a wide range of environments\u201d. In 2015 Jan Lieke and Marcus Hutter showed that \"Legg-Hutter intelligence is measured with respect to a fixed UTM. AIXI is the most intelligent policy if it uses the same UTM\", a result which \"undermines all existing optimality properties for AIXI\", rendering them subjective.\n\n\n## Criticism\n\nOne of the essential theses of this approach is that biological systems generate meanings, i.e. they are semiotic systems, engaging in transformational and not merely informational interactions. Since this thesis raised the problems of beginning cognition for organisms in the developmental stage of only simple reflexes (the binding problem and the problem of primary data entry), enactivists proposed the concept of embodied information that serves to start cognition. However, critics highlight that this idea requires introducing the nature of intentionality before engaging embodied information. In a natural environment, the stimulus-reaction pair (causation) is unpredictable due to many irrelevant stimuli claiming to be randomly associated with the embodied information. While embodied information is only beneficial when intentionality is already in place, enactivists introduced the notion of the generation of meanings by biological systems (engaging in transformational interactions) without introducing a neurophysiological basis of intentionality.\n\n\n## See also\n\n\n\n## Notes\n\n\n\n## References\n\n\n\n## Further reading\n\nClark, Andy (2015). Surfing uncertainty: Prediction, action, and the embodied mind. Oxford University Press. ISBN 9780190217013.\nDe Jaegher H.; Di Paolo E. A. (2007). \"Participatory sense-making: An enactive approach to social cognition\". Phenomenology and the Cognitive Sciences. 6 (4): 485\u2013507. doi:10.1007/s11097-007-9076-9. S2CID 142842155.\nDi Paolo, E. A., Rohde, M. and De Jaegher, H., (2010). Horizons for the Enactive Mind: Values, Social Interaction, and Play. In J. Stewart, O. Gapenne and E. A. Di Paolo (eds), Enaction: Towards a New Paradigm for Cognitive Science, Cambridge, MA: MIT Press, pp. 33 \u2013 87. ISBN 9780262014601\nGallagher, Shaun (2017). Enactivist Interventions: Rethinking the Mind. Oxford University Press. ISBN 978-0198794325\nHutto, D. D. (Ed.)  (2006).  Radical Enactivism: Intentionality, phenomenology, and narrative.  In R. D. Ellis & N. Newton (Series Eds.), Consciousness & Emotion, vol. 2. ISBN 90-272-4151-1\nMcGann, M. & Torrance, S. (2005).  Doing it and meaning it (and the relationship between the two).  In R. D. Ellis & N. Newton, Consciousness & Emotion, vol. 1: Agency, conscious choice, and selective perception. Amsterdam: John Benjamins. ISBN 1-58811-596-8\nMerleau-Ponty, Maurice (2005). Phenomenology of Perception. Routledge. ISBN 9780415278416 (Originally published 1945)\nNo\u00eb, Alva (2010). Out of Our Heads: Why You Are Not Your Brain, and Other Lessons from the Biology of Consciousness. Hill and Wang. ISBN 978-0809016488\nTom Froese; Ezequiel A DiPaolo (2011). \"The enactive approach: Theoretical sketches from cell to society\". Pragmatics & Cognition. 19 (1): 1\u201336. CiteSeerX 10.1.1.224.5504. doi:10.1075/pc.19.1.01fro.\nSteve Torrance; Tom Froese (2011). \"An inter-enactive approach to agency: participatory sense-making, dynamics, and sociality\". Humana. Mente. 15: 21\u201353. CiteSeerX 10.1.1.187.1151.\n(fr) Domenico Masciotra (2023). Une approche \u00e9nactive des formations, Th\u00e9orie et M\u00e9thode. En devenir comp\u00e9tent et connaisseur. ASCAR Inc.\n\n\n## External links\n\n",
      "vector_count": 1,
      "vector_offset": 1
    },
    {
      "format": "md",
      "id": "PSY0027_Episodic_memory",
      "metadata": {
        "source_format": "md",
        "source_path": "/tmp/corpus_split_psychology/shard_005/PSY0027_Episodic_memory.md",
        "source_relpath": "PSY0027_Episodic_memory.md"
      },
      "path": "PSY0027_Episodic_memory.md",
      "text": "# Episodic_memory\n\nEpisodic memory is the memory of everyday events (such as times, location geography, associated emotions, and other contextual information) that can be explicitly stated or conjured. It is the collection of past personal experiences that occurred at particular times and places; for example, the party on one's 7th birthday. Along with semantic memory, it comprises the category of explicit memory, one of the two major divisions of long-term memory (the other being implicit memory).\nThe term \"episodic memory\" was coined by Endel Tulving in 1972, referring to the distinction between knowing and remembering: knowing is factual recollection (semantic) whereas remembering is a feeling that is located in the past (episodic).\nOne of the main components of episodic memory is the process of recollection, which elicits the retrieval of contextual information pertaining to a specific event or experience that has occurred. Tulving seminally defined three key properties of episodic memory recollection as:\n\nA subjective sense of time (or mental time travel)\nConnection to the self\nAutonoetic consciousness, a special kind of consciousness that accompanies the act of remembering, which enables an individual to be aware of the self in a subjective time\nAside from Tulving, others named additional aspects of recollection, including visual imagery, narrative structure, retrieval of semantic information and feelings of familiarity.\nEvents that are recorded into episodic memory may trigger episodic learning, i.e. a change in behavior that occurs as a result of an event, such as a fear of dogs after being bitten by a dog.\n\n\n## Nine properties\n\nThere are essentially nine properties of episodic memory that collectively distinguish it from other types of memory. Other types of memory may exhibit a few of these properties, but only episodic memory has all nine:\n\nContain summary records of sensory-perceptual-conceptual-affective processing.\nRetain patterns of activation/inhibition over long periods.\nOften represented in the form of (visual) images.\nThey always have a perspective (field or observer).\nRepresent short time slices of experience.\nThey are represented on a temporal dimension roughly in order of occurrence.\nThey are subject to rapid forgetting.\nThey make autobiographical remembering specific.\nThey are recollectively experienced when accessed.\n\n\n## Cognitive neuroscience\n\nThe formation of new episodic memories requires the medial temporal lobe, a structure that includes the hippocampus. Without the medial temporal lobe, one is able to form new procedural memories (such as playing the piano) but cannot remember the events during which they happened (See the hippocampus and memory).\nThe prefrontal cortex (and in particular the right hemisphere) is also involved in the formation of new episodic memories (also known as episodic encoding). Patients with damage to the prefrontal cortex can learn new information, but tend to do so in a disordered fashion. For example, they might show normal recognition of an object they had seen in the past, but fail to recollect when or where it had been viewed. Some researchers believe that the prefrontal cortex helps organize information for more efficient storage, drawing upon its role in executive function. Others believe that the prefrontal cortex underlies semantic strategies which enhance encoding, such as thinking about the meaning of the study material or rehearsing it in working memory.\nOther work has shown that portions of the inferior parietal lobe play a role in episodic memory, potentially acting as an accumulator to support the subjective feeling that something is \"old\", or perhaps supporting mental imagery which allows you a sense of the vividness of memories.  Indeed, bilateral damage to the inferior parietal lobe results in episodic memory that is largely intact, however it lacks details  and lesion patients report low levels of confidence in their memories.\nResearchers do not agree about how long episodic memories are stored in the hippocampus. Some researchers believe that episodic memories always rely on the hippocampus. Others believe the hippocampus only stores episodic memories for a short time, after which the memories are consolidated to the neocortex. The latter view is strengthened by recent evidence that neurogenesis in the adult hippocampus may ease the removal of old memories and increase the efficiency of forming new memories.\n\n\n## Relationship to semantic memory\n\nEndel Tulving originally described episodic memory as a record of a person's experience that held temporally dated information and spatio-temporal relations. A feature of episodic memory that Tulving later elaborates on is that it allows an agent to imagine traveling back in time. A current situation may cue retrieval of a previous episode, so that context that colours the previous episode is experienced at the immediate moment. The agent is provided with a means of associating previous feelings with current situations. Semantic memory, on the other hand, is a structured record of facts, concepts, and skills that we have acquired. Semantic information is derived from accumulated episodic memory. Episodic memory can be thought of as a \"map\" that ties together items in semantic memory. For example, all encounters with how a \"dog\" looks and sounds will make up the semantic representation of that word. All episodic memories concerning a dog will then reference this single semantic representation of \"dog\" and, likewise, all new experiences with the dog will modify the single semantic representation of that dog.\nTogether, semantic and episodic memory make up our declarative memory. They each represent different parts of context to form a complete picture. As such, something that affects episodic memory can also affect semantic memory. For example, anterograde amnesia, from damage of the medial temporal lobe, is an impairment of declarative memory that affects both episodic and semantic memory operations. Originally, Tulving proposed that episodic and semantic memory were separate systems that competed with each other in retrieval. However, this theory was rejected when Howard and Kahana completed experiments on latent semantic analysis (LSA) that supported the opposite. Instead of an increase in semantic similarity when there was a decrease in the strength of temporal associations, the two worked together so semantic cues on retrieval were strongest when episodic cues were strong as well.\n\n\n## Age differences\n\n\nEpisodic memory emerges at approximately 3 to 4 years of age. Activation of specific brain areas (mostly the hippocampus) seems to be different between younger (aged 23\u201339) and older people (aged 67\u201380) upon episodic memory retrieval. Older people tend to activate both their left and right hippocampus, while younger people activate only the left one.\n\n\n## Relationship to emotion\n\nThe relationship between emotion and memory is complex, but generally, emotion tends to increase the likelihood that an event will be remembered later and that it will be remembered vividly. Flashbulb memory is one example of this. Flashbulb memory is event-specific, which consists of depictions of personal experiences. For example, saying \"I remember seeing Grandma smile when I gave her the present\", or remembering the detailed events of the tragedy of 9/11. This idea of flashbulb memory was proposed by R. Brown and Kulik (1977), in which they stated that this idea revolves around remembering an event or unexpected circumstance due to emotional arousal. They referred to this memory as \"photographic vividness\". However, whether the vividness of the flashbulb memory is due to a virtual \"flash\" that occurs because of the emotional experience has been hotly contested. Flashbulb memories may occur because of our propensity to rehearse and retell those highly emotional events, which strengthens the memory.  R. Brown and Kulik represented that these memories contain information that falls under the categories: place, ongoing activity, informant, own affect, and aftermath. Flashbulb memory is usually perceived as highly accurate and consistent over time and are presented with great confidence, even if sometimes they are inaccurate. Authors Brown, Kulik, and Conway argued that these special memories involve the limbic system, specifically, the amygdala. There is an abundancy of research that shows the amygdala involvement regarding retrieval of emotional memories, for example, research using brain imaging techniques.\n\n\n## Pharmacological enhancement\n\nIn healthy adults, longterm visual episodic memory can be enhanced specifically through administration of the Acetylcholine esterase inhibitor Donepezil, whereas verbal episodic memory can be improved in persons with the val/val genotype of the val158met polymorphism through administration of the CNS penetrant specific catecholamine-O-methyltransferase inhibitor Tolcapone. Furthermore, episodic memory is enhanced through AZD3480, a selective agonist at the neuronal alpha4beta2 nicotinic receptor, which is developed by the company Targacept. Currently, there are several other products developed by several companies\u2014including new catecholamine-O-methyltransferase inhibitors with fewer side effects\u2014that aim for improving episodic memory. A recent placebo controlled study found that DHEA, which is a functional cortisol antagonist, improves episodic memory in healthy young men (Alhaj et al. 2006).\nA 2015 meta-analysis of high quality evidence found that therapeutic doses of amphetamine and methylphenidate improve performance on working memory, episodic memory, and inhibitory control tests in normal healthy adults.\n\n\n## Damage\n\nBased on a review of behavioral studies, it is suggested that there may be selective damage to the limbic-prefrontal episodic memory system in some autistic people. Another study exhibited evidence of autistic deficits in the episodic or self-conscious memory of personally experienced events.\nThe label \"amnesia\" is most often given to patients with deficits in episodic memory.\nAlzheimer's disease tends to damage the entorhinal cortex  and the hippocampus before other brain areas and this leads to episodic memory loss \nA rare type of shellfish poisoning called amnesic shellfish poisoning or \"ASP\" quite effectively and irreversibly damages the hippocampus, rendering one amnesic.\nKorsakoff's syndrome is caused by thiamine (vitamin B1) deficiency, a form of malnutrition which can be precipitated by overconsumption of alcohol compared to foods.\nAn acute cortisol level (by injection) has been found to significantly inhibit the recall of autobiographical memories which may contribute to memory deficits found in depression.\nThe use of MDMA (\"Ecstasy\") has been associated with persistent deficits in episodic memory.\n\n\n## In animals\n\n\nTulving (1983) proposed that to meet the criteria of episodic memory, evidence of conscious recollection must be provided. Demonstrating episodic memory in the absence of language, and thus in non-human animals, has been declared impossible as long as there are no agreed-upon non-linguistic behavioral indicators of conscious experience (Griffiths et al., 1999).\nThis idea was first challenged by Clayton and Dickinson in their work with the western scrub jay (Aphelocoma californica). They were able to demonstrate that these birds may possess an episodic-like memory system as they found that they remember where they cached different food types and discriminately recovered them depending on the perishability of the item and time that elapsed since caching. Thus, scrub-jays appear to remember the \"what-where-and-when\" of specific past caching events. The authors argued that such performance meets the behavioral criteria for episodic memory, but referred to the ability as \"episodic-like\" memory because the study did not address the phenomenological aspects of episodic memory.\nAccording to a study conducted by the University of Edinburgh (2006), hummingbirds were the first animal to demonstrate two of the aspects of episodic memory\u2014the ability to recall where certain flowers were located and how recently they were visited. Other studies have examined this type of memory in different animal species, such as dogs, rats, honey bees, and primates.\nThe ability of animals to encode and retrieve past experiences relies on the circuitry of the medial temporal lobe, a structure including the hippocampus. Animal lesion studies have provided significant findings related to the importance of particular brain structures in episodic-like memory. For example, hippocampal lesions have severely impacted all three components (what, where, and when) in animals, suggesting that the hippocampus is responsible for detecting novel events, stimuli, and places when forming new memories and retrieving that information later on.\nDespite similar neural areas and evidence from experiments, some scholars remain cautious about comparisons to human episodic memory. Purported episodic-like memory often seems fixed to a particular domain or could be explained in terms of procedural or semantic memory. The problem may be better tractable by studying episodic memory's adaptive counterpart: the capacity to flexibly imagine future events. However, a recent experiment addressed one of Suddendorf and Busby (2003)'s specific criticisms (the Bischof-K\u00f6hler hypothesis, which states that nonhuman animals can only take actions based on immediate needs, as opposed to future needs). Correia and colleagues demonstrated  that western scrub-jays can selectively cache different types of foods depending on which type of food they will desire at a future time, offering strong evidence against the Bischof-K\u00f6hler hypothesis by demonstrating that scrub-jays can flexibly adjust their behavior based on past experience of desiring a particular food. Similarities and differences between humans and other animals are currently much debated.\n\n\n## Autobiographical memory\n\nAn autobiographical memory is a personal representation of general or specific events and personal facts. Additionally, it also refers to the memory of a person's history. An individual does not remember exactly everything that has happened in one's past. Memory is constructive, where previous experience affects how we remember events and what we end up recalling from memory. Similarly, autobiographical memory is constructive and reconstructed as an evolving process of history. A person's autobiographical memory is fairly reliable, although the reliability of autobiographical memories is questionable because of memory distortions.\nAutobiographical memories can differ for special periods of life. For instance, people recall a few personal events from the first years of their lives. The loss of these first events is called childhood or infantile amnesia. Also, people tend to recall many personal events from adolescence and early adulthood. This effect is called the reminiscence bump. Additionally, people recall many personal events from their previous few years. For adolescents and young adults, the reminiscence bump and the recent events can coincide.\nIt is known that autobiographical memories initially are stored as episodic memories, but it is currently unknown if autobiographical memories are the same as episodic memories or if the autobiographical memories become converted to semantic memories with time.\n\n\n## Types\n\nSpecific events\nWhen you first set foot in the ocean.\nGeneral events\nWhat it feels like stepping into the ocean in general. This is a memory of what a personal event is generally like. It might be based on the memories of having stepped in the ocean, many times during the years.\nFlashbulb memories\nFlashbulb memories are critical autobiographical memories about a major event.\n\n\n## Neural network models\n\n\nEpisodic memories can be stored in autoassociative neural networks (e.g., a Hopfield network) if the stored representation includes information on the spatiotemporal context in which an item was studied. Smaller memories such as words or references said by someone are labeled as inactive or active neurons in the entorhinal cortex.\nNeural networks help us understand how the brain sends and receives different messages to the body, and how they are connected. These networks are a group of neurons or structures that are connected together. These structures work harmoniously to produce different cognitions within the brain. One of the largest proposals for this ideology is that of Diffusion Tensor Imaging. This technique traces the differing pathways of nerve fibres that further create communication throughout differing structures. These networks can be thought of as neural maps that can expand or contract according to the information being processed at that time. Neural Network Models can undergo learning patterns to use episodic memories to predict certain moments. Neural network models help the episodic memories by capturing the naturalistic state you are currently in such as scenery, rooms, time, smell, or even your current feeling.\n\n\n## See also\n\nBipolar disorder\nBorderline personality disorder\nRapid cycling\n\n\n## References\n\n\nDistinct processes shape flashbulb and event memories: Carla Tinti & Susanna Schmidt & Silvia Testa & Linda J. Levine https://search.ebscohost.com/login.aspx?direct=true&AuthType=sso&db=psyh&AN=2013-40035-001&site=ehost-live&custid=102-900\nFlashbulb memory recall in healthy adults \u2013 a functional magnetic resonance imaging study: B. Metternich, K. Spanhel, A. Schoendube, I. Ofer, M. J. Geiger, A. Schulze-Bonhage, H. Mast and K. Wagner  https://search.ebscohost.com/login.aspx?direct=true&AuthType=sso&db=psyh&AN=2020-61703-001&site=ehost-live&custid=102-900\n\n\n## Further reading\n\n\n\n## External links\n\n",
      "vector_count": 1,
      "vector_offset": 2
    },
    {
      "format": "md",
      "id": "PSY0028_Epistemology",
      "metadata": {
        "source_format": "md",
        "source_path": "/tmp/corpus_split_psychology/shard_005/PSY0028_Epistemology.md",
        "source_relpath": "PSY0028_Epistemology.md"
      },
      "path": "PSY0028_Epistemology.md",
      "text": "# Epistemology\n\nEpistemology is the branch of philosophy that examines the nature, origin, and limits of knowledge. Also called \"the theory of knowledge\", it explores different types of knowledge, such as propositional knowledge about facts, practical knowledge in the form of skills, and knowledge by acquaintance as a familiarity through experience. Epistemologists study the concepts of belief, truth, and justification to understand the nature of knowledge. To discover how knowledge arises, they investigate sources of justification, such as perception, introspection, memory, reason, and testimony.\nThe school of skepticism questions the human ability to attain knowledge, while fallibilism says that knowledge is never certain. Empiricists hold that all knowledge comes from sense experience, whereas rationalists believe that some knowledge does not depend on it. Coherentists argue that a belief is justified if it coheres with other beliefs. Foundationalists, by contrast, maintain that the justification of basic beliefs does not depend on other beliefs. Internalism and externalism debate whether justification is determined solely by mental states or also by external circumstances.\nSeparate branches of epistemology focus on knowledge in specific fields, like scientific, mathematical, moral, and religious knowledge. Naturalized epistemology relies on empirical methods and discoveries, whereas formal epistemology uses formal tools from logic. Social epistemology investigates the communal aspect of knowledge, and historical epistemology examines its historical conditions. Epistemology is closely related to psychology, which describes the beliefs people hold, while epistemology studies the norms governing the evaluation of beliefs. It also intersects with fields such as decision theory, education, and anthropology.\nEarly reflections on the nature, sources, and scope of knowledge are found in ancient Greek, Indian, and Chinese philosophy. The relation between reason and faith was a central topic in the medieval period. The modern era was characterized by the contrasting perspectives of empiricism and rationalism. Epistemologists in the 20th century examined the components, structure, and value of knowledge while integrating insights from the natural sciences and linguistics.\n\n\n## Definition\n\nEpistemology is the philosophical study of knowledge and related concepts, such as justification. Also called theory of knowledge, it examines the nature and types of knowledge. It further investigates the sources of knowledge, like perception, inference, and testimony, to understand how knowledge is created. Another set of questions concerns the extent and limits of knowledge, addressing what people can and cannot know. Central concepts in epistemology include belief, truth, evidence, and reason. As one of the main branches of philosophy, epistemology stands alongside fields like ethics, logic, and metaphysics. The term can also refer specific positions of philosophers within this branch, as in Plato's epistemology and Immanuel Kant's epistemology.\nEpistemology explores how people should acquire beliefs. It determines which beliefs or forms of belief acquisition meet the standards or epistemic goals of knowledge and which ones fail, thereby providing an evaluation of beliefs. The fields of psychology and cognitive sociology are also interested in beliefs and related cognitive processes, but examine them from a different perspective. Unlike epistemology, they study the beliefs people actually have and how people acquire them instead of examining the evaluative norms of these processes. In this regard, epistemology is a normative discipline, whereas psychology and cognitive sociology are descriptive disciplines. Epistemology is relevant to many descriptive and normative disciplines, such as the other branches of philosophy and the sciences, by exploring the principles of how they may arrive at knowledge.\nThe word epistemology comes from the ancient Greek terms \u1f10\u03c0\u03b9\u03c3\u03c4\u03ae\u03bc\u03b7 (episteme, meaning knowledge or understanding) and \u03bb\u03cc\u03b3\u03bf\u03c2 (logos, meaning study of or reason), literally, the study of knowledge. Despite its ancient roots, the word itself was coined only in the 19th century to designate this field as a distinct branch of philosophy.\n\n\n## Central concepts\n\nEpistemologists examine several foundational concepts to understand their essences and rely on them to formulate theories. Various epistemological disagreements have their roots in disputes about the nature and function of these concepts, like the controversies surrounding the definition of knowledge and the role of justification in it.\n\n\n### Knowledge\n\nKnowledge is an awareness, familiarity, understanding, or skill. Its various forms all involve a cognitive success through which a person establishes epistemic contact with reality. Epistemologists typically understand knowledge as an aspect of individuals, generally as a cognitive mental state that helps them understand, interpret, and interact with the world. While this core sense is of particular interest to epistemologists, the term also has other meanings. For example, the epistemology of groups examines knowledge as a characteristic of a group of people who share ideas. The term can also refer to information stored in documents and computers.\nKnowledge contrasts with ignorance, often simply defined as the absence of knowledge. Knowledge is usually accompanied by ignorance because people rarely have complete knowledge of a field, forcing them to rely on incomplete or uncertain information when making decisions. Even though many forms of ignorance can be mitigated through education and research, certain limits to human understanding result in inevitable ignorance. Some limitations are inherent in the human cognitive faculties themselves, such as the inability to know facts too complex for the human mind to conceive. Others depend on external circumstances when no access to the relevant information exists.\nEpistemologists disagree on how much people know, for example, whether fallible beliefs can amount to knowledge or whether absolute certainty is required. The most stringent position is taken by radical skeptics, who argue that there is no knowledge at all.\n\n\n=### Types=\n\nEpistemologists distinguish between different types of knowledge. Their primary interest is in knowledge of facts, called propositional knowledge. It is theoretical knowledge that can be expressed in declarative sentences using a that-clause, like \"Ravi knows that kangaroos hop\". For this reason, it is also called knowledge-that. Epistemologists often understand it as a relation between a knower and a known proposition, in the case above between the person Ravi and the proposition \"kangaroos hop\". It is use-independent since it is not tied to one specific purpose, unlike practical knowledge. It is a mental representation that embodies concepts and ideas to reflect reality. Because of its theoretical nature, it is typically held that only creatures with highly developed minds, such as humans, possess propositional knowledge.\nPropositional knowledge contrasts with non-propositional knowledge in the form of knowledge-how and knowledge by acquaintance. Knowledge-how is a practical ability or skill, like knowing how to read or how to prepare lasagna. It is usually tied to a specific goal and not mastered in the abstract without concrete practice. To know something by acquaintance means to have an immediate familiarity with or awareness of it, usually as a result of direct experiential contact. Examples are \"familiarity with the city of Perth\", \"knowing the taste of tsampa\", and \"knowing Marta Vieira da Silva personally\".\n\nAnother influential distinction in epistemology is between a posteriori and a priori knowledge. A posteriori knowledge is knowledge of empirical facts based on sensory experience, like \"seeing that the sun is shining\" and \"smelling that a piece of meat has gone bad\". This type of knowledge is associated with the empirical science and everyday affairs. A priori knowledge, by contrast, pertains to non-empirical facts and does not depend on evidence from sensory experience, like knowing that \n  \n    \n      \n        2\n        +\n        2\n        =\n        4\n      \n    \n    {\\displaystyle 2+2=4}\n  \n. It belongs to fields such as mathematics and logic. The distinction between a posteriori and a priori knowledge is central to the debate between empiricists and rationalists regarding whether all knowledge depends on sensory experience.\nA closely related contrast is between analytic and synthetic truths. A sentence is analytically true if its truth depends only on the meanings of the words it uses. For instance, the sentence \"all bachelors are unmarried\" is analytically true because the word \"bachelor\" already includes the meaning \"unmarried\". A sentence is synthetically true if its truth depends on additional facts. For example, the sentence \"snow is white\" is synthetically true because its truth depends on the color of snow in addition to the meanings of the words snow and white. A priori knowledge is primarily associated with analytic sentences, whereas a posteriori knowledge is primarily associated with synthetic sentences. However, it is controversial whether this is true for all cases. Some philosophers, such as Willard Van Orman Quine, reject the distinction, saying that there are no analytic truths.\n\n\n=### Analysis=\n\nThe analysis of knowledge is the attempt to identify the essential components or conditions of all and only propositional knowledge states. According to the so-called traditional analysis, knowledge has three components: it is a belief that is justified and true. In the second half of the 20th century, this view was challenged by a series of thought experiments aiming to show that some justified true beliefs do not amount to knowledge. In one of them, a person is unaware of all the fake barns in their area. By coincidence, they stop in front of the only real barn and form a justified true belief that it is a real barn. Many epistemologists agree that this is not knowledge because the justification is not directly relevant to the truth. More specifically, this and similar counterexamples involve some form of epistemic luck, that is, a cognitive success that results from fortuitous circumstances rather than competence.\n\nFollowing these thought experiments, philosophers proposed various alternative definitions of knowledge by modifying or expanding the traditional analysis. According to one view, the known fact has to cause the belief in the right way. Another theory states that the belief is the product of a reliable belief formation process. Further approaches require that the person would not have the belief if it was false, that the belief is not inferred from a falsehood, that the justification cannot be undermined, or that the belief is infallible. There is no consensus on which of the proposed modifications and reconceptualizations is correct. Some philosophers, such as Timothy Williamson, reject the basic assumption underlying the analysis of knowledge by arguing that propositional knowledge is a unique state that cannot be dissected into simpler components.\n\n\n=### Value=\nThe value of knowledge is the worth it holds by expanding understanding and guiding action. Knowledge can have instrumental value by helping a person achieve their goals. For example, knowledge of a disease helps a doctor cure their patient. The usefulness of a known fact depends on the circumstances. Knowledge of some facts may have little to no uses, like memorizing random phone numbers from an outdated phone book. Being able to assess the value of knowledge matters in choosing what information to acquire and share. It affects decisions like which subjects to teach at school and how to allocate funds to research projects.\nEpistemologists are particularly interested in whether knowledge is more valuable than a mere true opinion. Knowledge and true opinion often have a similar usefulness since both accurately represent reality. For example, if a person wants to go to Larissa, a true opinion about the directions can guide them as effectively as knowledge. Considering this problem, Plato proposed that knowledge is better because it is more stable. Another suggestion focuses on practical reasoning, arguing that people put more trust in knowledge than in mere true opinions when drawing conclusions and deciding what to do. A different response says that knowledge has intrinsic value in addition to instrumental value. This view asserts that knowledge is always valuable, whereas true opinion is only valuable in circumstances where it is useful.\n\n\n### Belief and truth\n\nBeliefs are mental states about what is the case, like believing that snow is white or that God exists. In epistemology, they are often understood as subjective attitudes that affirm or deny a proposition, which can be expressed in a declarative sentence. For instance, to believe that snow is white is to affirm the proposition \"snow is white\". According to this view, beliefs are representations of what the universe is like. They are stored in memory and retrieved when actively thinking about reality or deciding how to act. A different view understands beliefs as behavioral patterns or dispositions to act rather than as representational items stored in the mind. According to this perspective, to believe that there is mineral water in the fridge is nothing more than a group of dispositions related to mineral water and the fridge. Examples are the dispositions to answer questions about the presence of mineral water affirmatively and to go to the fridge when thirsty. Some theorists deny the existence of beliefs, saying that this concept borrowed from folk psychology oversimplifies much more complex psychological or neurological processes. Beliefs are central to various epistemological debates, which cover their status as a component of propositional knowledge, the question of whether people have control over and responsibility for their beliefs, and the issue of whether beliefs have degrees, called credences.\nAs propositional attitudes, beliefs are true or false depending on whether they affirm a true or a false proposition. According to the correspondence theory of truth, to be true means to stand in the right relation to the world by accurately describing what it is like. This means that truth is objective: a belief is true if it corresponds to a fact. The coherence theory of truth says that a belief is true if it belongs to a coherent system of beliefs. A result of this view is that truth is relative since it depends on other beliefs. Further theories of truth include pragmatist, semantic, pluralist, and deflationary theories. Truth plays a central role in epistemology as a goal of cognitive processes and an attribute of propositional knowledge.\n\n\n### Justification\n\nIn epistemology, justification is a property of beliefs that meet certain norms about what a person should believe. According to a common view, this means that the person has sufficient reasons for holding this belief because they have information that supports it. Another view states that a belief is justified if it is formed by a reliable belief formation process, such as perception. The terms reasonable, warranted, and supported are sometimes used as synonyms of the word justified. Justification distinguishes well-founded beliefs from superstition and lucky guesses. However, it does not guarantee truth. For example, a person with strong but misleading evidence may form a justified belief that is false.\nEpistemologists often identify justification as a key component of knowledge. Usually, they are not only interested in whether a person has a sufficient reason to hold a belief, known as propositional justification, but also in whether the person holds the belief because or based on this reason, known as doxastic justification. For example, if a person has sufficient reason to believe that a neighborhood is dangerous but forms this belief based on superstition then they have propositional justification but lack doxastic justification.\n\n\n=### Sources=\nSources of justification are ways or cognitive capacities through which people acquire justification. Often-discussed sources include perception, introspection, memory, reason, and testimony, but there is no universal agreement to what extent they all provide valid justification. Perception relies on sensory organs to gain empirical information. Distinct forms of perception correspond to different physical stimuli, such as visual, auditory, haptic, olfactory, and gustatory perception. Perception is not merely the reception of sense impressions but an active process that selects, organizes, and interprets sensory signals. Introspection is a closely related process focused on internal mental states rather than external physical objects. For example, seeing a bus at a bus station belongs to perception while feeling tired belongs to introspection.\nRationalists understand reason as a source of justification for non-empirical facts, explaining how people can know about mathematical, logical, and conceptual truths. Reason is also responsible for inferential knowledge, in which one or more beliefs serve as premises to support another belief. Memory depends on information provided by other sources, which it retains and recalls, like remembering a phone number perceived earlier. Justification by testimony relies on information one person communicates to another person. This can happen by talking to each other but can also occur in other forms, like a letter, a newspaper, and a blog.\n\n\n### Other concepts\nRationality is closely related to justification and the terms rational belief and justified belief are sometimes used interchangeably. However, rationality has a wider scope that encompasses both a theoretical side, covering beliefs, and a practical side, covering decisions, intentions, and actions. There are different conceptions about what it means for something to be rational. According to one view, a mental state is rational if it is based on or responsive to good reasons. Another view emphasizes the role of coherence, stating that rationality requires that the different mental states of a person are consistent and support each other. A slightly different approach holds that rationality is about achieving certain goals. Two goals of theoretical rationality are accuracy and comprehensiveness, meaning that a person has as few false beliefs and as many true beliefs as possible.\nEpistemologists rely on the concept of epistemic norms as criteria to assess the cognitive quality of beliefs, like their justification and rationality. They distinguish between deontic norms, which prescribe what people should believe, and axiological norms, which identify the goals and values of beliefs. Epistemic norms are closely linked to intellectual or epistemic virtues, which are character traits like open-mindedness and conscientiousness. Epistemic virtues help individuals form true beliefs and acquire knowledge. They contrast with epistemic vices and act as foundational concepts of virtue epistemology.\nEpistemologists understand evidence for a belief as information that favors or supports it. They conceptualize evidence primarily in terms of mental states, such as sensory impressions or other known propositions. But in a wider sense, it can also include physical objects, like bloodstains examined by forensic analysts or financial records studied by investigative journalists. Evidence is often understood in terms of probability: evidence for a belief makes it more likely that the belief is true. A defeater is evidence against a belief or evidence that undermines another piece of evidence. For instance, witness testimony linking a suspect to a crime is evidence of their guilt, while an alibi is a defeater. Evidentialists analyze justification in terms of evidence by asserting that for a belief to be justified, it needs to rest on adequate evidence.\nThe presence of evidence usually affects doubt and certainty, which are subjective attitudes toward propositions that differ regarding their level of confidence. Doubt involves questioning the validity or truth of a proposition. Certainty, by contrast, is a strong affirmative conviction, indicating an absence of doubt about the proposition's truth. Doubt and certainty are central to ancient Greek skepticism and its goal of establishing that no belief is immune to doubt. They are also crucial in attempts to find a secure foundation of all knowledge, such as Ren\u00e9 Descartes' foundationalist epistemology.\nWhile propositional knowledge is the main topic in epistemology, some theorists focus on understanding instead. Understanding is a more holistic notion that involves a wider grasp of a subject. To understand something, a person requires awareness of how different things are connected and why they are the way they are. For example, knowledge of isolated facts memorized from a textbook does not amount to understanding. According to one view, understanding is a unique epistemic good that, unlike propositional knowledge, is always intrinsically valuable. Wisdom is similar in this regard and is sometimes considered the highest epistemic good. It encompasses a reflective understanding with practical applications, helping people grasp and evaluate complex situations and lead a good life.\nIn epistemology, knowledge ascription is the act of attributing knowledge to someone, expressed in sentences like \"Sarah knows that it will rain today\". According to invariantism, knowledge ascriptions have fixed standards across different contexts. Contextualists, by contrast, argue that knowledge ascriptions are context-dependent. From this perspective, Sarah may know about the weather in the context of an everyday conversation even though she is not sufficiently informed to know it in the context of a rigorous meteorological debate. Contrastivism, another view, argues that knowledge ascriptions are comparative, meaning that to know something involves distinguishing it from relevant alternatives. For example, if a person spots a bird in the garden, they may know that it is a sparrow rather than an eagle, but they may not know that it is a sparrow rather than an indistinguishable sparrow hologram.\n\n\n## Major schools of thought\n\n\n\n### Skepticism and fallibilism\n\nPhilosophical skepticism questions the human ability to attain knowledge by challenging the foundations upon which knowledge claims rest. Some skeptics limit their criticism to specific domains of knowledge. For example, religious skeptics say that it is impossible to know about the existence of deities or the truth of other religious doctrines. Similarly, moral skeptics challenge the existence of moral knowledge and metaphysical skeptics say that humans cannot know ultimate reality. External world skepticism questions knowledge of external facts, whereas skepticism about other minds doubts knowledge of the mental states of others.\nGlobal skepticism is the broadest form of skepticism, asserting that there is no knowledge in any domain. In ancient philosophy, this view was embraced by academic skeptics, whereas Pyrrhonian skeptics recommended the suspension of belief to attain tranquility. Few epistemologists have explicitly defended global skepticism. The influence of this position stems from attempts by other philosophers to show that their theory overcomes the challenge of skepticism. For example, Ren\u00e9 Descartes used methodological doubt to find facts that cannot be doubted.\nOne consideration in favor of global skepticism is the dream argument. It starts from the observation that, while people are dreaming, they are usually unaware of this. This inability to distinguish between dream and regular experience is used to argue that there is no certain knowledge since a person can never be sure that they are not dreaming. Some critics assert that global skepticism is self-refuting because denying the existence of knowledge is itself a knowledge claim. Another objection says that the abstract reasoning leading to skepticism is not convincing enough to overrule common sense.\nFallibilism is another response to skepticism. Fallibilists agree with skeptics that absolute certainty is impossible. They reject the assumption that knowledge requires absolute certainty, leading them to the conclusion that fallible knowledge exists. They emphasize the need to keep an open and inquisitive mind, acknowledging that doubt can never be fully excluded, even for well-established knowledge claims like thoroughly tested scientific theories.\nEpistemic relativism is related to skepticism but differs in that it does not question the existence of knowledge in general. Instead, epistemic relativists only reject the notion of universal epistemic standards or absolute principles that apply equally to everyone. This means that what a person knows depends on subjective criteria or social conventions used to assess epistemic status.\n\n\n### Empiricism and rationalism\n\nThe debate between empiricism and rationalism centers on the origins of human knowledge. Empiricism emphasizes that sense experience is the primary source of all knowledge. Some empiricists illustrate this view by describing the mind as a blank slate that only develops ideas about the external world through the sense data received from the sensory organs. According to them, the mind can attain various additional insights by comparing impressions, combining them, generalizing to form more abstract ideas, and deducing new conclusions from them. Empiricists say that all these mental operations depend on sensory material and do not function on their own.\nEven though rationalists usually accept sense experience as one source of knowledge, they argue that certain forms of knowledge are directly accessed through reason without sense experience, like knowledge of mathematical and logical truths. Some forms of rationalism state that the mind possesses inborn ideas, accessible without sensory assistance. Others assert that there is an additional cognitive faculty, sometimes called rational intuition, through which people acquire nonempirical knowledge. Some rationalists limit their discussion to the origin of concepts, saying that the mind relies on inborn categories to understand the world and organize experience.\n\n\n### Foundationalism and coherentism\n\nFoundationalists and coherentists disagree about the structure of knowledge. Foundationalism distinguishes between basic and non-basic beliefs. A belief is basic if it is justified directly, meaning that its validity does not depend on the support of other beliefs. A belief is non-basic if it is justified by another belief. For example, the belief that it rained last night is a non-basic belief if it is inferred from the observation that the street is wet. According to foundationalism, basic beliefs are the foundation on which all other knowledge is built while non-basic beliefs act as the superstructure resting on this foundation.\nCoherentists reject the distinction between basic and non-basic beliefs, saying that the justification of any belief depends on other beliefs. They assert that a belief must align with other beliefs to amount to knowledge. This occurs when beliefs are consistent and support each other. According to coherentism, justification is a holistic aspect determined by the whole system of beliefs, which resembles an interconnected web.\nFoundherentism is an intermediary position combining elements of both foundationalism and coherentism. It accepts the distinction between basic and non-basic beliefs while asserting that the justification of non-basic beliefs depends on coherence with other beliefs.\nInfinitism presents a less common alternative perspective on the structure of knowledge. It agrees with coherentism that there are no basic beliefs while rejecting the view that beliefs can support each other in a circular manner. Instead, it argues that beliefs form infinite justification chains, in which each link of the chain supports the belief following it and is supported by the belief preceding it.\n\n\n### Internalism and externalism\n\nThe disagreement between internalism and externalism is about the sources of justification. Internalists say that justification depends only on factors within the individual, such as perceptual experience, memories, and other beliefs. This view emphasizes the importance of the cognitive perspective of the individual in the form of their mental states. It is commonly associated with the idea that the relevant factors are accessible, meaning that the individual can become aware of their reasons for holding a justified belief through introspection and reflection.\nEvidentialism is an influential internalist view, asserting that justification depends on the possession of evidence. In this context, evidence for a belief is any information in the individual's mind that supports the belief. For example, the perceptual experience of rain is evidence for the belief that it is raining. Evidentialists suggest various other forms of evidence, including memories, intuitions, and other beliefs. According to evidentialism, a belief is justified if the individual's evidence supports it and they hold the belief on the basis of this evidence.\nExternalism, by contrast, asserts that at least some relevant factors of knowledge are external to the individual. For instance, when considering the belief that a cup of coffee stands on the table, externalists are not primarily interested in the subjective perceptual experience that led to this belief. Instead, they focus on objective factors, like the quality of the person's eyesight, their ability to differentiate coffee from other beverages, and the circumstances under which they observed the cup. A key motivation of many forms of externalism is that justification makes it more likely that a belief is true. Based on this view, justification is external to the extent that some factors contributing to this likelihood are not part of the believer's cognitive perspective.\nReliabilism is an externalist theory asserting that a reliable connection between belief and truth is required for justification. Some reliabilists explain this in terms of reliable processes. According to this view, a belief is justified if it is produced by a reliable process, like perception. A belief-formation process is deemed reliable if most of the beliefs it generates are true. An alternative view focuses on beliefs rather than belief-formation processes, saying that a belief is justified if it is a reliable indicator of the fact it presents. This means that the belief tracks the fact: the person believes it because it is true but would not believe it otherwise.\nVirtue epistemology, another type of externalism, asserts that a belief is justified if it manifests intellectual virtues. Intellectual virtues are capacities or traits that perform cognitive functions and help people form true beliefs. Suggested examples include faculties, like vision, memory, and introspection, and character traits, like open-mindedness.\n\n\n## Branches and approaches\n\nSome branches of epistemology are characterized by their research methods. Formal epistemology employs formal tools from logic and mathematics to investigate the nature of knowledge. For example, Bayesian epistemology represents beliefs as degrees of certainty and uses probability theory to formally define norms of rationality governing how certain people should be. Experimental epistemologists base their research on empirical evidence about common knowledge practices. Applied epistemology focuses on the practical application of epistemological principles to diverse real-world problems, like the reliability of knowledge claims on the internet, how to assess sexual assault allegations, and how racism may lead to epistemic injustice. Metaepistemologists study the nature, goals, and research methods of epistemology. As a metatheory, it does not directly advocate for specific epistemological theories but examines their fundamental concepts and background assumptions.\nParticularism and generalism disagree about the right method of conducting epistemological research. Particularists start their inquiry by looking at specific cases. For example, to find a definition of knowledge, they rely on their intuitions about concrete instances of knowledge and particular thought experiments. They use these observations as methodological constraints that any theory of general principles needs to follow. Generalists proceed in the opposite direction. They prioritize general epistemic principles, saying that it is not possible to accurately identify and describe specific cases without a grasp of these principles. Other methods in contemporary epistemology aim to extract philosophical insights from ordinary language or look at the role of knowledge in making assertions and guiding actions.\nPhenomenological epistemology emphasizes the importance of first-person experience. It distinguishes between the natural and the phenomenological attitudes. The natural attitude focuses on objects belonging to common sense and natural science. The phenomenological attitude focuses on the experience of objects and aims to provide a presuppositionless description of how objects appear to the observer.\nNaturalized epistemology is closely associated with the natural sciences, relying on their methods and theories to examine knowledge. Arguing that epistemological theories should rest on empirical observation, it is critical of a priori reasoning. Evolutionary epistemology is a naturalistic approach that understands cognition as a product of evolution, examining knowledge and the cognitive faculties responsible for it through the lens of natural selection. Social epistemology focuses on the social dimension of knowledge. While traditional epistemology is mainly interested in the knowledge possessed by individuals, social epistemology covers knowledge acquisition, transmission, and evaluation within groups, with specific emphasis on how people rely on each other when seeking knowledge.\nPragmatist epistemology is a form of fallibilism that emphasizes the close relation between knowing and acting. It sees the pursuit of knowledge as an ongoing process guided by common sense and experience while always open to revision. This approach reinterprets some core epistemological notions, for example, by conceptualizing beliefs as habits that shape actions rather than representations that mirror the world. Motivated by pragmatic considerations, epistemic conservatism is a view about belief revision. It prioritizes pre-existing beliefs, asserting that a person should only change their beliefs if they have a good reason to. One argument for epistemic conservatism rests on the recognition that the cognitive resources of humans are limited, making it impractical to constantly reexamine every belief.\n\nPostmodern epistemology critiques the conditions of knowledge in advanced societies. This concerns in particular the metanarrative of a constant progress of scientific knowledge leading to a universal and foundational understanding of reality. Similarly, feminist epistemology adopts a critical perspective, focusing on the effect of gender on knowledge. Among other topics, it explores how preconceptions about gender influence who has access to knowledge, how knowledge is produced, and which types of knowledge are valued in society. Some postmodern and feminist thinkers adopt a constructivist approach, arguing that the way people view the world is not a simple reflection of external reality but a social construction. This view emphasizes the creative role of interpretation while undermining objectivity since social constructions can vary across societies. Another critical approach, found in decolonial scholarship, opposes the global influence of Western knowledge systems. It seeks to undermine Western hegemony and decolonize knowledge.\nThe decolonial outlook is also present in African epistemology. Grounded in African ontology, it emphasizes the interconnectedness of reality as a continuum between knowing subject and known object. It understands knowledge as a holistic phenomenon that includes sensory, emotional, intuitive, and rational aspects, extending beyond the limits of the physical domain.\nAnother epistemological tradition is found in ancient Indian philosophy. Its diverse schools of thought examine different sources of knowledge, called pram\u0101\u1e47a. Perception, inference, and testimony are sources discussed by most schools. Other sources only considered by some schools are non-perception, which leads to knowledge of absences, and presumption. Buddhist epistemology focuses on immediate experience, understood as the presentation of unique particulars without secondary cognitive processes, like thought and desire. Ny\u0101ya epistemology is a causal theory of knowledge, understanding sources of knowledge as reliable processes that cause episodes of truthful awareness. It sees perception as the primary source of knowledge and emphasizes its importance for successful action. M\u012bm\u0101\u1e43s\u0101 epistemology considers the holy scriptures known as the Vedas as a key source of knowledge, addressing the problem of their right interpretation. Jain epistemology states that reality is many-sided, meaning that no single viewpoint can capture the entirety of truth.\nHistorical epistemology examines how the understanding of knowledge and related concepts has changed over time. It asks whether the main issues in epistemology are perennial and to what extent past epistemological theories are relevant to contemporary debates. It is particularly concerned with scientific knowledge and practices associated with it. It contrasts with the history of epistemology, which presents, reconstructs, and evaluates epistemological theories of philosophers in the past.\n\n\n### Knowledge in particular domains\nSome branches of epistemology focus on knowledge within specific academic disciplines. The epistemology of science examines how scientific knowledge is generated and what problems arise in the process of validating, justifying, and interpreting scientific claims. A key issue concerns the problem of how individual observations can support universal scientific laws. Other topics include the nature of scientific evidence and the aims of science. The epistemology of mathematics studies the origin of mathematical knowledge. In exploring how mathematical theories are justified, it investigates the role of proofs and whether there are empirical sources of mathematical knowledge.\nDistinct areas of epistemology are dedicated to specific sources of knowledge. Examples are the epistemology of perception, the epistemology of memory, and the epistemology of testimony. In the epistemology of perception, direct and indirect realists debate the connection between the perceiver and the perceived object. Direct realists say that this connection is direct, meaning that there is no difference between the object present in perceptual experience and the physical object causing this experience. According to indirect realism, the connection is indirect, involving mental entities, like ideas or sense data, that mediate between the perceiver and the external world. The contrast between direct and indirect realism is important for explaining the nature of illusions.\nEpistemological issues are found in most areas of philosophy. The epistemology of logic examines how people know that an argument is valid. For example, it explores how logicians justify that modus ponens is a correct rule of inference or that all contradictions are false. Epistemologists of metaphysics investigate whether knowledge of the basic structure of reality is possible and what sources this knowledge could have. Knowledge of moral statements, like the claim that lying is wrong, belongs to the epistemology of ethics. It studies the role of ethical intuitions, coherence among moral beliefs, and the problem of moral disagreement. The ethics of belief is a closely related field exploring the intersection of epistemology and ethics. It examines the norms governing belief formation and asks whether violating them is morally wrong. Religious epistemology studies the role of knowledge and justification for religious doctrines and practices. It evaluates the reliability of evidence from religious experience and holy scriptures while also asking whether the norms of reason should be applied to religious faith.\nEpistemologists of language explore the nature of linguistic knowledge. One of their topics is the role of tacit knowledge, for example, when native speakers have mastered the rules of grammar but are unable to explicitly articulate them. Epistemologists of modality examine knowledge about what is possible and necessary. Epistemic problems that arise when two people have diverging opinions on a topic are covered by the epistemology of disagreement. Epistemologists of ignorance are interested in epistemic faults and gaps in knowledge.\n\n\n## Related fields\n\nEpistemology and psychology were not defined as distinct fields until the 19th century; earlier investigations about knowledge often do not fit neatly into today's academic categories. Both contemporary disciplines study beliefs and the mental processes responsible for their formation and change. One key contrast is that psychology describes what beliefs people have and how they acquire them, thereby explaining why someone has a specific belief. The focus of epistemology is on evaluating beliefs, leading to a judgment about whether a belief is justified and rational in a particular case. Epistemology also shares a close connection with cognitive science, which understands mental events as processes that transform information. Artificial intelligence relies on the insights of epistemology and cognitive science to implement concrete solutions to problems associated with knowledge representation and automatic reasoning.\nLogic is the study of correct reasoning. For epistemology, it is relevant to inferential knowledge, which arises when a person reasons from one known fact to another. This is the case, for example, when inferring that it rained based on the observation that the streets are wet. Whether an inferential belief amounts to knowledge depends on the form of reasoning used, in particular, that the process does not violate the laws of logic. Another overlap between the two fields is found in the epistemic approach to fallacies. Fallacies are faulty arguments based on incorrect reasoning. The epistemic approach to fallacies explains why they are faulty, stating that arguments aim to expand knowledge. According to this view, an argument is a fallacy if it fails to do so. A further intersection is found in epistemic logic, which uses formal logical devices to study epistemological concepts like knowledge and belief.\nBoth decision theory and epistemology are interested in the foundations of rational thought and the role of beliefs. Unlike many approaches in epistemology, the main focus of decision theory lies less in the theoretical and more in the practical side, exploring how beliefs are translated into action. Decision theorists examine the reasoning involved in decision-making and the standards of good decisions, identifying beliefs as a central aspect of decision-making. One of their innovations is to distinguish between weaker and stronger beliefs, which helps them consider the effects of uncertainty on decisions.\nEpistemology and education have a shared interest in knowledge, with one difference being that education focuses on the transmission of knowledge, exploring the roles of both learner and teacher. Learning theory examines how people acquire knowledge. Behavioral learning theories explain the process in terms of behavior changes, for example, by associating a certain response with a particular stimulus. Cognitive learning theories study how the cognitive processes that affect knowledge acquisition transform information. Pedagogy looks at the transmission of knowledge from the teacher's perspective, exploring the teaching methods they may employ. In teacher-centered methods, the teacher serves as the main authority delivering knowledge and guiding the learning process. In student-centered methods, the teacher primarily supports and facilitates the learning process, allowing students to take a more active role. The beliefs students have about knowledge, called personal epistemology, influence their intellectual development and learning success.\nThe anthropology of knowledge examines how knowledge is acquired, stored, retrieved, and communicated. It studies the social and cultural circumstances that affect how knowledge is reproduced and changes, covering the role of institutions like university departments and scientific journals as well as face-to-face discussions and online communications. This field has a broad concept of knowledge, encompassing various forms of understanding and culture, including practical skills. Unlike epistemology, it is not interested in whether a belief is true or justified but in how understanding is reproduced in society. A closely related field, the sociology of knowledge has a similar conception of knowledge. It explores how physical, demographic, economic, and sociocultural factors impact knowledge. This field examines in what sociohistorical contexts knowledge emerges and the effects it has on people, for example, how socioeconomic conditions are related to the dominant ideology in a society.\n\n\n## History\n\n\nEarly reflections on the nature and sources of knowledge are found in ancient history. In ancient Greek philosophy, Plato (427\u2013347 BCE) studied what knowledge is, examining how it differs from true opinion by being based on good reasons. He proposed that learning is a form of recollection in which the soul remembers what it already knew but had forgotten. Plato's student Aristotle (384\u2013322 BCE) was particularly interested in scientific knowledge, exploring the role of sensory experience and the process of making inferences from general principles. Aristotle's ideas influenced the Hellenistic schools of philosophy, which began to arise in the 4th century BCE and included Epicureanism, Stoicism, and skepticism. The Epicureans had an empiricist outlook, stating that sensations are always accurate and act as the supreme standard of judgments. The Stoics defended a similar position but confined their trust to lucid and specific sensations, which they regarded as true. The skeptics questioned that knowledge is possible, recommending instead suspension of judgment to attain a state of tranquility. Emerging in the 3rd century CE and inspired by Plato's philosophy, Neoplatonism distinguished knowledge from true belief, arguing that knowledge is infallible and limited to the realm of immaterial forms.\n\nThe Upanishads, philosophical scriptures composed in ancient India between 700 and 300 BCE, examined how people acquire knowledge, including the role of introspection, comparison, and deduction. In the 6th century BCE, the school of Aj\u00f1ana developed a radical skepticism questioning the possibility and usefulness of knowledge. By contrast, the school of Nyaya, which emerged in the 2nd century BCE, asserted that knowledge is possible. It provided a systematic treatment of how people acquire knowledge, distinguishing between valid and invalid sources. When Buddhist philosophers became interested in epistemology, they relied on concepts developed in Nyaya and other traditions. Buddhist philosopher Dharmakirti (6th or 7th century CE) analyzed the process of knowing as a series of causally related events.\nAncient Chinese philosophers understood knowledge as an interconnected phenomenon fundamentally linked to ethical behavior and social involvement. Many saw wisdom as the goal of attaining knowledge. Mozi (470\u2013391 BCE) proposed a pragmatic approach to knowledge using historical records, sensory evidence, and practical outcomes to validate beliefs. Mencius (c.\u2009372\u2013289 BCE) explored analogical reasoning as a source of knowledge and employed this method to criticize Mozi. Xunzi (c.\u2009310\u2013220 BCE) aimed to combine empirical observation and rational inquiry. He emphasized the importance of clarity and standards of reasoning without excluding the role of feeling and emotion.\nThe relation between reason and faith was a central topic in the medieval period. In Arabic\u2013Persian philosophy, al-Farabi (c.\u2009870\u2013950) and Averroes (1126\u20131198) discussed how philosophy and theology interact, debating which one is a better vehicle to truth. Al-Ghazali (c.\u20091056\u20131111) criticized many core teachings of previous Islamic philosophers, saying that they relied on unproven assumptions that did not amount to knowledge. Similarly in Western philosophy, Anselm of Canterbury (1033\u20131109) proposed that theological teaching and philosophical inquiry are in harmony and complement each other. Formulating a more critical approach, Peter Abelard (1079\u20131142) argued against unquestioned theological authorities and said that all things are open to rational doubt. Influenced by Aristotle, Thomas Aquinas (1225\u20131274) developed an empiricist theory, stating that \"nothing is in the intellect unless it first appeared in the senses\". According to an early form of direct realism proposed by William of Ockham (c.\u20091285\u20131349), perception of mind-independent objects happens directly without intermediaries. Meanwhile, in 14th-century India, Ga\u1e45ge\u015ba developed a reliabilist theory of knowledge and considered the problems of testimony and fallacies. In China, Wang Yangming (1472\u20131529) explored the unity of knowledge and action, holding that moral knowledge is inborn and can be attained by overcoming self-interest.\n\nThe course of modern philosophy was shaped by Ren\u00e9 Descartes (1596\u20131650), who stated that philosophy must begin from a position of indubitable knowledge of first principles. Inspired by skepticism, he aimed to find absolutely certain knowledge by encountering truths that cannot be doubted. He thought that this is the case for the assertion \"I think, therefore I am\", from which he constructed the rest of his philosophical system. Descartes, together with Baruch Spinoza (1632\u20131677) and Gottfried Wilhelm Leibniz (1646\u20131716), belonged to the school of rationalism, which asserts that the mind possesses innate ideas independent of experience. John Locke (1632\u20131704) rejected this view in favor of an empiricism according to which the mind is a blank slate. This means that all ideas depend on experience, either as \"ideas of sense\", which are directly presented through the senses, or as \"ideas of reflection\", which the mind creates by reflecting on its own activities. David Hume (1711\u20131776) used this idea to explore the limits of what people can know. He said that knowledge of facts is never certain, adding that knowledge of relations between ideas, like mathematical truths, can be certain but contains no information about the world. Immanuel Kant (1724\u20131804) sought a middle ground between rationalism and empiricism by identifying a type of knowledge overlooked by Hume. For Kant, this knowledge pertains to principles that underlie and structure all experience, such as spatial and temporal relations and fundamental categories of understanding.\nIn the 19th century and influenced by Kant's philosophy, Georg Wilhelm Friedrich Hegel (1770\u20131831) rejected empiricism by arguing that sensory impressions alone cannot amount to knowledge since all knowledge is actively structured by the knowing subject. John Stuart Mill (1806\u20131873), by contrast, defended a wide-sweeping form of empiricism and explained knowledge of general truths through inductive reasoning. Charles Peirce (1839\u20131914) thought that all knowledge is fallible, emphasizing that knowledge seekers should remain open to revising their beliefs in light of new evidence. He used this idea to argue against Cartesian foundationalism, which seeks absolutely certain truths.\nIn the 20th century, fallibilism was further explored by J. L. Austin (1911\u20131960) and Karl Popper (1902\u20131994). In continental philosophy, Edmund Husserl (1859\u20131938) applied the skeptical idea of suspending judgment to the study of experience. By not judging whether an experience is accurate, he tried to describe its internal structure instead. Influenced by earlier empiricists, logical positivists, like A. J. Ayer (1910\u20131989), said that all knowledge is either empirical or analytic, rejecting any form of metaphysical knowledge. Bertrand Russell (1872\u20131970) developed an empiricist sense-datum theory, distinguishing between direct knowledge by acquaintance of sense data and indirect knowledge by description, which is inferred from knowledge by acquaintance. Common sense had a central place in G. E. Moore's (1873\u20131958) epistemology. He used trivial observations, like the fact that he has two hands, to argue against abstract philosophical theories that deviate from common sense. Ordinary language philosophy, as practiced by the late Ludwig Wittgenstein (1889\u20131951), is a similar approach that tries to extract epistemological insights from how ordinary language is used.\nEdmund Gettier (1927\u20132021) conceived counterexamples against the idea that knowledge is justified true belief. These counterexamples prompted many philosophers to suggest alternative definitions of knowledge. Developed by philosophers such as Alvin Goldman (1938\u20132024), reliabilism emerged as one of the alternatives, asserting that knowledge requires reliable sources and shifting the focus away from justification. Virtue epistemologists, such as Ernest Sosa (1940\u2013present) and Linda Zagzebski (1946\u2013present), analyse belief formation in terms of the intellectual virtues or cognitive competencies involved in the process. Naturalized epistemology, as conceived by Willard Van Orman Quine (1908\u20132000), employs concepts and ideas from the natural sciences to formulate its theories. Other developments in late 20th-century epistemology were the emergence of social, feminist, and historical epistemology.\n\n\n## See also\n\n\nEpistemological pluralism \u2013 School of thought in epistemology\nKnowledge falsification \u2013 Deliberate misrepresentation of knowledge\nLogology (science)\nReformed epistemology \u2013 School of philosophical thought\nTheory of Knowledge (IB Course) \u2013 Compulsory International Baccalaureate subjectPages displaying short descriptions of redirect targets\n\n\n## References\n\n",
      "vector_count": 1,
      "vector_offset": 3
    },
    {
      "format": "md",
      "id": "PSY0029_Expressive_aphasia",
      "metadata": {
        "source_format": "md",
        "source_path": "/tmp/corpus_split_psychology/shard_005/PSY0029_Expressive_aphasia.md",
        "source_relpath": "PSY0029_Expressive_aphasia.md"
      },
      "path": "PSY0029_Expressive_aphasia.md",
      "text": "# Expressive_aphasia\n\nExpressive aphasia (also known as Broca's aphasia) is a type of aphasia characterized by partial loss of the ability to produce language (spoken, manual, or written), although comprehension generally remains intact. A person with expressive aphasia will exhibit effortful speech. Speech generally includes important content words but leaves out function words that have more grammatical significance than physical meaning, such as prepositions and articles. This is known as \"telegraphic speech\". The person's intended message may still be understood, but their sentence will not be grammatically correct. In very severe forms of expressive aphasia, a person may only speak using single word utterances. Typically, comprehension is mildly to moderately impaired in expressive aphasia due to difficulty understanding complex grammar.\nIt is caused by acquired damage to the frontal regions of the brain, such as Broca's area. Expressive aphasia contrasts with receptive aphasia, in which patients are able to speak in grammatical sentences that lack semantic significance and generally also have trouble with comprehension. Expressive aphasia differs from dysarthria, which is typified by a patient's inability to properly move the muscles of the tongue and mouth to produce speech. Expressive aphasia also differs from apraxia of speech, which is a motor disorder characterized by an inability to create and sequence motor plans for conscious speech.\n\n\n## Signs and symptoms\n\nBroca's (expressive) aphasia is a type of non-fluent aphasia in which an individual's speech is halting and effortful. Misarticulations or distortions of consonants and vowels, namely phonetic dissolution, are common. Individuals with expressive aphasia may only produce single words, or words in groups of two or three. Long pauses between words are common and multi-syllabic words may be produced one syllable at a time with pauses between each syllable. The prosody of a person with Broca's aphasia is compromised by shortened length of utterances and the presence of self-repairs and disfluencies. Intonation and stress patterns are also deficient.\n\nFor example, in the following passage, a patient with Broca's aphasia is trying to explain how he came to the hospital for dental surgery:Yes... ah... Monday... er... Dad and Peter H... (his own name), and Dad.... er... hospital... and ah... Wednesday... Wednesday, nine o'clock... and oh... Thursday... ten o'clock, ah doctors... two... an' doctors... and er... teeth... yah.The speech of a person with expressive aphasia contains mostly content words such as nouns, verbs, and some adjectives. However, function words like conjunctions, articles, and prepositions are rarely used except for \"and\" which is prevalent in the speech of most patients with aphasia. The omission of function words makes the person's speech agrammatic. A communication partner of a person with aphasia may say that the person's speech sounds telegraphic due to poor sentence construction and disjointed words. For example, a person with expressive aphasia might say \"Smart... university... smart... good... good...\"\nSelf-monitoring is typically well preserved in patients with Broca's aphasia. They are usually aware of their communication deficits, and are more prone to depression and outbursts from frustration than are patients with other forms of aphasia.\nIn general, word comprehension is preserved, allowing patients to have functional receptive language skills. Individuals with Broca's aphasia understand most of the everyday conversation around them, but higher-level deficits in receptive language can occur. Because comprehension is substantially impaired for more complex sentences, it is better to use simple language when speaking with an individual with expressive aphasia. This is exemplified by the difficulty to understand phrases or sentences with unusual structure. A typical patient with Broca's aphasia will misinterpret \"the man is bitten by the dog\" by switching the subject and object to \"the dog is bitten by the man.\"\nTypically, people with expressive aphasia can understand speech and read better than they can produce speech and write. The person's writing will resemble their speech and will be effortful, lacking cohesion, and containing mostly content words. Letters will likely be formed clumsily and distorted and some may even be omitted. Although listening and reading are generally intact, subtle deficits in both reading and listening comprehension are almost always present during assessment of aphasia.\nBecause Broca's area is anterior to the primary motor cortex, which is responsible for movement of the face, hands, and arms, a lesion affecting Broca's areas may also result in hemiparesis (weakness of both limbs on the same side of the body) or hemiplegia (paralysis of both limbs on the same side of the body). The brain is wired contralaterally, which means the limbs on right side of the body are controlled by the left hemisphere and vice versa. Therefore, when Broca's area or surrounding areas in the left hemisphere are damaged, hemiplegia or hemiparesis often occurs on the right side of the body in individuals with Broca's aphasia.\nSeverity of expressive aphasia varies among patients. Some people may only have mild deficits and detecting problems with their language may be difficult. In the most extreme cases, patients may be able to produce only a single word. Even in such cases, over-learned and rote-learned speech patterns may be retained\u2013 for instance, some patients can count from one to ten, but cannot produce the same numbers in novel conversation.\n\n\n### Manual language and aphasia\nIn deaf patients who use manual language (such as American Sign Language), damage to the left hemisphere of the brain leads to disruptions in their signing ability. Paraphasic errors similar to spoken language have been observed; whereas in spoken language a phonemic substitution would occur (e.g. \"tagle\" instead of \"table\"), in ASL case studies errors in movement, hand position, and morphology have been noted. Agrammatism, or the lack of grammatical morphemes in sentence production, has also been observed in lifelong users of ASL who have left hemisphere damage. The lack of syntactic accuracy shows that the errors in signing are not due to damage to the motor cortex, but rather area manifestation of the damage to the language-producing area of the brain. Similar symptoms have been seen in a patient with left hemisphere damage whose first language was British Sign Language, further showing that damage to the left hemisphere primarily hinders linguistic ability, not motor ability. In contrast, patients who have damage to non-linguistic areas on the left hemisphere have been shown to be fluent in signing, but are unable to comprehend written language.\n\n\n### Overlap with receptive aphasia\nIn addition to difficulty expressing oneself, individuals with expressive aphasia are also noted to commonly have trouble with comprehension in certain linguistic areas. This agrammatism overlaps with receptive aphasia, but can be seen in patients who have expressive aphasia without being diagnosed as having receptive aphasia. The most well-noted of these are object-relative clauses, object Wh- questions, and topicalized structures (placing the topic at the beginning of the sentence). These three concepts all share phrasal movement, which can cause words to lose their thematic roles when they change order in the sentence. This is often not an issue for people without agrammatic aphasias, but many people with aphasia rely heavily on word order to understand roles that words play within the sentence.\n\n\n## Causes\n\n\n\n### More common\nStroke or brain anoxia.\nBrain tumor\nBrain trauma\n\n\n### Less common\nAutoimmune disease\nParaneoplastic syndrome\nMicrometastasis\nneurodegenerative disorders\nCertain infections (e.g., Bartonella henselae)\nMetabolic disease (e.g., hyperosmolar hyperglycemic state)\n\n\n=### Common causes=\nThe most common cause of expressive aphasia is stroke. A stroke is caused by hypoperfusion (lack of oxygen) to an area of the brain, which is commonly caused by thrombosis or embolism. Some form of aphasia occurs in 34 to 38% of stroke patients. Expressive aphasia occurs in approximately 12% of new cases of aphasia caused by stroke.\nIn most cases, expressive aphasia is caused by a stroke in Broca's area or the surrounding vicinity. Broca's area is in the lower part of the premotor cortex in the language dominant hemisphere and is responsible for planning motor speech movements. However, cases of expressive aphasia have been seen in patients with strokes in other areas of the brain. Patients with classic symptoms of expressive aphasia in general have more acute brain lesions, whereas patients with larger, widespread lesions exhibit a variety of symptoms that may be classified as global aphasia or left unclassified.\nExpressive aphasia can also be caused by trauma to the brain, tumor,  cerebral hemorrhage and by extradural abscess.\nUnderstanding lateralization of brain function is important for understanding which areas of the brain cause expressive aphasia when damaged. In the past, it has been believed that the area for language production differs between left and right-handed individuals. If this were true, damage to the homologous region of Broca's area in the right hemisphere should cause aphasia in a left-handed individual. More recent studies have shown that even left-handed individuals typically have language functions only in the left hemisphere. However, left-handed individuals are more likely to have a dominance of language in the right hemisphere.\n\n\n=### Uncommon causes=\nLess common causes of expressive aphasia include primary autoimmune phenomenon and autoimmune phenomenon that are secondary to cancer (as a paraneoplastic syndrome) have been listed as the primary hypothesis for several cases of aphasia, especially when presenting with other psychiatric disturbances and focal neurological deficits. Many case reports exist describing paraneoplastic aphasia, and the reports that are specific tend to describe expressive aphasia.  Although most cases attempt to exclude micro-metastasis, it is likely that some cases of paraneoplastic aphasia are actually extremely small metastasis to the vocal motor regions.\nNeurodegenerative disorders may present with aphasia. Alzheimer's disease may present with either fluent aphasia or expressive aphasia. There are case reports of Creutzfeldt-Jakob disease presenting with expressive aphasia.\n\n\n## Diagnosis\n\nExpressive aphasia is classified as non-fluent aphasia, as opposed to fluent aphasia. Diagnosis is done on a case-by-case basis, as lesions often affect the surrounding cortex and deficits are highly variable among patients with aphasia.\nA physician is typically the first person to recognize aphasia in a patient who is being treated for damage to the brain. Routine processes for determining the presence and location of lesion in the brain include magnetic resonance imaging (MRI) and computed tomography (CT) scans. The physician will complete a brief assessment of the patient's ability to understand and produce language. For further diagnostic testing, the physician will refer the patient to a speech-language pathologist, who will complete a comprehensive evaluation.\nIn order to diagnose a patient with Broca's aphasia, there are certain commonly used tests and procedures. The Western Aphasia Battery (WAB) classifies individuals based on their scores on the subtests; spontaneous speech, auditory comprehension, repetition, and naming. The Boston Diagnostic Aphasia Examination (BDAE) can inform users what specific type of aphasia they may have, infer the location of lesion, and assess current language abilities. The Porch Index of Communication Ability (PICA) can predict potential recovery outcomes of the patients with aphasia. Quality of life measurement is also an important assessment tool. Tests such as the Assessment for Living with Aphasia (ALA) and the Satisfaction with Life Scale (SWLS) allow for therapists to target skills that are important and meaningful for the individual.\nIn addition to formal assessments, patient and family interviews are valid and important sources of information. The patient's previous hobbies, interests, personality, and occupation are all factors that will not only impact therapy but may motivate them throughout the recovery process. Patient interviews and observations allow professionals to learn the priorities of the patient and family and determine what the patient hopes to regain in therapy. Observations of the patient may also be beneficial to determine where to begin treatment. The current behaviors and interactions of the patient will provide the therapist with more insight about the client and their individual needs. Other information about the patient can be retrieved from medical records, patient referrals from physicians, and the nursing staff.\nIn non-speaking patients who use manual languages, diagnosis is often based on interviews from the patient's acquaintances, noting the differences in sign production pre- and post-damage to the brain. Many of these patients will also begin to rely on non-linguistic gestures to communicate, rather than signing since their language production is hindered.\n\n\n## Treatment\n\nCurrently, there is no standard treatment for expressive aphasia. Most aphasia treatment is individualized based on a patient's condition and needs as assessed by a speech language pathologist. Patients go through a period of spontaneous recovery following brain injury in which they regain a great deal of language function.\nIn the months following injury or stroke, most patients receive traditional treatment for a few hours per day. Among other exercises, patients practice the repetition of words and phrases. Mechanisms are also taught in traditional treatment to compensate for lost language function such as drawing and using phrases that are easier to pronounce.\nEmphasis is placed on establishing a basis for communication with family and caregivers in everyday life. Treatment is individualized based on the patient's own priorities, along with the family's input.\nA patient may have the option of individual or group treatment. Although less common, group treatment has been shown to have advantageous outcomes. Some types of group treatments include family counseling, maintenance groups, support groups and treatment groups.\n\n\n### Augmentative and Alternative Communication\n\nAugmentative and Alternative Communication (AAC) refers to a set of tools and strategies that support or replace verbal communication for individuals with communication disorders, such as Broca's aphasia or other conditions that affect speech and language abilities. AAC is designed to enhance communication and may be used as a temporary or permanent solution, depending on the individual's needs. Here are some key aspects of AAC:\n\nCommunication Aids:\nLow-Tech AAC: This includes simple, non-electronic communication aids such as communication boards, picture books, or communication charts. Users can point to or select symbols or pictures to convey their messages\nHigh-Tech AAC: Involves electronic devices such as speech-generating devices (SGDs) or tablet-based communication apps. These devices use synthesized speech or recorded messages to facilitate communication. Users can select words, phrases, or symbols on a screen to express themselves.\nSymbols and Representations:\nSymbols used in AAC can vary and may include pictures, icons, words, or a combination of these. Symbols are chosen based on the individual's cognitive and language abilities.\nTypes of AAC Systems:\nUnaided AAC: Relies on the user's body to convey messages without external tools, such as using gestures, facial expressions, or sign language.\nAided AAC: Involves external tools or devices, such as communication boards, speech-generating devices, or computer-based systems.\nVocabulary and Language Systems:\nCore Vocabulary: Focuses on essential words that are frequently used across various contexts. Core vocabulary systems aim to provide users with a versatile set of words to express a wide range of messages.\nFringe Vocabulary: Includes specific words related to an individual's unique needs, interests, or daily activities. Fringe vocabulary supplements core vocabulary to make communication more personalized.\nCustomization and Individualization:\nAAC systems are highly customizable to meet the unique needs of each user. Therapists work with individuals and their families to tailor the system to the user's abilities, preferences, and communication goals.\nTraining and Support:\nUsers of AAC systems, as well as their caregivers and support networks, receive training to effectively use the communication tools. Training may involve learning how to navigate electronic devices, program personalized messages, or understand the meaning of symbols.\nIntegration with Therapy:\nAAC is often integrated into speech and language therapy sessions. Therapists use AAC tools to facilitate communication practice and help individuals with communication disorders improve their language skills.\nSocial and Emotional Aspects:\nAAC not only addresses the functional aspects of communication but also considers the social and emotional dimensions. It plays a crucial role in helping individuals with communication disorders participate more fully in social interactions and express their thoughts and feelings.\nAAC is a dynamic and evolving field, and advancements in technology continue to enhance the range and effectiveness of communication tools available for individuals with speech and language challenges. The selection of AAC strategies depends on factors such as the individual's abilities, preferences, and the specific nature of their communication disorder.\n\n\n### Melodic intonation therapy\nMelodic intonation therapy was inspired by the observation that individuals with non-fluent aphasia sometimes can sing words or phrases that they normally cannot speak. \"Melodic Intonation Therapy was begun as an attempt to use the intact melodic/prosodic processing skills of the right hemisphere in those with aphasia to help cue retrieval words and expressive language.\" It is believed that this is because singing capabilities are stored in the right hemisphere of the brain, which is likely to remain unaffected after a stroke in the left hemisphere. However, recent evidence demonstrates that the capability of individuals with aphasia to sing entire pieces of text may actually result from rhythmic features and the familiarity with the lyrics.\nThe goal of Melodic Intonation Therapy is to utilize singing to access the language-capable regions in the right hemisphere and use these regions to compensate for lost function in the left hemisphere. The natural musical component of speech was used to engage the patients' ability to produce phrases. A clinical study revealed that singing and rhythmic speech may be similarly effective in the treatment of non-fluent aphasia and apraxia of speech. Moreover, evidence from randomized controlled trials is still needed to confirm that Melodic Intonation Therapy is suitable to improve propositional utterances and speech intelligibility in individuals with (chronic) non-fluent aphasia and apraxia of speech.\nMelodic Intonation Therapy appears to work particularly well in patients who have had a unilateral, left hemisphere stroke, show poor articulation, are non-fluent or have severely restricted speech output, have moderately preserved auditory comprehension, and show good motivation. MIT therapy on average lasts for 1.5 hours per day for five days per week. At the lowest level of therapy, simple words and phrases (such as \"water\" and \"I love you\") are broken down into a series of high- and low-pitch syllables. With increased treatment, longer phrases are taught and less support is provided by the therapist. Patients are taught to say phrases using the natural melodic component of speaking and continuous voicing is emphasized. The patient is also instructed to use the left hand to tap the syllables of the phrase while the phrases are spoken. Tapping is assumed to trigger the rhythmic component of speaking to utilize the right hemisphere.\nFMRI studies have shown that Melodic Intonation Therapy (MIT) uses both sides of the brain to recover lost function, as opposed to traditional therapies that utilize only the left hemisphere. In MIT, individuals with small lesions in the left hemisphere seem to recover by activation of the left hemisphere perilesional cortex. Meanwhile, individuals with larger left-hemisphere lesions show a recruitment of the use of language-capable regions in the right hemisphere. The interpretation of these results is still a matter of debate. For example, it remains unclear whether changes in neural activity in the right hemisphere result from singing or from the intensive use of common phrases, such as \"thank you\", \"how are you?\" or \"I am fine.\" This type of phrases falls into the category of formulaic language and is known to be supported by neural networks of the intact right hemisphere.\nA pilot study reported positive results when comparing the efficacy of a modified form of MIT to no treatment in people with nonfluent aphasia with damage to their left-brain. A randomized controlled trial was conducted and the study reported benefits of utilizing modified MIT treatment early in the recovery phase for people with nonfluent aphasia.\nMelodic Intonation Therapy is used by music therapists, board-certified professionals that use music as a therapeutic tool to effect certain non-musical outcomes in their patients. Speech language pathologists can also use this therapy for individuals who have had a left hemisphere stroke and non-fluent aphasias such as Broca's or even apraxia of speech.\n\n\n### Constraint-induced therapy\nConstraint-induced aphasia therapy (CIAT) is based on similar principles as constraint-induced movement therapy developed by Dr. Edward Taub at the University of Alabama at Birmingham. Constraint-induced movement therapy is based on the idea that a person with an impairment (physical or communicative) develops a \"learned nonuse\" by compensating for the lost function with other means such as using an unaffected limb by a paralyzed individual or drawing by a patient with aphasia. In constraint-induced movement therapy, the alternative limb is constrained with a glove or sling and the patient is forced to use the affected limb. In constraint-induced aphasia therapy the interaction is guided by communicative need in a language game context, picture cards, barriers making it impossible to see other players' cards, and other materials, so that patients are encouraged (\"constrained\") to use the remaining verbal abilities to succeed in the communication game.\nTwo important principles of constraint-induced aphasia therapy are that treatment is very intense, with sessions lasting for up to 6 hours over the course of 10 days and that language is used in a communication context in which it is closely linked to (nonverbal) actions.  These principles are motivated by neuroscience insights about learning at the level of nerve cells (synaptic plasticity) and the coupling between cortical systems for language and action in the human brain. Constraint-induced therapy contrasts sharply with traditional therapy by the strong belief that mechanisms to compensate for lost language function, such as gesturing or writing, should not be used unless absolutely necessary, even in everyday life.\nIt is believed that CIAT works by the mechanism of increased neuroplasticity. By constraining an individual to use only speech, it is believed that the brain is more likely to reestablish old neural pathways and recruit new neural pathways to compensate for lost function.\nThe strongest results of CIAT have been seen in patients with chronic aphasia (lasting over 6 months). Studies of CIAT have confirmed that further improvement is possible even after a patient has reached a \"plateau\" period of recovery. It has also been proven that the benefits of CIAT are retained long term. However, improvements only seem to be made while a patient is undergoing intense therapy. Recent work has investigated combining constraint-induced aphasia therapy with drug treatment, which led to an amplification of therapy benefits.\n\n\n### Medication\nIn addition to active speech therapy, pharmaceuticals have also been considered as a useful treatment for expressive aphasia. This area of study is relatively new and much research continues to be conducted.\nThe following drugs have been suggested for use in treating aphasia and their efficacy has been studied in control studies.\n\nBromocriptine \u2013 acts on Catecholamine Systems\nPiracetam \u2013 mechanism not fully understood, but most likely interacts with cholinergic and glutamatergic receptors, among others\nCholinergic drugs (Donepezil, Aniracetam, Bifemelane) \u2013 acts on acetylcholine systems\nDopaminergic psychostimulants: (Dexamphetamine, Methylphenidate)\nThe most effect has been shown by piracetam and amphetamine, which may increase cerebral plasticity and result in an increased capability to improve language function. It has been seen that piracetam is most effective when treatment is begun immediately following stroke. When used in chronic cases it has been much less efficient.\nBromocriptine has been shown by some studies to increase verbal fluency and word retrieval with therapy than with just therapy alone.  Furthermore, its use seems to be restricted to non-fluent aphasia.\nDonepezil has shown a potential for helping chronic aphasia.\nNo study has established irrefutable evidence that any drug is an effective treatment for aphasia therapy. Furthermore, no study has shown any drug to be specific for language recovery.  Comparison between the recovery of language function and other motor function using any drug has shown that improvement is due to a global increase plasticity of neural networks.\n\n\n### Transcranial magnetic stimulation\nIn transcranial magnetic stimulation (TMS), magnetic fields are used to create electrical currents in specified cortical regions. The procedure is a painless and noninvasive method of stimulating the cortex. TMS works by suppressing the inhibition process in certain areas of the brain. By suppressing the inhibition of neurons by external factors, the targeted area of the brain may be reactivated and thereby recruited to compensate for lost function. Research has shown that patients can demonstrate increased object naming ability with regular transcranial magnetic stimulation than patients not receiving TMS. Furthermore, research suggests this improvement is sustained upon the completion of TMS therapy. However, some patients fail to show any significant improvement from TMS which indicates the need for further research of this treatment.\n\n\n### Treatment of underlying forms\nDescribed as the linguistic approach to the treatment of expressive aphasia, treatment begins by emphasizing and educating patients on the thematic roles of words within sentences. Sentences that are usually problematic will be reworded into active-voiced, declarative phrasings of their non-canonical counterparts. The simpler sentence phrasings are then transformed into variations that are more difficult to interpret. For example, many individuals who have expressive aphasia struggle with Wh- sentences. \"What\" and \"who\" questions are problematic sentences that this treatment method attempts to improve, and they are also two interrogative particles that are strongly related to each other because they reorder arguments from the declarative counterparts. For instance, therapists have used sentences like, \"Who is the boy helping?\" and \"What is the boy fixing?\" because both verbs are transitive- they require two arguments in the form of a subject and a direct object, but not necessarily an indirect object. In addition, certain question particles are linked together based on how the reworded sentence is formed. Training \"who\" sentences increased the generalizations of non-trained \"who\" sentences as well as untrained \"what\" sentences, and vice versa. Likewise, \"where\" and \"when\" question types are very closely linked. \"What\" and \"who\" questions alter placement of arguments, and \"where\" and \"when\" sentences move adjunct phrases. Training is in the style of: \"The man parked the car in the driveway. What did the man park in the driveway?\" Sentence training goes on in this manner for more domains, such as clefts and sentence voice.\nResults: Patients' use of sentence types used in the TUF treatment will improve, subjects will generalize sentences of similar category to those used for treatment in TUF, and results are applied to real-world conversations with others. Generalization of sentence types used can be improved when the treatment progresses in the order of more complex sentences to more elementary sentences. Treatment has been shown to affect on-line (real-time) processing of trained sentences and these results can be tracked using fMRI mappings. Training of Wh- sentences has led improvements in three main areas of discourse for aphasics: increased average length of utterances, higher proportions of grammatical sentences, and larger ratios of numbers of verbs to nouns produced. Patients also showed improvements in verb argument structure productions and assigned thematic roles to words in utterances with more accuracy. In terms of on-line sentence processing, patients having undergone this treatment discriminate between anomalous and non-anomalous sentences with more accuracy than control groups and are closer to levels of normalcy than patients not having participated in this treatment.\n\n\n### Mechanisms of recovery\nMechanisms for recovery differ from patient to patient. Some mechanisms for recovery occur spontaneously after damage to the brain, whereas others are caused by the effects of language therapy. FMRI studies have shown that recovery can be partially attributed to the activation of tissue around the damaged area and the recruitment of new neurons in these areas to compensate for the lost function. Recovery may also be caused in very acute lesions by a return of blood flow and function to damaged tissue that has not died around an injured area. It has been stated by some researchers that the recruitment and recovery of neurons in the left hemisphere opposed to the recruitment of similar neurons in the right hemisphere is superior for long-term recovery and continued rehabilitation. It is thought that, because the right hemisphere is not intended for full language function, using the right hemisphere as a mechanism of recovery is effectively a \"dead-end\" and can lead only to partial recovery.\nThere is evidence to support that, among all types of therapies, one of the most important factors and best predictors for a successful outcome is the intensity of the therapy. By comparing the length and intensity of various methods of therapies, it was proven that intensity is a better predictor of recovery than the method of therapy used.\n\n\n## Prognosis\n\nIn most individuals with expressive aphasia, the majority of recovery is seen within the first year following a stroke or injury. The majority of this improvement is seen in the first four weeks in therapy following a stroke and slows thereafter. However, this timeline will vary depending upon the type of stroke experienced by the patient. Patients who experienced an ischemic stroke may recover in the days and weeks following the stroke, and then experience a plateau and gradual slowing of recovery. On the contrary, patients who experienced a hemorrhagic stroke experience a slower recovery in the first 4\u20138 weeks, followed by a faster recovery which eventually stabilizes.\nNumerous factors impact the recovery process and outcomes. Site and extent of lesion greatly impacts recovery. Other factors that may affect prognosis are age, education, gender, and motivation. Occupation, handedness, personality, and emotional state may also be associated with recovery outcomes.\nStudies have also found that prognosis of expressive aphasia correlates strongly with the initial severity of impairment. However, it has been seen that continued recovery is possible years after a stroke with effective treatment. Timing and intensity of treatment is another factor that impacts outcomes. Research suggests that even in later stages of recovery, intervention is effective at improving function, as well as, preventing loss of function.\nUnlike receptive aphasia, patients with expressive aphasia are aware of their errors in language production. This may further motivate a person with expressive aphasia to progress in treatment, which would affect treatment outcomes. On the other hand, awareness of impairment may lead to higher levels of frustration, depression, anxiety, or social withdrawal, which have been proven to negatively affect a person's chance of recovery.\n\n\n## History\n\nExpressive aphasia was first identified by the French neurologist Paul Broca. By examining the brains of deceased individuals having acquired expressive aphasia in life, he concluded that language ability is localized in the ventroposterior region of the frontal lobe. One of the most important aspects of Paul Broca's discovery was the observation that the loss of proper speech in expressive aphasia is due to the brain's loss of ability to produce language, as opposed to the mouth's loss of ability to produce words.\nThe discoveries of Paul Broca were made during the same period of time as the German Neurologist Carl Wernicke, who was also studying brains of aphasiacs post-mortem and identified the region now known as Wernicke's area. Discoveries of both men contributed to the concept of localization, which states that specific brain functions are all localized to a specific area of the brain. While both men made significant contributions to the field of aphasia, it was Carl Wernicke who realized the difference between patients with aphasia that could not produce language and those that could not comprehend language (the essential difference between expressive and receptive aphasia).\n\n\n## See also\n\nBroca's area\nTranscortical sensory aphasia\nWernicke's aphasia\nWord salad\n\n\n## References\n\n\nASHA Glossary: Broca's Aphasia. (n.d.). Retrieved November 18, 2015, from http://www.asha.org/Glossary/Brocas-Aphasia/\n\n\n## Sources\n\n\n\n## External links\n\n",
      "vector_count": 1,
      "vector_offset": 4
    }
  ]
}